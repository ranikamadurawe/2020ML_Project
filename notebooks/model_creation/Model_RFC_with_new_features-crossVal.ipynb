{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as slearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset Importing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path.cwd() / \"../../datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(DATA_PATH / \"train.csv\", index_col=\"tripid\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.dropna(subset=['fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Conversions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date time objects from Objects to datetime64\n",
    "training_df['pickup_time'] = pd.to_datetime(training_df['pickup_time'], format=\"%m/%d/%Y %H:%M\")\n",
    "training_df['drop_time'] = pd.to_datetime(training_df['drop_time'], format=\"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Adding Features</h2>\n",
    "Adding features deemed useful from Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "for index,row in training_df.iterrows():\n",
    "  provided_duration = row['duration'] #first row of location.lat column here\n",
    "  if math.isnan(provided_duration) or provided_duration <= 0 :\n",
    "    time_dif = (row['drop_time'] - row['pickup_time']).seconds\n",
    "    if(time_dif == 0):\n",
    "        time_dif = 60\n",
    "    durations.append(time_dif)\n",
    "  else :  \n",
    "    durations.append(provided_duration)\n",
    "\n",
    "training_df.insert(4,\"time_dif\",durations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_from_coordinates(lat1, lon1, lat2, lon2):\n",
    "  R = 6371  # Earth radius in km\n",
    "\n",
    "  #conversion to radians\n",
    "  d_lat = np.radians(lat2-lat1)\n",
    "  d_lon = np.radians(lon2-lon1)\n",
    "\n",
    "  r_lat1 = np.radians(lat1)\n",
    "  r_lat2 = np.radians(lat2)\n",
    "\n",
    "  #haversine formula\n",
    "  a = np.sin(d_lat/2.) **2 + np.cos(r_lat1) * np.cos(r_lat2) * np.sin(d_lon/2.)**2\n",
    "\n",
    "  haversine = 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "  return haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.assign(timeOfDay=pd.cut(training_df.pickup_time.dt.hour,[-1, 8, 20, 24],labels=['dawn','day', 'night']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = []                    #empty column for distance\n",
    "for index,row in training_df.iterrows():\n",
    "  lat1 = row['pick_lat'] #first row of location.lat column here\n",
    "  lon1 = row['pick_lon'] #first row of location.long column here\n",
    "  lat2 = row['drop_lat'] #second row of location.lat column here\n",
    "  lon2 = row['drop_lon'] #second row of location.long column here\n",
    "  value = dist_from_coordinates(lat1, lon1, lat2, lon2)  #get the distance\n",
    "  new_column.append(value)   #append the empty list with distance values\n",
    "\n",
    "training_df.insert(4,\"distance\",new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['avg_speed'] = (training_df['distance'] /  ( training_df['time_dif']) * 3600 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.drop(index=190167541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.nlargest(100,'avg_speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the useful features deemed in feature engineering\n",
    "features_classifier = training_df[['additional_fare', 'time_dif', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup','distance','avg_speed','fare']]\n",
    "label_classifier = training_df[['label']]\n",
    "mapping = {'correct': 1, 'incorrect': 0}\n",
    "label_classifier = label_classifier.replace({'label':mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_classifier.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = features_classifier.columns[features_classifier.dtypes == \"float64\"].values\n",
    "categorical_features = features_classifier.columns[features_classifier.dtypes == \"category\" ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "non_numeric_preprocessing_steps = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot_encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "#     ('label_encoder', LabelEncoder())\n",
    "])\n",
    "\n",
    "## create preprocessor stage of the final pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('non_numeric', non_numeric_preprocessing_steps, categorical_features),\n",
    "        ('numeric', numeric_preprocessing_steps, numerical_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of new columns\n",
    "new_columns = ['additional_fare', 'time_dif', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup','distance','avg_speed','fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(features_classifier, label_classifier, test_size=0.3, shuffle=True,stratify=label_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(random_state=42, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X_train,y_train):\n",
    "    X_train_fold, X_eval_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_eval_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    # Transform training data columns \n",
    "    preprocessed_train_features = preprocessor.fit_transform(X_train_fold)\n",
    "    preprocessed_train_features_data_frame = pd.DataFrame(data=preprocessed_train_features, columns=new_columns)\n",
    "    \n",
    "    \n",
    "    ## Train the model\n",
    "    classifier.fit(preprocessed_train_features_data_frame, y_train_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_features = preprocessor.fit_transform(X_eval)\n",
    "preprocessed_test_features_data_frame = pd.DataFrame(data=preprocessed_test_features, columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the evaluation set\n",
    "print(\"Training Accuracy: %.2f\" % (classifier.score(preprocessed_test_features_data_frame, y_eval)*100), \"%\")\n",
    "y_pred = classifier.predict(preprocessed_test_features_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(classifier.feature_importances_, index=new_columns)\n",
    "   .nlargest(30)\n",
    "   .plot(kind='barh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_eval, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Validation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading the test data set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(DATA_PATH / \"test.csv\", index_col=\"tripid\")\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Addition for the Test Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['pickup_time'] = pd.to_datetime(test_set['pickup_time'], format=\"%m/%d/%Y %H:%M\")\n",
    "test_set['drop_time'] = pd.to_datetime(test_set['drop_time'], format=\"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.assign(timeOfDay=pd.cut(test_set.pickup_time.dt.hour,[-1, 8, 20, 24],labels=['dawn','day', 'night']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = []                    #empty column for distance\n",
    "for index,row in test_set.iterrows():\n",
    "  lat1 = row['pick_lat'] #first row of location.lat column here\n",
    "  lon1 = row['pick_lon'] #first row of location.long column here\n",
    "  lat2 = row['drop_lat'] #second row of location.lat column here\n",
    "  lon2 = row['drop_lon'] #second row of location.long column here\n",
    "  value = dist_from_coordinates(lat1, lon1, lat2, lon2)  #get the distance\n",
    "  new_column.append(value)   #append the empty list with distance values\n",
    "\n",
    "test_set .insert(4,\"distance\",new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "for index,row in test_set.iterrows():\n",
    "  provided_duration = row['duration'] #first row of location.lat column here\n",
    "  if math.isnan(provided_duration) or provided_duration <= 0 :\n",
    "    time_dif = (row['drop_time'] - row['pickup_time']).seconds\n",
    "    if(time_dif == 0):\n",
    "        time_dif = 60\n",
    "    durations.append(time_dif)\n",
    "  else :  \n",
    "    durations.append(provided_duration)\n",
    "\n",
    "test_set.insert(4,\"time_dif\",durations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['avg_speed'] = (test_set['distance'] /  ( test_set['time_dif']) * 3600 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_set[['additional_fare', 'time_dif', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup','distance','avg_speed','fare']]\n",
    "preprocessed_test_features = preprocessor.fit_transform(test_features)\n",
    "preprocessed_test_features_data_frame = pd.DataFrame(data=preprocessed_test_features, columns=new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fare prediction and correctness prediction using Test Dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = classifier.predict(preprocessed_test_features_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Writing to the Submission File</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set = pd.read_csv(DATA_PATH / \"sample_submission.csv\", index_col=\"tripid\")\n",
    "submission_set.head()\n",
    "\n",
    "submission_set['prediction']= predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../submissions/'+theNotebook+'/teamCluster_submission_{%i}.csv'\n",
    "dirname = '../../submissions/'+theNotebook\n",
    "fileversion = 1\n",
    "\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)\n",
    "while glob.glob(filename.replace('{%i}',str(fileversion))) :\n",
    "    fileversion+=1\n",
    "submission_set.to_csv(filename.replace('{%i}',str(fileversion)), index=True)\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set['prediction'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
