{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as slearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset Importing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path.cwd() / \"../../datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189123628</th>\n",
       "      <td>10.5</td>\n",
       "      <td>834.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11/1/2019 0:20</td>\n",
       "      <td>11/1/2019 0:34</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>6.90330</td>\n",
       "      <td>79.8783</td>\n",
       "      <td>270.32</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125358</th>\n",
       "      <td>10.5</td>\n",
       "      <td>791.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11/1/2019 0:56</td>\n",
       "      <td>11/1/2019 1:09</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>6.91373</td>\n",
       "      <td>79.8923</td>\n",
       "      <td>197.85</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125719</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11/1/2019 1:08</td>\n",
       "      <td>11/1/2019 1:26</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.93669</td>\n",
       "      <td>79.9146</td>\n",
       "      <td>301.64</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189127273</th>\n",
       "      <td>10.5</td>\n",
       "      <td>598.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11/1/2019 2:27</td>\n",
       "      <td>11/1/2019 2:37</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>6.92748</td>\n",
       "      <td>79.8971</td>\n",
       "      <td>82.30</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189128020</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/1/2019 3:34</td>\n",
       "      <td>11/1/2019 3:51</td>\n",
       "      <td>6.87441</td>\n",
       "      <td>79.8615</td>\n",
       "      <td>6.84478</td>\n",
       "      <td>79.9290</td>\n",
       "      <td>358.39</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "tripid                                                                    \n",
       "189123628             10.5     834.0           56.0              0.0000   \n",
       "189125358             10.5     791.0           47.0              0.0000   \n",
       "189125719             10.5    1087.0           80.0              0.0000   \n",
       "189127273             10.5     598.0          271.0             15.6638   \n",
       "189128020              NaN       NaN            NaN                 NaN   \n",
       "\n",
       "           meter_waiting_till_pickup     pickup_time       drop_time  \\\n",
       "tripid                                                                 \n",
       "189123628                       64.0  11/1/2019 0:20  11/1/2019 0:34   \n",
       "189125358                      134.0  11/1/2019 0:56  11/1/2019 1:09   \n",
       "189125719                       61.0  11/1/2019 1:08  11/1/2019 1:26   \n",
       "189127273                       68.0  11/1/2019 2:27  11/1/2019 2:37   \n",
       "189128020                        NaN  11/1/2019 3:34  11/1/2019 3:51   \n",
       "\n",
       "           pick_lat  pick_lon  drop_lat  drop_lon    fare    label  \n",
       "tripid                                                              \n",
       "189123628   6.86252   79.8993   6.90330   79.8783  270.32  correct  \n",
       "189125358   6.88589   79.8984   6.91373   79.8923  197.85  correct  \n",
       "189125719   6.90839   79.8651   6.93669   79.9146  301.64  correct  \n",
       "189127273   6.92570   79.8895   6.92748   79.8971   82.30  correct  \n",
       "189128020   6.87441   79.8615   6.84478   79.9290  358.39  correct  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(DATA_PATH / \"train.csv\", index_col=\"tripid\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.dropna(subset=['fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Conversions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date time objects from Objects to datetime64\n",
    "training_df['pickup_time'] = pd.to_datetime(training_df['pickup_time'], format=\"%m/%d/%Y %H:%M\")\n",
    "training_df['drop_time'] = pd.to_datetime(training_df['drop_time'], format=\"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Adding Features</h2>\n",
    "Adding features deemed useful from Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_from_coordinates(lat1, lon1, lat2, lon2):\n",
    "  R = 6371  # Earth radius in km\n",
    "\n",
    "  #conversion to radians\n",
    "  d_lat = np.radians(lat2-lat1)\n",
    "  d_lon = np.radians(lon2-lon1)\n",
    "\n",
    "  r_lat1 = np.radians(lat1)\n",
    "  r_lat2 = np.radians(lat2)\n",
    "\n",
    "  #haversine formula\n",
    "  a = np.sin(d_lat/2.) **2 + np.cos(r_lat1) * np.cos(r_lat2) * np.sin(d_lon/2.)**2\n",
    "\n",
    "  haversine = 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "  return haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.assign(timeOfDay=pd.cut(training_df.pickup_time.dt.hour,[-1, 8, 20, 24],labels=['dawn','day', 'night']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = []                    #empty column for distance\n",
    "for index,row in training_df.iterrows():\n",
    "  lat1 = row['pick_lat'] #first row of location.lat column here\n",
    "  lon1 = row['pick_lon'] #first row of location.long column here\n",
    "  lat2 = row['drop_lat'] #second row of location.lat column here\n",
    "  lon2 = row['drop_lon'] #second row of location.long column here\n",
    "  value = dist_from_coordinates(lat1, lon1, lat2, lon2)  #get the distance\n",
    "  new_column.append(value)   #append the empty list with distance values\n",
    "\n",
    "training_df.insert(4,\"distance\",new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "for index,row in training_df.iterrows():\n",
    "  provided_duration = row['duration'] #first row of location.lat column here\n",
    "  if math.isnan(provided_duration) or provided_duration <= 0 :\n",
    "    time_dif = (row['drop_time'] - row['pickup_time']).seconds\n",
    "    if(time_dif == 0):\n",
    "        time_dif = 60\n",
    "    durations.append(time_dif)\n",
    "  else :  \n",
    "    durations.append(provided_duration)\n",
    "\n",
    "training_df.insert(4,\"time_dif\",durations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['avg_speed'] = (training_df['distance'] /  ( training_df['time_dif']) * 3600 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.drop(index=190167541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset after adding Columns\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Training</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 1 : Fare Predictor </h2>\n",
    "Predict fare using features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Correctly predicted fares\n",
    "correct_training_df = training_df[training_df['label'] == 'correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the useful features deemed in feature engineering\n",
    "features_predictor = correct_training_df[['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup','distance','avg_speed']]\n",
    "fare_prediction = correct_training_df[['fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_predictor.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = features_predictor.columns[features_predictor.dtypes == \"float64\"].values\n",
    "categorical_features = features_predictor.columns[features_predictor.dtypes == \"category\" ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(features_predictor, fare_prediction, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## chain numerical preprocessing into a pipeline object\n",
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "non_numeric_preprocessing_steps = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot_encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "#     ('label_encoder', LabelEncoder())\n",
    "])\n",
    "\n",
    "## create preprocessor stage of the final pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('non_numeric', non_numeric_preprocessing_steps, categorical_features),\n",
    "        ('numeric', numeric_preprocessing_steps, numerical_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of new columns\n",
    "new_columns = ['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup', 'distance','avg_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data columns \n",
    "preprocessed_train_features = preprocessor.fit_transform(X_train)\n",
    "preprocessed_train_features_data_frame = pd.DataFrame(data=preprocessed_train_features, columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform tvalidation data columns \n",
    "preprocessed_test_features = preprocessor.fit_transform(X_eval)\n",
    "preprocessed_test_features_data_frame = pd.DataFrame(data=preprocessed_test_features, columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_features_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the Predictor\n",
    "estimator = RandomForestRegressor()\n",
    "\n",
    "# Train the model\n",
    "estimator.fit(preprocessed_train_features, y_train)\n",
    "\n",
    "# Predict for the evaluation set\n",
    "y_pred = estimator.predict(preprocessed_test_features_data_frame)\n",
    "slearn.metrics.mean_squared_error(y_pred, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training using split data done prepare features for training with full dataset !! Optional !!\n",
    "\n",
    "required_features = training_df[['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup','distance','avg_speed']]\n",
    "preprocessed_full_features = preprocessor.fit_transform(required_features)\n",
    "preprocessed_full_features_data_frame = pd.DataFrame(data=preprocessed_full_features, columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = estimator.predict(preprocessed_full_features_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.insert(13,'predicted_price',predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset after new features inserted\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: Training the classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_features = training_df[['predicted_price','fare']]\n",
    "classifier_label = training_df[['label']]\n",
    "mapping = {'correct': 1, 'incorrect': 0}\n",
    "classifier_label = classifier_label.replace({'label':mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(classifier_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', np.unique(classifier_label), classifier_label['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(classifier_features, classifier_label, test_size=0.3,stratify= classifier_label, shuffle=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "## Train the model\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict for the evaluation set\n",
    "print(\"Training Accuracy: %.2f\" % (classifier.score(X_eval, y_eval)*100), \"%\")\n",
    "y_pred = classifier.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_eval, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Validation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading the test data set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(DATA_PATH / \"test.csv\", index_col=\"tripid\")\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Addition for the Test Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['pickup_time'] = pd.to_datetime(test_set['pickup_time'], format=\"%m/%d/%Y %H:%M\")\n",
    "test_set['drop_time'] = pd.to_datetime(test_set['drop_time'], format=\"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.assign(timeOfDay=pd.cut(test_set.pickup_time.dt.hour,[-1, 8, 20, 24],labels=['dawn','day', 'night']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = []                    #empty column for distance\n",
    "for index,row in test_set.iterrows():\n",
    "  lat1 = row['pick_lat'] #first row of location.lat column here\n",
    "  lon1 = row['pick_lon'] #first row of location.long column here\n",
    "  lat2 = row['drop_lat'] #second row of location.lat column here\n",
    "  lon2 = row['drop_lon'] #second row of location.long column here\n",
    "  value = dist_from_coordinates(lat1, lon1, lat2, lon2)  #get the distance\n",
    "  new_column.append(value)   #append the empty list with distance values\n",
    "\n",
    "test_set .insert(4,\"distance\",new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "for index,row in test_set.iterrows():\n",
    "  provided_duration = row['duration'] #first row of location.lat column here\n",
    "  if math.isnan(provided_duration) or provided_duration <= 0 :\n",
    "    time_dif = (row['drop_time'] - row['pickup_time']).seconds\n",
    "    if(time_dif == 0):\n",
    "        time_dif = 60\n",
    "    durations.append(time_dif)\n",
    "  else :  \n",
    "    durations.append(provided_duration)\n",
    "\n",
    "test_set.insert(4,\"time_dif\",durations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['avg_speed'] = (test_set['distance'] /  ( test_set['time_dif']) * 3600 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_set[['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup','distance','avg_speed']]\n",
    "preprocessed_test_features = preprocessor.fit_transform(test_features)\n",
    "preprocessed_test_features_data_frame = pd.DataFrame(data=preprocessed_test_features, columns=new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fare prediction and correctness prediction using Test Dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = estimator.predict(preprocessed_test_features_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.insert(10,'predicted_price',test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_test_features = test_set[['predicted_price','fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = classifier.predict(classifier_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Writing to the Submission File</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set = pd.read_csv(DATA_PATH / \"sample_submission.csv\", index_col=\"tripid\")\n",
    "submission_set.head()\n",
    "\n",
    "submission_set['prediction']= predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../submissions/'+theNotebook+'/teamCluster_submission_{%i}.csv'\n",
    "dirname = '../../submissions/'+theNotebook\n",
    "fileversion = 1\n",
    "\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)\n",
    "while glob.glob(filename.replace('{%i}',str(fileversion))) :\n",
    "    fileversion+=1\n",
    "submission_set.to_csv(filename.replace('{%i}',str(fileversion)), index=True)\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set['prediction'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
