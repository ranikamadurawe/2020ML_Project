{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PLEASE NOTE THAT THIS NOTEBOOK WAS RUN IN GOOGLE COLAB AS SUCH CERTAIN IMPORT STATEMENTS MAY DIFFER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2945,
     "status": "ok",
     "timestamp": 1588583119742,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "jUaEoTp3nX62",
    "outputId": "36e30994-3d7b-4033-a1d2-5f10f37ee215"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2937,
     "status": "ok",
     "timestamp": 1588583119746,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "UMLARlE7odoM",
    "outputId": "096f1497-10a8-4a35-c043-1ba282121b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rK7kM-kBppeM"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_path=os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..', '/content/drive/My Drive/datasets/train.csv'))\n",
    "training_df = pd.read_csv(train_path, index_col=\"tripid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1jv6jOZxtmM"
   },
   "outputs": [],
   "source": [
    "training_df = training_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED75ozkwtQbb"
   },
   "outputs": [],
   "source": [
    "def dist_from_coordinates(lat1, lon1, lat2, lon2):\n",
    "  R = 6371  # Earth radius in km\n",
    "\n",
    "  #conversion to radians\n",
    "  d_lat = np.radians(lat2-lat1)\n",
    "  d_lon = np.radians(lon2-lon1)\n",
    "\n",
    "  r_lat1 = np.radians(lat1)\n",
    "  r_lat2 = np.radians(lat2)\n",
    "\n",
    "  #haversine formula\n",
    "  a = np.sin(d_lat/2.) **2 + np.cos(r_lat1) * np.cos(r_lat2) * np.sin(d_lon/2.)**2\n",
    "\n",
    "  haversine = 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "  return haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0ER9Zu9tSHe"
   },
   "outputs": [],
   "source": [
    "training_df['pickup_time'] = pd.to_datetime(training_df['pickup_time'], format=\"%m/%d/%Y %H:%M\")\n",
    "training_df['drop_time'] = pd.to_datetime(training_df['drop_time'], format=\"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8Ffh2yUuQEL"
   },
   "outputs": [],
   "source": [
    "training_df = training_df.assign(timeOfDay=pd.cut(training_df.pickup_time.dt.hour,[-1, 8, 20, 24],labels=['dawn','day', 'night']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDJHv4gVtZBN"
   },
   "outputs": [],
   "source": [
    "durations = []\n",
    "for index,row in training_df.iterrows():\n",
    "  provided_duration = row['duration'] #first row of location.lat column here\n",
    "  if math.isnan(provided_duration) or provided_duration <= 0 :\n",
    "    time_dif = (row['drop_time'] - row['pickup_time']).seconds\n",
    "    if(time_dif == 0):\n",
    "        time_dif = np.nan\n",
    "    durations.append(time_dif)\n",
    "  else :  \n",
    "    durations.append(provided_duration)\n",
    "\n",
    "training_df.insert(4,\"time_dif\",durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maXCexqwuXAB"
   },
   "outputs": [],
   "source": [
    "new_column = []                    #empty column for distance\n",
    "for index,row in training_df.iterrows():\n",
    "  lat1 = row['pick_lat'] #first row of location.lat column here\n",
    "  lon1 = row['pick_lon'] #first row of location.long column here\n",
    "  lat2 = row['drop_lat'] #second row of location.lat column here\n",
    "  lon2 = row['drop_lon'] #second row of location.long column here\n",
    "  value = dist_from_coordinates(lat1, lon1, lat2, lon2)  #get the distance\n",
    "  new_column.append(value)   #append the empty list with distance values\n",
    "\n",
    "training_df.insert(4,\"distance\",new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUUL7qjuuShC"
   },
   "outputs": [],
   "source": [
    "training_df['time_driven'] = training_df['duration']  - training_df['meter_waiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7DsSWOHuUWL"
   },
   "outputs": [],
   "source": [
    "chargeperhours = []\n",
    "for index,row in training_df.iterrows():\n",
    "    if(row['meter_waiting'] == 0):\n",
    "        chargeperhour = 0\n",
    "    else:\n",
    "        chargeperhour = (row['meter_waiting_fare'] / row['meter_waiting'])\n",
    "    chargeperhours.append(chargeperhour)\n",
    "\n",
    "training_df.insert(4,'charge_per_hour',chargeperhours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szAPuXJ9ur_5"
   },
   "outputs": [],
   "source": [
    "training_df['driving_fare'] = training_df['fare']  - training_df['meter_waiting_fare'] - training_df['additional_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1KGgvV9uu5X"
   },
   "outputs": [],
   "source": [
    "avgspeeds = []\n",
    "for index,row in training_df.iterrows():\n",
    "    if(row['time_driven'] == 0):\n",
    "        avgspeed = 0    \n",
    "    else:\n",
    "        avgspeed = (row['distance'] / row['time_driven'])\n",
    "    avgspeeds.append(avgspeed)\n",
    "\n",
    "training_df.insert(4,\"avg_speed\",avgspeeds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wq6qOBghuxfr"
   },
   "outputs": [],
   "source": [
    "costsperkm = []\n",
    "for index,row in training_df.iterrows():\n",
    "    if row['driving_fare'] == 0:\n",
    "        costperkm = 0\n",
    "            \n",
    "    else:\n",
    "        costperkm = (row['distance'] / row['driving_fare'])\n",
    "    costsperkm.append(costperkm)\n",
    "\n",
    "training_df.insert(4,\"cost_per_km\",costsperkm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KliU6BiLzyFt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1929,
     "status": "ok",
     "timestamp": 1588581456561,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "wnBaVUvju_RB",
    "outputId": "2851fb2d-9338-4672-f8ae-9ab2486e4319"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
       "       'cost_per_km', 'avg_speed', 'charge_per_hour', 'distance', 'time_dif',\n",
       "       'meter_waiting_till_pickup', 'pickup_time', 'drop_time', 'pick_lat',\n",
       "       'pick_lon', 'drop_lat', 'drop_lon', 'fare', 'label', 'timeOfDay',\n",
       "       'time_driven', 'driving_fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evN3ZUMhrt6z"
   },
   "outputs": [],
   "source": [
    "training_features_labels = ['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'cost_per_km', 'avg_speed', 'distance', 'time_dif',\n",
    "       'meter_waiting_till_pickup', 'fare',\n",
    "       'time_driven', 'charge_per_hour', 'driving_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kG1yQPf6ryTh"
   },
   "outputs": [],
   "source": [
    "correct_training_df = training_df[training_df['label'] == 'correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwxbcqkDsmZG"
   },
   "outputs": [],
   "source": [
    "correct_training_df = correct_training_df[training_features_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1588583143259,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "BlZu8olgxSha",
    "outputId": "1fe1d273-0a2e-400f-a61e-5fcbaa716604"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "additional_fare              0\n",
       "duration                     0\n",
       "meter_waiting                0\n",
       "meter_waiting_fare           0\n",
       "cost_per_km                  0\n",
       "avg_speed                    0\n",
       "distance                     0\n",
       "time_dif                     0\n",
       "meter_waiting_till_pickup    0\n",
       "fare                         0\n",
       "time_driven                  0\n",
       "charge_per_hour              0\n",
       "driving_fare                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_training_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsNZwHrlvc7B"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# scaled_seqs = scaler.fit_transform(correct_training_df )\n",
    "scaled_seqs = correct_training_df\n",
    "#Create a test and train sets of our data\n",
    "X_train = scaled_seqs[:12000]\n",
    "X_test = scaled_seqs[12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHjfiP4zwCe2"
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmwiT1fGoXRT"
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1] # the # features\n",
    "encoding_dim = 8 # first layer\n",
    "hidden_dim = int(encoding_dim / 2) #hideen layer\n",
    "\n",
    "nb_epoch = 30\n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(encoding_dim, activation='relu')(encoder)\n",
    "decoder = Dense(input_dim, activation='tanh')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# ----- some data omitted --------- #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnXDbzCXwfpR"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yj6iWgg1we6M",
    "outputId": "4780ffc1-a761-461a-f24d-afc47bd71b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Epoch 5489/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1168 - val_loss: 14571678.4522\n",
      "Epoch 5490/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 5491/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 5492/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 5493/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1297 - val_loss: 14571678.4522\n",
      "Epoch 5494/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1667 - val_loss: 14571678.4522\n",
      "Epoch 5495/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0652 - val_loss: 14571678.4522\n",
      "Epoch 5496/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1073 - val_loss: 14571678.4522\n",
      "Epoch 5497/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 5498/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 5499/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1498 - val_loss: 14571678.4522\n",
      "Epoch 5500/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1703 - val_loss: 14571678.4522\n",
      "Epoch 5501/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 5502/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 5503/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9568 - val_loss: 14571678.4522\n",
      "Epoch 5504/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0620 - val_loss: 14571678.4522\n",
      "Epoch 5505/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1387 - val_loss: 14571678.4522\n",
      "Epoch 5506/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0777 - val_loss: 14571678.4522\n",
      "Epoch 5507/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 5508/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0635 - val_loss: 14571678.4522\n",
      "Epoch 5509/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0079 - val_loss: 14571678.4522\n",
      "Epoch 5510/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1209 - val_loss: 14571678.4522\n",
      "Epoch 5511/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0422 - val_loss: 14571678.4522\n",
      "Epoch 5512/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1323 - val_loss: 14571678.4522\n",
      "Epoch 5513/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1338 - val_loss: 14571678.4522\n",
      "Epoch 5514/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0437 - val_loss: 14571678.4522\n",
      "Epoch 5515/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 5516/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0600 - val_loss: 14571678.4522\n",
      "Epoch 5517/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 5518/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1073 - val_loss: 14571678.4522\n",
      "Epoch 5519/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1412 - val_loss: 14571678.4522\n",
      "Epoch 5520/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1542 - val_loss: 14571678.4522\n",
      "Epoch 5521/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0903 - val_loss: 14571678.4522\n",
      "Epoch 5522/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 5523/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0517 - val_loss: 14571678.4522\n",
      "Epoch 5524/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1394 - val_loss: 14571678.4522\n",
      "Epoch 5525/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 5526/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0738 - val_loss: 14571678.4522\n",
      "Epoch 5527/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 5528/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1273 - val_loss: 14571678.4522\n",
      "Epoch 5529/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1523 - val_loss: 14571678.4522\n",
      "Epoch 5530/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0940 - val_loss: 14571678.4522\n",
      "Epoch 5531/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1550 - val_loss: 14571678.4522\n",
      "Epoch 5532/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1567 - val_loss: 14571678.4522\n",
      "Epoch 5533/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1105 - val_loss: 14571678.4522\n",
      "Epoch 5534/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0433 - val_loss: 14571678.4522\n",
      "Epoch 5535/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0126 - val_loss: 14571678.4522\n",
      "Epoch 5536/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1032 - val_loss: 14571678.4522\n",
      "Epoch 5537/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0685 - val_loss: 14571678.4522\n",
      "Epoch 5538/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1343 - val_loss: 14571678.4522\n",
      "Epoch 5539/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0083 - val_loss: 14571678.4522\n",
      "Epoch 5540/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1183 - val_loss: 14571678.4522\n",
      "Epoch 5541/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1273 - val_loss: 14571678.4522\n",
      "Epoch 5542/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 5543/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1407 - val_loss: 14571678.4522\n",
      "Epoch 5544/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0233 - val_loss: 14571678.4522\n",
      "Epoch 5545/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0943 - val_loss: 14571678.4522\n",
      "Epoch 5546/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0421 - val_loss: 14571678.4522\n",
      "Epoch 5547/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 5548/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0377 - val_loss: 14571678.4522\n",
      "Epoch 5549/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0777 - val_loss: 14571678.4522\n",
      "Epoch 5550/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 5551/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1283 - val_loss: 14571678.4522\n",
      "Epoch 5552/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0413 - val_loss: 14571678.4522\n",
      "Epoch 5553/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9665 - val_loss: 14571678.4522\n",
      "Epoch 5554/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0390 - val_loss: 14571678.4522\n",
      "Epoch 5555/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0347 - val_loss: 14571678.4522\n",
      "Epoch 5556/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0436 - val_loss: 14571678.4522\n",
      "Epoch 5557/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 5558/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0450 - val_loss: 14571678.4522\n",
      "Epoch 5559/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9957 - val_loss: 14571678.4522\n",
      "Epoch 5560/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 5561/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 5562/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1330 - val_loss: 14571678.4522\n",
      "Epoch 5563/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0217 - val_loss: 14571678.4522\n",
      "Epoch 5564/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 5565/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 5566/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0192 - val_loss: 14571678.4522\n",
      "Epoch 5567/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 5568/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1225 - val_loss: 14571678.4522\n",
      "Epoch 5569/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1313 - val_loss: 14571678.4522\n",
      "Epoch 5570/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 5571/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0718 - val_loss: 14571678.4522\n",
      "Epoch 5572/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1212 - val_loss: 14571678.4522\n",
      "Epoch 5573/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0628 - val_loss: 14571678.4522\n",
      "Epoch 5574/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0670 - val_loss: 14571678.4522\n",
      "Epoch 5575/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0547 - val_loss: 14571678.4522\n",
      "Epoch 5576/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 5577/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1140 - val_loss: 14571678.4522\n",
      "Epoch 5578/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0881 - val_loss: 14571678.4522\n",
      "Epoch 5579/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0197 - val_loss: 14571678.4522\n",
      "Epoch 5580/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 5581/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1198 - val_loss: 14571678.4522\n",
      "Epoch 5582/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 5583/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1767 - val_loss: 14571678.4522\n",
      "Epoch 5584/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1254 - val_loss: 14571678.4522\n",
      "Epoch 5585/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 5586/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 5587/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1387 - val_loss: 14571678.4522\n",
      "Epoch 5588/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 5589/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 5590/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1095 - val_loss: 14571678.4522\n",
      "Epoch 5591/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0700 - val_loss: 14571678.4522\n",
      "Epoch 5592/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0701 - val_loss: 14571678.4522\n",
      "Epoch 5593/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0090 - val_loss: 14571678.4522\n",
      "Epoch 5594/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 5595/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1603 - val_loss: 14571678.4522\n",
      "Epoch 5596/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 5597/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0837 - val_loss: 14571678.4522\n",
      "Epoch 5598/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1305 - val_loss: 14571678.4522\n",
      "Epoch 5599/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1513 - val_loss: 14571678.4522\n",
      "Epoch 5600/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 5601/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0563 - val_loss: 14571678.4522\n",
      "Epoch 5602/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0600 - val_loss: 14571678.4522\n",
      "Epoch 5603/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1262 - val_loss: 14571678.4522\n",
      "Epoch 5604/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0865 - val_loss: 14571678.4522\n",
      "Epoch 5605/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0624 - val_loss: 14571678.4522\n",
      "Epoch 5606/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0543 - val_loss: 14571678.4522\n",
      "Epoch 5607/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 5608/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0387 - val_loss: 14571678.4522\n",
      "Epoch 5609/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0527 - val_loss: 14571678.4522\n",
      "Epoch 5610/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 5611/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 5612/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0127 - val_loss: 14571678.4522\n",
      "Epoch 5613/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1467 - val_loss: 14571678.4522\n",
      "Epoch 5614/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0482 - val_loss: 14571678.4522\n",
      "Epoch 5615/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0871 - val_loss: 14571678.4522\n",
      "Epoch 5616/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1400 - val_loss: 14571678.4522\n",
      "Epoch 5617/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1093 - val_loss: 14571678.4522\n",
      "Epoch 5618/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 5619/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 5620/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 5621/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0547 - val_loss: 14571678.4522\n",
      "Epoch 5622/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 5623/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0283 - val_loss: 14571678.4522\n",
      "Epoch 5624/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1358 - val_loss: 14571678.4522\n",
      "Epoch 5625/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0370 - val_loss: 14571678.4522\n",
      "Epoch 5626/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 5627/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1313 - val_loss: 14571678.4522\n",
      "Epoch 5628/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0920 - val_loss: 14571678.4522\n",
      "Epoch 5629/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9837 - val_loss: 14571678.4522\n",
      "Epoch 5630/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 5631/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 5632/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0955 - val_loss: 14571678.4522\n",
      "Epoch 5633/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0440 - val_loss: 14571678.4522\n",
      "Epoch 5634/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1513 - val_loss: 14571678.4522\n",
      "Epoch 5635/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0397 - val_loss: 14571678.4522\n",
      "Epoch 5636/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0825 - val_loss: 14571678.4522\n",
      "Epoch 5637/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0765 - val_loss: 14571678.4522\n",
      "Epoch 5638/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0567 - val_loss: 14571678.4522\n",
      "Epoch 5639/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 5640/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1060 - val_loss: 14571678.4522\n",
      "Epoch 5641/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0825 - val_loss: 14571678.4522\n",
      "Epoch 5642/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 5643/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1393 - val_loss: 14571678.4522\n",
      "Epoch 5644/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1183 - val_loss: 14571678.4522\n",
      "Epoch 5645/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1553 - val_loss: 14571678.4522\n",
      "Epoch 5646/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0473 - val_loss: 14571678.4522\n",
      "Epoch 5647/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 5648/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1497 - val_loss: 14571678.4522\n",
      "Epoch 5649/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0725 - val_loss: 14571678.4522\n",
      "Epoch 5650/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1295 - val_loss: 14571678.4522\n",
      "Epoch 5651/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 5652/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1413 - val_loss: 14571678.4522\n",
      "Epoch 5653/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0728 - val_loss: 14571678.4522\n",
      "Epoch 5654/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0585 - val_loss: 14571678.4522\n",
      "Epoch 5655/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0637 - val_loss: 14571678.4522\n",
      "Epoch 5656/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1208 - val_loss: 14571678.4522\n",
      "Epoch 5657/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 5658/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 5659/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0500 - val_loss: 14571678.4522\n",
      "Epoch 5660/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0858 - val_loss: 14571678.4522\n",
      "Epoch 5661/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 5662/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1577 - val_loss: 14571678.4522\n",
      "Epoch 5663/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0873 - val_loss: 14571678.4522\n",
      "Epoch 5664/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0680 - val_loss: 14571678.4522\n",
      "Epoch 5665/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1195 - val_loss: 14571678.4522\n",
      "Epoch 5666/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0585 - val_loss: 14571678.4522\n",
      "Epoch 5667/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 5668/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 5669/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0902 - val_loss: 14571678.4522\n",
      "Epoch 5670/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 5671/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0453 - val_loss: 14571678.4522\n",
      "Epoch 5672/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1160 - val_loss: 14571678.4522\n",
      "Epoch 5673/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1503 - val_loss: 14571678.4522\n",
      "Epoch 5674/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 5675/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1073 - val_loss: 14571678.4522\n",
      "Epoch 5676/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0852 - val_loss: 14571678.4522\n",
      "Epoch 5677/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1478 - val_loss: 14571678.4522\n",
      "Epoch 5678/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2200 - val_loss: 14571678.4522\n",
      "Epoch 5679/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0515 - val_loss: 14571678.4522\n",
      "Epoch 5680/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1388 - val_loss: 14571678.4522\n",
      "Epoch 5681/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1238 - val_loss: 14571678.4522\n",
      "Epoch 5682/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0233 - val_loss: 14571678.4522\n",
      "Epoch 5683/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0788 - val_loss: 14571678.4522\n",
      "Epoch 5684/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1223 - val_loss: 14571678.4522\n",
      "Epoch 5685/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1319 - val_loss: 14571678.4522\n",
      "Epoch 5686/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 5687/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1517 - val_loss: 14571678.4522\n",
      "Epoch 5688/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1032 - val_loss: 14571678.4522\n",
      "Epoch 5689/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 5690/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 5691/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0882 - val_loss: 14571678.4522\n",
      "Epoch 5692/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1155 - val_loss: 14571678.4522\n",
      "Epoch 5693/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2153 - val_loss: 14571678.4522\n",
      "Epoch 5694/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 5695/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1578 - val_loss: 14571678.4522\n",
      "Epoch 5696/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0178 - val_loss: 14571678.4522\n",
      "Epoch 5697/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 5698/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1613 - val_loss: 14571678.4522\n",
      "Epoch 5699/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1081 - val_loss: 14571678.4522\n",
      "Epoch 5700/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0105 - val_loss: 14571678.4522\n",
      "Epoch 5701/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1028 - val_loss: 14571678.4522\n",
      "Epoch 5702/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 5703/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0312 - val_loss: 14571678.4522\n",
      "Epoch 5704/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 5705/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1783 - val_loss: 14571678.4522\n",
      "Epoch 5706/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1065 - val_loss: 14571678.4522\n",
      "Epoch 5707/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1102 - val_loss: 14571678.4522\n",
      "Epoch 5708/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1953 - val_loss: 14571678.4522\n",
      "Epoch 5709/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 5710/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0510 - val_loss: 14571678.4522\n",
      "Epoch 5711/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 5712/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0900 - val_loss: 14571678.4522\n",
      "Epoch 5713/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 5714/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1907 - val_loss: 14571678.4522\n",
      "Epoch 5715/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1910 - val_loss: 14571678.4522\n",
      "Epoch 5716/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0410 - val_loss: 14571678.4522\n",
      "Epoch 5717/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 5718/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 5719/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 5720/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0733 - val_loss: 14571678.4522\n",
      "Epoch 5721/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1051 - val_loss: 14571678.4522\n",
      "Epoch 5722/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0940 - val_loss: 14571678.4522\n",
      "Epoch 5723/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1297 - val_loss: 14571678.4522\n",
      "Epoch 5724/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 5725/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 5726/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1498 - val_loss: 14571678.4522\n",
      "Epoch 5727/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0327 - val_loss: 14571678.4522\n",
      "Epoch 5728/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0637 - val_loss: 14571678.4522\n",
      "Epoch 5729/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1579 - val_loss: 14571678.4522\n",
      "Epoch 5730/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1193 - val_loss: 14571678.4522\n",
      "Epoch 5731/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 5732/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1485 - val_loss: 14571678.4522\n",
      "Epoch 5733/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 5734/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0140 - val_loss: 14571678.4522\n",
      "Epoch 5735/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0005 - val_loss: 14571678.4522\n",
      "Epoch 5736/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0976 - val_loss: 14571678.4522\n",
      "Epoch 5737/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0570 - val_loss: 14571678.4522\n",
      "Epoch 5738/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1355 - val_loss: 14571678.4522\n",
      "Epoch 5739/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0094 - val_loss: 14571678.4522\n",
      "Epoch 5740/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1143 - val_loss: 14571678.4522\n",
      "Epoch 5741/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 5742/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1628 - val_loss: 14571678.4522\n",
      "Epoch 5743/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1048 - val_loss: 14571678.4522\n",
      "Epoch 5744/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0653 - val_loss: 14571678.4522\n",
      "Epoch 5745/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 5746/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 5747/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1097 - val_loss: 14571678.4522\n",
      "Epoch 5748/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 5749/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1155 - val_loss: 14571678.4522\n",
      "Epoch 5750/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1468 - val_loss: 14571678.4522\n",
      "Epoch 5751/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1819 - val_loss: 14571678.4522\n",
      "Epoch 5752/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 5753/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0347 - val_loss: 14571678.4522\n",
      "Epoch 5754/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1269 - val_loss: 14571678.4522\n",
      "Epoch 5755/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0920 - val_loss: 14571678.4522\n",
      "Epoch 5756/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0602 - val_loss: 14571678.4522\n",
      "Epoch 5757/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 5758/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0688 - val_loss: 14571678.4522\n",
      "Epoch 5759/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1777 - val_loss: 14571678.4522\n",
      "Epoch 5760/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0782 - val_loss: 14571678.4522\n",
      "Epoch 5761/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1630 - val_loss: 14571678.4522\n",
      "Epoch 5762/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0353 - val_loss: 14571678.4522\n",
      "Epoch 5763/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0335 - val_loss: 14571678.4522\n",
      "Epoch 5764/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 5765/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9860 - val_loss: 14571678.4522\n",
      "Epoch 5766/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0985 - val_loss: 14571678.4522\n",
      "Epoch 5767/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1222 - val_loss: 14571678.4522\n",
      "Epoch 5768/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 5769/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0140 - val_loss: 14571678.4522\n",
      "Epoch 5770/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 5771/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 5772/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 5773/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 5774/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0698 - val_loss: 14571678.4522\n",
      "Epoch 5775/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 5776/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 5777/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0512 - val_loss: 14571678.4522\n",
      "Epoch 5778/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0909 - val_loss: 14571678.4522\n",
      "Epoch 5779/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0695 - val_loss: 14571678.4522\n",
      "Epoch 5780/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2367 - val_loss: 14571678.4522\n",
      "Epoch 5781/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1023 - val_loss: 14571678.4522\n",
      "Epoch 5782/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 5783/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0158 - val_loss: 14571678.4522\n",
      "Epoch 5784/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 5785/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 5786/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0970 - val_loss: 14571678.4522\n",
      "Epoch 5787/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 5788/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1018 - val_loss: 14571678.4522\n",
      "Epoch 5789/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1363 - val_loss: 14571678.4522\n",
      "Epoch 5790/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0698 - val_loss: 14571678.4522\n",
      "Epoch 5791/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0392 - val_loss: 14571678.4522\n",
      "Epoch 5792/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 5793/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1575 - val_loss: 14571678.4522\n",
      "Epoch 5794/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 5795/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0247 - val_loss: 14571678.4522\n",
      "Epoch 5796/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1030 - val_loss: 14571678.4522\n",
      "Epoch 5797/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 5798/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1168 - val_loss: 14571678.4522\n",
      "Epoch 5799/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 5800/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 5801/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1200 - val_loss: 14571678.4522\n",
      "Epoch 5802/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0985 - val_loss: 14571678.4522\n",
      "Epoch 5803/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0355 - val_loss: 14571678.4522\n",
      "Epoch 5804/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0448 - val_loss: 14571678.4522\n",
      "Epoch 5805/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 5806/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0615 - val_loss: 14571678.4522\n",
      "Epoch 5807/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0825 - val_loss: 14571678.4522\n",
      "Epoch 5808/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1125 - val_loss: 14571678.4522\n",
      "Epoch 5809/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9868 - val_loss: 14571678.4522\n",
      "Epoch 5810/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 5811/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1843 - val_loss: 14571678.4522\n",
      "Epoch 5812/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0635 - val_loss: 14571678.4522\n",
      "Epoch 5813/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 5814/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0832 - val_loss: 14571678.4522\n",
      "Epoch 5815/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1877 - val_loss: 14571678.4522\n",
      "Epoch 5816/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0550 - val_loss: 14571678.4522\n",
      "Epoch 5817/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0396 - val_loss: 14571678.4522\n",
      "Epoch 5818/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0347 - val_loss: 14571678.4522\n",
      "Epoch 5819/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1215 - val_loss: 14571678.4522\n",
      "Epoch 5820/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1297 - val_loss: 14571678.4522\n",
      "Epoch 5821/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1283 - val_loss: 14571678.4522\n",
      "Epoch 5822/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 5823/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1800 - val_loss: 14571678.4522\n",
      "Epoch 5824/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1597 - val_loss: 14571678.4522\n",
      "Epoch 5825/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0491 - val_loss: 14571678.4522\n",
      "Epoch 5826/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0577 - val_loss: 14571678.4522\n",
      "Epoch 5827/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1008 - val_loss: 14571678.4522\n",
      "Epoch 5828/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1044 - val_loss: 14571678.4522\n",
      "Epoch 5829/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 5830/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1192 - val_loss: 14571678.4522\n",
      "Epoch 5831/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1677 - val_loss: 14571678.4522\n",
      "Epoch 5832/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 5833/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1372 - val_loss: 14571678.4522\n",
      "Epoch 5834/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1583 - val_loss: 14571678.4522\n",
      "Epoch 5835/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0950 - val_loss: 14571678.4522\n",
      "Epoch 5836/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 5837/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1193 - val_loss: 14571678.4522\n",
      "Epoch 5838/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1162 - val_loss: 14571678.4522\n",
      "Epoch 5839/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0492 - val_loss: 14571678.4522\n",
      "Epoch 5840/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0792 - val_loss: 14571678.4522\n",
      "Epoch 5841/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0568 - val_loss: 14571678.4522\n",
      "Epoch 5842/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1178 - val_loss: 14571678.4522\n",
      "Epoch 5843/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 5844/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1135 - val_loss: 14571678.4522\n",
      "Epoch 5845/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1202 - val_loss: 14571678.4522\n",
      "Epoch 5846/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 5847/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1397 - val_loss: 14571678.4522\n",
      "Epoch 5848/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1864 - val_loss: 14571678.4522\n",
      "Epoch 5849/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0792 - val_loss: 14571678.4522\n",
      "Epoch 5850/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1990 - val_loss: 14571678.4522\n",
      "Epoch 5851/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 5852/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 5853/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 5854/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 5855/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1073 - val_loss: 14571678.4522\n",
      "Epoch 5856/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0332 - val_loss: 14571678.4522\n",
      "Epoch 5857/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 5858/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0320 - val_loss: 14571678.4522\n",
      "Epoch 5859/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1090 - val_loss: 14571678.4522\n",
      "Epoch 5860/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0532 - val_loss: 14571678.4522\n",
      "Epoch 5861/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1900 - val_loss: 14571678.4522\n",
      "Epoch 5862/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 5863/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 5864/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0270 - val_loss: 14571678.4522\n",
      "Epoch 5865/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0690 - val_loss: 14571678.4522\n",
      "Epoch 5866/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0597 - val_loss: 14571678.4522\n",
      "Epoch 5867/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0895 - val_loss: 14571678.4522\n",
      "Epoch 5868/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0293 - val_loss: 14571678.4522\n",
      "Epoch 5869/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 5870/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 5871/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1173 - val_loss: 14571678.4522\n",
      "Epoch 5872/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0828 - val_loss: 14571678.4522\n",
      "Epoch 5873/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0220 - val_loss: 14571678.4522\n",
      "Epoch 5874/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 5875/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2008 - val_loss: 14571678.4522\n",
      "Epoch 5876/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 5877/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0137 - val_loss: 14571678.4522\n",
      "Epoch 5878/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 5879/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 5880/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 5881/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1162 - val_loss: 14571678.4522\n",
      "Epoch 5882/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0530 - val_loss: 14571678.4522\n",
      "Epoch 5883/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 5884/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1270 - val_loss: 14571678.4522\n",
      "Epoch 5885/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 5886/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0123 - val_loss: 14571678.4522\n",
      "Epoch 5887/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 5888/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1203 - val_loss: 14571678.4522\n",
      "Epoch 5889/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0066 - val_loss: 14571678.4522\n",
      "Epoch 5890/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 5891/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1073 - val_loss: 14571678.4522\n",
      "Epoch 5892/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0303 - val_loss: 14571678.4522\n",
      "Epoch 5893/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 5894/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 5895/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0817 - val_loss: 14571678.4522\n",
      "Epoch 5896/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1257 - val_loss: 14571678.4522\n",
      "Epoch 5897/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1205 - val_loss: 14571678.4522\n",
      "Epoch 5898/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1073 - val_loss: 14571678.4522\n",
      "Epoch 5899/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0785 - val_loss: 14571678.4522\n",
      "Epoch 5900/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 5901/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 5902/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 5903/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 5904/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 5905/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0578 - val_loss: 14571678.4522\n",
      "Epoch 5906/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 5907/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1300 - val_loss: 14571678.4522\n",
      "Epoch 5908/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0228 - val_loss: 14571678.4522\n",
      "Epoch 5909/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1300 - val_loss: 14571678.4522\n",
      "Epoch 5910/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0600 - val_loss: 14571678.4522\n",
      "Epoch 5911/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0500 - val_loss: 14571678.4522\n",
      "Epoch 5912/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 5913/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1102 - val_loss: 14571678.4522\n",
      "Epoch 5914/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 5915/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0563 - val_loss: 14571678.4522\n",
      "Epoch 5916/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1122 - val_loss: 14571678.4522\n",
      "Epoch 5917/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2638 - val_loss: 14571678.4522\n",
      "Epoch 5918/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1907 - val_loss: 14571678.4522\n",
      "Epoch 5919/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0733 - val_loss: 14571678.4522\n",
      "Epoch 5920/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 5921/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2012 - val_loss: 14571678.4522\n",
      "Epoch 5922/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 5923/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1318 - val_loss: 14571678.4522\n",
      "Epoch 5924/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1247 - val_loss: 14571678.4522\n",
      "Epoch 5925/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 5926/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1673 - val_loss: 14571678.4522\n",
      "Epoch 5927/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1480 - val_loss: 14571678.4522\n",
      "Epoch 5928/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0193 - val_loss: 14571678.4522\n",
      "Epoch 5929/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0762 - val_loss: 14571678.4522\n",
      "Epoch 5930/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1212 - val_loss: 14571678.4522\n",
      "Epoch 5931/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0715 - val_loss: 14571678.4522\n",
      "Epoch 5932/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0242 - val_loss: 14571678.4522\n",
      "Epoch 5933/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1053 - val_loss: 14571678.4522\n",
      "Epoch 5934/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 5935/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0288 - val_loss: 14571678.4522\n",
      "Epoch 5936/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0412 - val_loss: 14571678.4522\n",
      "Epoch 5937/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 5938/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1473 - val_loss: 14571678.4522\n",
      "Epoch 5939/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1052 - val_loss: 14571678.4522\n",
      "Epoch 5940/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1658 - val_loss: 14571678.4522\n",
      "Epoch 5941/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 5942/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1253 - val_loss: 14571678.4522\n",
      "Epoch 5943/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1060 - val_loss: 14571678.4522\n",
      "Epoch 5944/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 5945/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0297 - val_loss: 14571678.4522\n",
      "Epoch 5946/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 5947/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0742 - val_loss: 14571678.4522\n",
      "Epoch 5948/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 5949/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0300 - val_loss: 14571678.4522\n",
      "Epoch 5950/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 5951/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0588 - val_loss: 14571678.4522\n",
      "Epoch 5952/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0348 - val_loss: 14571678.4522\n",
      "Epoch 5953/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0752 - val_loss: 14571678.4522\n",
      "Epoch 5954/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1287 - val_loss: 14571678.4522\n",
      "Epoch 5955/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1030 - val_loss: 14571678.4522\n",
      "Epoch 5956/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 5957/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 5958/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 5959/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0588 - val_loss: 14571678.4522\n",
      "Epoch 5960/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0420 - val_loss: 14571678.4522\n",
      "Epoch 5961/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0955 - val_loss: 14571678.4522\n",
      "Epoch 5962/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 5963/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0562 - val_loss: 14571678.4522\n",
      "Epoch 5964/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0083 - val_loss: 14571678.4522\n",
      "Epoch 5965/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 5966/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0997 - val_loss: 14571678.4522\n",
      "Epoch 5967/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 5968/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1493 - val_loss: 14571678.4522\n",
      "Epoch 5969/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0320 - val_loss: 14571678.4522\n",
      "Epoch 5970/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1204 - val_loss: 14571678.4522\n",
      "Epoch 5971/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0627 - val_loss: 14571678.4522\n",
      "Epoch 5972/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0623 - val_loss: 14571678.4522\n",
      "Epoch 5973/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0628 - val_loss: 14571678.4522\n",
      "Epoch 5974/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 5975/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0665 - val_loss: 14571678.4522\n",
      "Epoch 5976/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 5977/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 5978/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 5979/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1056 - val_loss: 14571678.4522\n",
      "Epoch 5980/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0227 - val_loss: 14571678.4522\n",
      "Epoch 5981/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0382 - val_loss: 14571678.4522\n",
      "Epoch 5982/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 5983/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0685 - val_loss: 14571678.4522\n",
      "Epoch 5984/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0613 - val_loss: 14571678.4522\n",
      "Epoch 5985/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0690 - val_loss: 14571678.4522\n",
      "Epoch 5986/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9781 - val_loss: 14571678.4522\n",
      "Epoch 5987/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0273 - val_loss: 14571678.4522\n",
      "Epoch 5988/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0270 - val_loss: 14571678.4522\n",
      "Epoch 5989/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0717 - val_loss: 14571678.4522\n",
      "Epoch 5990/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 5991/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1307 - val_loss: 14571678.4522\n",
      "Epoch 5992/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0563 - val_loss: 14571678.4522\n",
      "Epoch 5993/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1028 - val_loss: 14571678.4522\n",
      "Epoch 5994/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 5995/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0440 - val_loss: 14571678.4522\n",
      "Epoch 5996/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0170 - val_loss: 14571678.4522\n",
      "Epoch 5997/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1350 - val_loss: 14571678.4522\n",
      "Epoch 5998/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 5999/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1235 - val_loss: 14571678.4522\n",
      "Epoch 6000/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0822 - val_loss: 14571678.4522\n",
      "Epoch 6001/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0490 - val_loss: 14571678.4522\n",
      "Epoch 6002/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0407 - val_loss: 14571678.4522\n",
      "Epoch 6003/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 6004/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1395 - val_loss: 14571678.4522\n",
      "Epoch 6005/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0837 - val_loss: 14571678.4522\n",
      "Epoch 6006/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 6007/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 6008/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0358 - val_loss: 14571678.4522\n",
      "Epoch 6009/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1008 - val_loss: 14571678.4522\n",
      "Epoch 6010/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0340 - val_loss: 14571678.4522\n",
      "Epoch 6011/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 6012/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 6013/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0718 - val_loss: 14571678.4522\n",
      "Epoch 6014/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0639 - val_loss: 14571678.4522\n",
      "Epoch 6015/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0837 - val_loss: 14571678.4522\n",
      "Epoch 6016/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0370 - val_loss: 14571678.4522\n",
      "Epoch 6017/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1183 - val_loss: 14571678.4522\n",
      "Epoch 6018/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1263 - val_loss: 14571678.4522\n",
      "Epoch 6019/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 6020/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0077 - val_loss: 14571678.4522\n",
      "Epoch 6021/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 6022/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 6023/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0878 - val_loss: 14571678.4522\n",
      "Epoch 6024/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0465 - val_loss: 14571678.4522\n",
      "Epoch 6025/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 6026/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1168 - val_loss: 14571678.4522\n",
      "Epoch 6027/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1065 - val_loss: 14571678.4522\n",
      "Epoch 6028/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0487 - val_loss: 14571678.4522\n",
      "Epoch 6029/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1255 - val_loss: 14571678.4522\n",
      "Epoch 6030/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1597 - val_loss: 14571678.4522\n",
      "Epoch 6031/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0757 - val_loss: 14571678.4522\n",
      "Epoch 6032/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0503 - val_loss: 14571678.4522\n",
      "Epoch 6033/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1330 - val_loss: 14571678.4522\n",
      "Epoch 6034/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 6035/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0192 - val_loss: 14571678.4522\n",
      "Epoch 6036/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1225 - val_loss: 14571678.4522\n",
      "Epoch 6037/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0597 - val_loss: 14571678.4522\n",
      "Epoch 6038/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 6039/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0705 - val_loss: 14571678.4522\n",
      "Epoch 6040/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1377 - val_loss: 14571678.4522\n",
      "Epoch 6041/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 6042/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1073 - val_loss: 14571678.4522\n",
      "Epoch 6043/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0945 - val_loss: 14571678.4522\n",
      "Epoch 6044/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1760 - val_loss: 14571678.4522\n",
      "Epoch 6045/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0748 - val_loss: 14571678.4522\n",
      "Epoch 6046/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 6047/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1960 - val_loss: 14571678.4522\n",
      "Epoch 6048/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0528 - val_loss: 14571678.4522\n",
      "Epoch 6049/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0168 - val_loss: 14571678.4522\n",
      "Epoch 6050/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0900 - val_loss: 14571678.4522\n",
      "Epoch 6051/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 6052/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1452 - val_loss: 14571678.4522\n",
      "Epoch 6053/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0553 - val_loss: 14571678.4522\n",
      "Epoch 6054/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2227 - val_loss: 14571678.4522\n",
      "Epoch 6055/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 6056/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0487 - val_loss: 14571678.4522\n",
      "Epoch 6057/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1420 - val_loss: 14571678.4522\n",
      "Epoch 6058/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1907 - val_loss: 14571678.4522\n",
      "Epoch 6059/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 6060/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0678 - val_loss: 14571678.4522\n",
      "Epoch 6061/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 6062/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0613 - val_loss: 14571678.4522\n",
      "Epoch 6063/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0748 - val_loss: 14571678.4522\n",
      "Epoch 6064/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0367 - val_loss: 14571678.4522\n",
      "Epoch 6065/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1472 - val_loss: 14571678.4522\n",
      "Epoch 6066/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 6067/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1142 - val_loss: 14571678.4522\n",
      "Epoch 6068/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1547 - val_loss: 14571678.4522\n",
      "Epoch 6069/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 6070/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1617 - val_loss: 14571678.4522\n",
      "Epoch 6071/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0364 - val_loss: 14571678.4522\n",
      "Epoch 6072/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9662 - val_loss: 14571678.4522\n",
      "Epoch 6073/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0398 - val_loss: 14571678.4522\n",
      "Epoch 6074/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0963 - val_loss: 14571678.4522\n",
      "Epoch 6075/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0602 - val_loss: 14571678.4522\n",
      "Epoch 6076/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 6077/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 6078/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0562 - val_loss: 14571678.4522\n",
      "Epoch 6079/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 6080/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 6081/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0762 - val_loss: 14571678.4522\n",
      "Epoch 6082/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 6083/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9873 - val_loss: 14571678.4522\n",
      "Epoch 6084/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0582 - val_loss: 14571678.4522\n",
      "Epoch 6085/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0178 - val_loss: 14571678.4522\n",
      "Epoch 6086/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1143 - val_loss: 14571678.4522\n",
      "Epoch 6087/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0250 - val_loss: 14571678.4522\n",
      "Epoch 6088/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 6089/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0352 - val_loss: 14571678.4522\n",
      "Epoch 6090/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1148 - val_loss: 14571678.4522\n",
      "Epoch 6091/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0190 - val_loss: 14571678.4522\n",
      "Epoch 6092/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0648 - val_loss: 14571678.4522\n",
      "Epoch 6093/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 6094/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1453 - val_loss: 14571678.4522\n",
      "Epoch 6095/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 6096/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1232 - val_loss: 14571678.4522\n",
      "Epoch 6097/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 6098/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1528 - val_loss: 14571678.4522\n",
      "Epoch 6099/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1140 - val_loss: 14571678.4522\n",
      "Epoch 6100/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1238 - val_loss: 14571678.4522\n",
      "Epoch 6101/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 6102/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 6103/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1167 - val_loss: 14571678.4522\n",
      "Epoch 6104/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 6105/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0943 - val_loss: 14571678.4522\n",
      "Epoch 6106/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0113 - val_loss: 14571678.4522\n",
      "Epoch 6107/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1118 - val_loss: 14571678.4522\n",
      "Epoch 6108/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 6109/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 6110/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1104 - val_loss: 14571678.4522\n",
      "Epoch 6111/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 6112/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 6113/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 6114/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 6115/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 6116/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 6117/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 6118/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 6119/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 6120/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0720 - val_loss: 14571678.4522\n",
      "Epoch 6121/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 6122/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0447 - val_loss: 14571678.4522\n",
      "Epoch 6123/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 6124/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1500 - val_loss: 14571678.4522\n",
      "Epoch 6125/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1372 - val_loss: 14571678.4522\n",
      "Epoch 6126/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0585 - val_loss: 14571678.4522\n",
      "Epoch 6127/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 6128/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1355 - val_loss: 14571678.4522\n",
      "Epoch 6129/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0392 - val_loss: 14571678.4522\n",
      "Epoch 6130/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 6131/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 6132/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0760 - val_loss: 14571678.4522\n",
      "Epoch 6133/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 6134/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 6135/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 6136/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 6137/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9994 - val_loss: 14571678.4522\n",
      "Epoch 6138/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 6139/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1038 - val_loss: 14571678.4522\n",
      "Epoch 6140/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 6141/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1667 - val_loss: 14571678.4522\n",
      "Epoch 6142/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0360 - val_loss: 14571678.4522\n",
      "Epoch 6143/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0527 - val_loss: 14571678.4522\n",
      "Epoch 6144/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1527 - val_loss: 14571678.4522\n",
      "Epoch 6145/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1110 - val_loss: 14571678.4522\n",
      "Epoch 6146/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0497 - val_loss: 14571678.4522\n",
      "Epoch 6147/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0965 - val_loss: 14571678.4522\n",
      "Epoch 6148/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 6149/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1187 - val_loss: 14571678.4522\n",
      "Epoch 6150/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0888 - val_loss: 14571678.4522\n",
      "Epoch 6151/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0742 - val_loss: 14571678.4522\n",
      "Epoch 6152/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0576 - val_loss: 14571678.4522\n",
      "Epoch 6153/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1255 - val_loss: 14571678.4522\n",
      "Epoch 6154/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1335 - val_loss: 14571678.4522\n",
      "Epoch 6155/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1403 - val_loss: 14571678.4522\n",
      "Epoch 6156/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1577 - val_loss: 14571678.4522\n",
      "Epoch 6157/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 6158/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1138 - val_loss: 14571678.4522\n",
      "Epoch 6159/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1125 - val_loss: 14571678.4522\n",
      "Epoch 6160/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0340 - val_loss: 14571678.4522\n",
      "Epoch 6161/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0048 - val_loss: 14571678.4522\n",
      "Epoch 6162/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 6163/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0845 - val_loss: 14571678.4522\n",
      "Epoch 6164/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0822 - val_loss: 14571678.4522\n",
      "Epoch 6165/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0173 - val_loss: 14571678.4522\n",
      "Epoch 6166/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0808 - val_loss: 14571678.4522\n",
      "Epoch 6167/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1933 - val_loss: 14571678.4522\n",
      "Epoch 6168/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0627 - val_loss: 14571678.4522\n",
      "Epoch 6169/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0277 - val_loss: 14571678.4522\n",
      "Epoch 6170/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0940 - val_loss: 14571678.4522\n",
      "Epoch 6171/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 6172/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 6173/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0795 - val_loss: 14571678.4522\n",
      "Epoch 6174/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1533 - val_loss: 14571678.4522\n",
      "Epoch 6175/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 6176/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 6177/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0698 - val_loss: 14571678.4522\n",
      "Epoch 6178/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1167 - val_loss: 14571678.4522\n",
      "Epoch 6179/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 6180/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 6181/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9757 - val_loss: 14571678.4522\n",
      "Epoch 6182/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0970 - val_loss: 14571678.4522\n",
      "Epoch 6183/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1717 - val_loss: 14571678.4522\n",
      "Epoch 6184/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 6185/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 6186/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0403 - val_loss: 14571678.4522\n",
      "Epoch 6187/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 6188/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 6189/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1577 - val_loss: 14571678.4522\n",
      "Epoch 6190/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0715 - val_loss: 14571678.4522\n",
      "Epoch 6191/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0992 - val_loss: 14571678.4522\n",
      "Epoch 6192/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 6193/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1235 - val_loss: 14571678.4522\n",
      "Epoch 6194/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1797 - val_loss: 14571678.4522\n",
      "Epoch 6195/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1457 - val_loss: 14571678.4522\n",
      "Epoch 6196/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 6197/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 6198/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1215 - val_loss: 14571678.4522\n",
      "Epoch 6199/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1323 - val_loss: 14571678.4522\n",
      "Epoch 6200/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1315 - val_loss: 14571678.4522\n",
      "Epoch 6201/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0863 - val_loss: 14571678.4522\n",
      "Epoch 6202/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1542 - val_loss: 14571678.4522\n",
      "Epoch 6203/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1570 - val_loss: 14571678.4522\n",
      "Epoch 6204/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0761 - val_loss: 14571678.4522\n",
      "Epoch 6205/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 6206/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 6207/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 6208/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0705 - val_loss: 14571678.4522\n",
      "Epoch 6209/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 6210/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 6211/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 6212/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 6213/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0970 - val_loss: 14571678.4522\n",
      "Epoch 6214/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1098 - val_loss: 14571678.4522\n",
      "Epoch 6215/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 6216/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1392 - val_loss: 14571678.4522\n",
      "Epoch 6217/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1268 - val_loss: 14571678.4522\n",
      "Epoch 6218/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 6219/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1069 - val_loss: 14571678.4522\n",
      "Epoch 6220/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1963 - val_loss: 14571678.4522\n",
      "Epoch 6221/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0665 - val_loss: 14571678.4522\n",
      "Epoch 6222/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1093 - val_loss: 14571678.4522\n",
      "Epoch 6223/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1036 - val_loss: 14571678.4522\n",
      "Epoch 6224/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0783 - val_loss: 14571678.4522\n",
      "Epoch 6225/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 6226/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0488 - val_loss: 14571678.4522\n",
      "Epoch 6227/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0878 - val_loss: 14571678.4522\n",
      "Epoch 6228/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 6229/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 6230/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9537 - val_loss: 14571678.4522\n",
      "Epoch 6231/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0672 - val_loss: 14571678.4522\n",
      "Epoch 6232/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 6233/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 6234/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0653 - val_loss: 14571678.4522\n",
      "Epoch 6235/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0734 - val_loss: 14571678.4522\n",
      "Epoch 6236/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 6237/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 6238/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 6239/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1223 - val_loss: 14571678.4522\n",
      "Epoch 6240/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 6241/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0453 - val_loss: 14571678.4522\n",
      "Epoch 6242/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0542 - val_loss: 14571678.4522\n",
      "Epoch 6243/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 6244/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1205 - val_loss: 14571678.4522\n",
      "Epoch 6245/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0219 - val_loss: 14571678.4522\n",
      "Epoch 6246/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1460 - val_loss: 14571678.4522\n",
      "Epoch 6247/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0313 - val_loss: 14571678.4522\n",
      "Epoch 6248/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 6249/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1277 - val_loss: 14571678.4522\n",
      "Epoch 6250/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0208 - val_loss: 14571678.4522\n",
      "Epoch 6251/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0337 - val_loss: 14571678.4522\n",
      "Epoch 6252/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1132 - val_loss: 14571678.4522\n",
      "Epoch 6253/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1132 - val_loss: 14571678.4522\n",
      "Epoch 6254/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0453 - val_loss: 14571678.4522\n",
      "Epoch 6255/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9848 - val_loss: 14571678.4522\n",
      "Epoch 6256/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0602 - val_loss: 14571678.4522\n",
      "Epoch 6257/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0383 - val_loss: 14571678.4522\n",
      "Epoch 6258/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 6259/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0087 - val_loss: 14571678.4522\n",
      "Epoch 6260/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 6261/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1523 - val_loss: 14571678.4522\n",
      "Epoch 6262/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0685 - val_loss: 14571678.4522\n",
      "Epoch 6263/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 6264/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9883 - val_loss: 14571678.4522\n",
      "Epoch 6265/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 6266/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0612 - val_loss: 14571678.4522\n",
      "Epoch 6267/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1071 - val_loss: 14571678.4522\n",
      "Epoch 6268/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1833 - val_loss: 14571678.4522\n",
      "Epoch 6269/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1489 - val_loss: 14571678.4522\n",
      "Epoch 6270/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1088 - val_loss: 14571678.4522\n",
      "Epoch 6271/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0875 - val_loss: 14571678.4522\n",
      "Epoch 6272/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1403 - val_loss: 14571678.4522\n",
      "Epoch 6273/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0257 - val_loss: 14571678.4522\n",
      "Epoch 6274/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 6275/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0843 - val_loss: 14571678.4522\n",
      "Epoch 6276/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1253 - val_loss: 14571678.4522\n",
      "Epoch 6277/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 6278/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1062 - val_loss: 14571678.4522\n",
      "Epoch 6279/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530844.9785 - val_loss: 14571678.4522\n",
      "Epoch 6280/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0447 - val_loss: 14571678.4522\n",
      "Epoch 6281/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0383 - val_loss: 14571678.4522\n",
      "Epoch 6282/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1737 - val_loss: 14571678.4522\n",
      "Epoch 6283/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1227 - val_loss: 14571678.4522\n",
      "Epoch 6284/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0533 - val_loss: 14571678.4522\n",
      "Epoch 6285/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1383 - val_loss: 14571678.4522\n",
      "Epoch 6286/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0197 - val_loss: 14571678.4522\n",
      "Epoch 6287/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1448 - val_loss: 14571678.4522\n",
      "Epoch 6288/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 6289/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 6290/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 6291/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 6292/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0608 - val_loss: 14571678.4522\n",
      "Epoch 6293/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1218 - val_loss: 14571678.4522\n",
      "Epoch 6294/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0711 - val_loss: 14571678.4522\n",
      "Epoch 6295/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0167 - val_loss: 14571678.4522\n",
      "Epoch 6296/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0510 - val_loss: 14571678.4522\n",
      "Epoch 6297/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1093 - val_loss: 14571678.4522\n",
      "Epoch 6298/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0325 - val_loss: 14571678.4522\n",
      "Epoch 6299/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0250 - val_loss: 14571678.4522\n",
      "Epoch 6300/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0317 - val_loss: 14571678.4522\n",
      "Epoch 6301/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0846 - val_loss: 14571678.4522\n",
      "Epoch 6302/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0982 - val_loss: 14571678.4522\n",
      "Epoch 6303/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0657 - val_loss: 14571678.4522\n",
      "Epoch 6304/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1403 - val_loss: 14571678.4522\n",
      "Epoch 6305/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1255 - val_loss: 14571678.4522\n",
      "Epoch 6306/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0698 - val_loss: 14571678.4522\n",
      "Epoch 6307/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 6308/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9293 - val_loss: 14571678.4522\n",
      "Epoch 6309/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 6310/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0688 - val_loss: 14571678.4522\n",
      "Epoch 6311/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0950 - val_loss: 14571678.4522\n",
      "Epoch 6312/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9748 - val_loss: 14571678.4522\n",
      "Epoch 6313/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0320 - val_loss: 14571678.4522\n",
      "Epoch 6314/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 6315/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0577 - val_loss: 14571678.4522\n",
      "Epoch 6316/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 6317/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1012 - val_loss: 14571678.4522\n",
      "Epoch 6318/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0992 - val_loss: 14571678.4522\n",
      "Epoch 6319/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1260 - val_loss: 14571678.4522\n",
      "Epoch 6320/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 6321/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1603 - val_loss: 14571678.4522\n",
      "Epoch 6322/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0372 - val_loss: 14571678.4522\n",
      "Epoch 6323/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0728 - val_loss: 14571678.4522\n",
      "Epoch 6324/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0530 - val_loss: 14571678.4522\n",
      "Epoch 6325/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0203 - val_loss: 14571678.4522\n",
      "Epoch 6326/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0757 - val_loss: 14571678.4522\n",
      "Epoch 6327/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1290 - val_loss: 14571678.4522\n",
      "Epoch 6328/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1245 - val_loss: 14571678.4522\n",
      "Epoch 6329/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 6330/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1144 - val_loss: 14571678.4522\n",
      "Epoch 6331/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1625 - val_loss: 14571678.4522\n",
      "Epoch 6332/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 6333/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0213 - val_loss: 14571678.4522\n",
      "Epoch 6334/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1118 - val_loss: 14571678.4522\n",
      "Epoch 6335/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0263 - val_loss: 14571678.4522\n",
      "Epoch 6336/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0553 - val_loss: 14571678.4522\n",
      "Epoch 6337/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0848 - val_loss: 14571678.4522\n",
      "Epoch 6338/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1081 - val_loss: 14571678.4522\n",
      "Epoch 6339/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1260 - val_loss: 14571678.4522\n",
      "Epoch 6340/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0488 - val_loss: 14571678.4522\n",
      "Epoch 6341/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1308 - val_loss: 14571678.4522\n",
      "Epoch 6342/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1370 - val_loss: 14571678.4522\n",
      "Epoch 6343/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 6344/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 6345/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1473 - val_loss: 14571678.4522\n",
      "Epoch 6346/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 6347/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1573 - val_loss: 14571678.4522\n",
      "Epoch 6348/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1173 - val_loss: 14571678.4522\n",
      "Epoch 6349/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0899 - val_loss: 14571678.4522\n",
      "Epoch 6350/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 6351/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 6352/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 6353/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0653 - val_loss: 14571678.4522\n",
      "Epoch 6354/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1513 - val_loss: 14571678.4522\n",
      "Epoch 6355/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0373 - val_loss: 14571678.4522\n",
      "Epoch 6356/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1458 - val_loss: 14571678.4522\n",
      "Epoch 6357/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1285 - val_loss: 14571678.4522\n",
      "Epoch 6358/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0273 - val_loss: 14571678.4522\n",
      "Epoch 6359/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 6360/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1262 - val_loss: 14571678.4522\n",
      "Epoch 6361/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0840 - val_loss: 14571678.4522\n",
      "Epoch 6362/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0331 - val_loss: 14571678.4522\n",
      "Epoch 6363/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0952 - val_loss: 14571678.4522\n",
      "Epoch 6364/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0760 - val_loss: 14571678.4522\n",
      "Epoch 6365/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0027 - val_loss: 14571678.4522\n",
      "Epoch 6366/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 6367/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0325 - val_loss: 14571678.4522\n",
      "Epoch 6368/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0738 - val_loss: 14571678.4522\n",
      "Epoch 6369/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1413 - val_loss: 14571678.4522\n",
      "Epoch 6370/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1108 - val_loss: 14571678.4522\n",
      "Epoch 6371/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 6372/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0843 - val_loss: 14571678.4522\n",
      "Epoch 6373/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 6374/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1465 - val_loss: 14571678.4522\n",
      "Epoch 6375/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1945 - val_loss: 14571678.4522\n",
      "Epoch 6376/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0842 - val_loss: 14571678.4522\n",
      "Epoch 6377/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 6378/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 6379/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1128 - val_loss: 14571678.4522\n",
      "Epoch 6380/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1638 - val_loss: 14571678.4522\n",
      "Epoch 6381/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0618 - val_loss: 14571678.4522\n",
      "Epoch 6382/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 6383/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 6384/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0443 - val_loss: 14571678.4522\n",
      "Epoch 6385/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0263 - val_loss: 14571678.4522\n",
      "Epoch 6386/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 6387/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0455 - val_loss: 14571678.4522\n",
      "Epoch 6388/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1008 - val_loss: 14571678.4522\n",
      "Epoch 6389/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0823 - val_loss: 14571678.4522\n",
      "Epoch 6390/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0497 - val_loss: 14571678.4522\n",
      "Epoch 6391/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1123 - val_loss: 14571678.4522\n",
      "Epoch 6392/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0373 - val_loss: 14571678.4522\n",
      "Epoch 6393/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0542 - val_loss: 14571678.4522\n",
      "Epoch 6394/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 6395/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 6396/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0912 - val_loss: 14571678.4522\n",
      "Epoch 6397/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1608 - val_loss: 14571678.4522\n",
      "Epoch 6398/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0848 - val_loss: 14571678.4522\n",
      "Epoch 6399/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 6400/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 6401/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0817 - val_loss: 14571678.4522\n",
      "Epoch 6402/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1972 - val_loss: 14571678.4522\n",
      "Epoch 6403/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 6404/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0517 - val_loss: 14571678.4522\n",
      "Epoch 6405/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0487 - val_loss: 14571678.4522\n",
      "Epoch 6406/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0594 - val_loss: 14571678.4522\n",
      "Epoch 6407/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1499 - val_loss: 14571678.4522\n",
      "Epoch 6408/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1645 - val_loss: 14571678.4522\n",
      "Epoch 6409/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 6410/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 6411/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1187 - val_loss: 14571678.4522\n",
      "Epoch 6412/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1185 - val_loss: 14571678.4522\n",
      "Epoch 6413/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 6414/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 6415/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0740 - val_loss: 14571678.4522\n",
      "Epoch 6416/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 6417/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 6418/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0510 - val_loss: 14571678.4522\n",
      "Epoch 6419/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1184 - val_loss: 14571678.4522\n",
      "Epoch 6420/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0233 - val_loss: 14571678.4522\n",
      "Epoch 6421/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 6422/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0747 - val_loss: 14571678.4522\n",
      "Epoch 6423/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1227 - val_loss: 14571678.4522\n",
      "Epoch 6424/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 6425/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0100 - val_loss: 14571678.4522\n",
      "Epoch 6426/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1470 - val_loss: 14571678.4522\n",
      "Epoch 6427/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 6428/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1068 - val_loss: 14571678.4522\n",
      "Epoch 6429/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0987 - val_loss: 14571678.4522\n",
      "Epoch 6430/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 6431/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 6432/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 6433/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 6434/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0281 - val_loss: 14571678.4522\n",
      "Epoch 6435/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1753 - val_loss: 14571678.4522\n",
      "Epoch 6436/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 6437/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1068 - val_loss: 14571678.4522\n",
      "Epoch 6438/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1500 - val_loss: 14571678.4522\n",
      "Epoch 6439/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 6440/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0777 - val_loss: 14571678.4522\n",
      "Epoch 6441/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1380 - val_loss: 14571678.4522\n",
      "Epoch 6442/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0532 - val_loss: 14571678.4522\n",
      "Epoch 6443/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0757 - val_loss: 14571678.4522\n",
      "Epoch 6444/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0855 - val_loss: 14571678.4522\n",
      "Epoch 6445/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 6446/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 6447/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0043 - val_loss: 14571678.4522\n",
      "Epoch 6448/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1206 - val_loss: 14571678.4522\n",
      "Epoch 6449/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0432 - val_loss: 14571678.4522\n",
      "Epoch 6450/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 6451/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 6452/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1135 - val_loss: 14571678.4522\n",
      "Epoch 6453/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1603 - val_loss: 14571678.4522\n",
      "Epoch 6454/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0563 - val_loss: 14571678.4522\n",
      "Epoch 6455/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1605 - val_loss: 14571678.4522\n",
      "Epoch 6456/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 6457/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1172 - val_loss: 14571678.4522\n",
      "Epoch 6458/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1075 - val_loss: 14571678.4522\n",
      "Epoch 6459/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 6460/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0495 - val_loss: 14571678.4522\n",
      "Epoch 6461/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 6462/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 6463/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 6464/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 6465/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 6466/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1397 - val_loss: 14571678.4522\n",
      "Epoch 6467/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0815 - val_loss: 14571678.4522\n",
      "Epoch 6468/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0815 - val_loss: 14571678.4522\n",
      "Epoch 6469/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9730 - val_loss: 14571678.4522\n",
      "Epoch 6470/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0603 - val_loss: 14571678.4522\n",
      "Epoch 6471/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0638 - val_loss: 14571678.4522\n",
      "Epoch 6472/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1105 - val_loss: 14571678.4522\n",
      "Epoch 6473/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1590 - val_loss: 14571678.4522\n",
      "Epoch 6474/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0885 - val_loss: 14571678.4522\n",
      "Epoch 6475/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1970 - val_loss: 14571678.4522\n",
      "Epoch 6476/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 6477/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0548 - val_loss: 14571678.4522\n",
      "Epoch 6478/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1160 - val_loss: 14571678.4522\n",
      "Epoch 6479/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0676 - val_loss: 14571678.4522\n",
      "Epoch 6480/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 6481/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0377 - val_loss: 14571678.4522\n",
      "Epoch 6482/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0717 - val_loss: 14571678.4522\n",
      "Epoch 6483/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0928 - val_loss: 14571678.4522\n",
      "Epoch 6484/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1343 - val_loss: 14571678.4522\n",
      "Epoch 6485/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1327 - val_loss: 14571678.4522\n",
      "Epoch 6486/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1579 - val_loss: 14571678.4522\n",
      "Epoch 6487/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 6488/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0137 - val_loss: 14571678.4522\n",
      "Epoch 6489/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 6490/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0493 - val_loss: 14571678.4522\n",
      "Epoch 6491/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0632 - val_loss: 14571678.4522\n",
      "Epoch 6492/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1045 - val_loss: 14571678.4522\n",
      "Epoch 6493/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 6494/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1370 - val_loss: 14571678.4522\n",
      "Epoch 6495/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1762 - val_loss: 14571678.4522\n",
      "Epoch 6496/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1297 - val_loss: 14571678.4522\n",
      "Epoch 6497/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 6498/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 6499/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 6500/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0328 - val_loss: 14571678.4522\n",
      "Epoch 6501/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 6502/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 6503/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 6504/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1060 - val_loss: 14571678.4522\n",
      "Epoch 6505/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1292 - val_loss: 14571678.4522\n",
      "Epoch 6506/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 6507/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 6508/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 6509/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0148 - val_loss: 14571678.4522\n",
      "Epoch 6510/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0525 - val_loss: 14571678.4522\n",
      "Epoch 6511/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1376 - val_loss: 14571678.4522\n",
      "Epoch 6512/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 6513/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 6514/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0580 - val_loss: 14571678.4522\n",
      "Epoch 6515/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0452 - val_loss: 14571678.4522\n",
      "Epoch 6516/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 6517/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0702 - val_loss: 14571678.4522\n",
      "Epoch 6518/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1993 - val_loss: 14571678.4522\n",
      "Epoch 6519/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0837 - val_loss: 14571678.4522\n",
      "Epoch 6520/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 6521/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 6522/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 6523/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1335 - val_loss: 14571678.4522\n",
      "Epoch 6524/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0060 - val_loss: 14571678.4522\n",
      "Epoch 6525/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0663 - val_loss: 14571678.4522\n",
      "Epoch 6526/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0093 - val_loss: 14571678.4522\n",
      "Epoch 6527/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1628 - val_loss: 14571678.4522\n",
      "Epoch 6528/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 6529/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0532 - val_loss: 14571678.4522\n",
      "Epoch 6530/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0678 - val_loss: 14571678.4522\n",
      "Epoch 6531/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0965 - val_loss: 14571678.4522\n",
      "Epoch 6532/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 6533/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1377 - val_loss: 14571678.4522\n",
      "Epoch 6534/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0632 - val_loss: 14571678.4522\n",
      "Epoch 6535/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 6536/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1572 - val_loss: 14571678.4522\n",
      "Epoch 6537/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 6538/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0670 - val_loss: 14571678.4522\n",
      "Epoch 6539/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0637 - val_loss: 14571678.4522\n",
      "Epoch 6540/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 6541/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0843 - val_loss: 14571678.4522\n",
      "Epoch 6542/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 6543/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 6544/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 6545/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 6546/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1155 - val_loss: 14571678.4522\n",
      "Epoch 6547/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0740 - val_loss: 14571678.4522\n",
      "Epoch 6548/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1232 - val_loss: 14571678.4522\n",
      "Epoch 6549/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0698 - val_loss: 14571678.4522\n",
      "Epoch 6550/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1208 - val_loss: 14571678.4522\n",
      "Epoch 6551/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1660 - val_loss: 14571678.4522\n",
      "Epoch 6552/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 6553/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0068 - val_loss: 14571678.4522\n",
      "Epoch 6554/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 6555/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1079 - val_loss: 14571678.4522\n",
      "Epoch 6556/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0649 - val_loss: 14571678.4522\n",
      "Epoch 6557/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1082 - val_loss: 14571678.4522\n",
      "Epoch 6558/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 6559/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1672 - val_loss: 14571678.4522\n",
      "Epoch 6560/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 6561/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0885 - val_loss: 14571678.4522\n",
      "Epoch 6562/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0427 - val_loss: 14571678.4522\n",
      "Epoch 6563/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1270 - val_loss: 14571678.4522\n",
      "Epoch 6564/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0920 - val_loss: 14571678.4522\n",
      "Epoch 6565/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1137 - val_loss: 14571678.4522\n",
      "Epoch 6566/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0902 - val_loss: 14571678.4522\n",
      "Epoch 6567/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 6568/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1380 - val_loss: 14571678.4522\n",
      "Epoch 6569/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1507 - val_loss: 14571678.4522\n",
      "Epoch 6570/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 6571/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0163 - val_loss: 14571678.4522\n",
      "Epoch 6572/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1333 - val_loss: 14571678.4522\n",
      "Epoch 6573/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0835 - val_loss: 14571678.4522\n",
      "Epoch 6574/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0950 - val_loss: 14571678.4522\n",
      "Epoch 6575/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1143 - val_loss: 14571678.4522\n",
      "Epoch 6576/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 6577/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0237 - val_loss: 14571678.4522\n",
      "Epoch 6578/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2000 - val_loss: 14571678.4522\n",
      "Epoch 6579/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0964 - val_loss: 14571678.4522\n",
      "Epoch 6580/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 6581/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1012 - val_loss: 14571678.4522\n",
      "Epoch 6582/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0553 - val_loss: 14571678.4522\n",
      "Epoch 6583/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 6584/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 6585/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0567 - val_loss: 14571678.4522\n",
      "Epoch 6586/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0757 - val_loss: 14571678.4522\n",
      "Epoch 6587/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1202 - val_loss: 14571678.4522\n",
      "Epoch 6588/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1440 - val_loss: 14571678.4522\n",
      "Epoch 6589/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0837 - val_loss: 14571678.4522\n",
      "Epoch 6590/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0735 - val_loss: 14571678.4522\n",
      "Epoch 6591/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0658 - val_loss: 14571678.4522\n",
      "Epoch 6592/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 6593/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 6594/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 6595/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1567 - val_loss: 14571678.4522\n",
      "Epoch 6596/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 6597/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0966 - val_loss: 14571678.4522\n",
      "Epoch 6598/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 6599/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 6600/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1590 - val_loss: 14571678.4522\n",
      "Epoch 6601/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 6602/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 6603/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1617 - val_loss: 14571678.4522\n",
      "Epoch 6604/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0745 - val_loss: 14571678.4522\n",
      "Epoch 6605/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 6606/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0732 - val_loss: 14571678.4522\n",
      "Epoch 6607/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 6608/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0762 - val_loss: 14571678.4522\n",
      "Epoch 6609/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 6610/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0217 - val_loss: 14571678.4522\n",
      "Epoch 6611/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0718 - val_loss: 14571678.4522\n",
      "Epoch 6612/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0399 - val_loss: 14571678.4522\n",
      "Epoch 6613/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0925 - val_loss: 14571678.4522\n",
      "Epoch 6614/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0720 - val_loss: 14571678.4522\n",
      "Epoch 6615/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1577 - val_loss: 14571678.4522\n",
      "Epoch 6616/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1095 - val_loss: 14571678.4522\n",
      "Epoch 6617/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 6618/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0558 - val_loss: 14571678.4522\n",
      "Epoch 6619/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0213 - val_loss: 14571678.4522\n",
      "Epoch 6620/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0844 - val_loss: 14571678.4522\n",
      "Epoch 6621/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0310 - val_loss: 14571678.4522\n",
      "Epoch 6622/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0915 - val_loss: 14571678.4522\n",
      "Epoch 6623/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 6624/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 6625/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 6626/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1500 - val_loss: 14571678.4522\n",
      "Epoch 6627/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0130 - val_loss: 14571678.4522\n",
      "Epoch 6628/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0530 - val_loss: 14571678.4522\n",
      "Epoch 6629/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0567 - val_loss: 14571678.4522\n",
      "Epoch 6630/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 6631/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0585 - val_loss: 14571678.4522\n",
      "Epoch 6632/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1238 - val_loss: 14571678.4522\n",
      "Epoch 6633/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0648 - val_loss: 14571678.4522\n",
      "Epoch 6634/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0934 - val_loss: 14571678.4522\n",
      "Epoch 6635/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0313 - val_loss: 14571678.4522\n",
      "Epoch 6636/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 6637/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1270 - val_loss: 14571678.4522\n",
      "Epoch 6638/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0485 - val_loss: 14571678.4522\n",
      "Epoch 6639/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 6640/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0010 - val_loss: 14571678.4522\n",
      "Epoch 6641/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0745 - val_loss: 14571678.4522\n",
      "Epoch 6642/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 6643/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 6644/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0030 - val_loss: 14571678.4522\n",
      "Epoch 6645/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 6646/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 6647/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0962 - val_loss: 14571678.4522\n",
      "Epoch 6648/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0997 - val_loss: 14571678.4522\n",
      "Epoch 6649/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0367 - val_loss: 14571678.4522\n",
      "Epoch 6650/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1347 - val_loss: 14571678.4522\n",
      "Epoch 6651/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9918 - val_loss: 14571678.4522\n",
      "Epoch 6652/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1653 - val_loss: 14571678.4522\n",
      "Epoch 6653/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0623 - val_loss: 14571678.4522\n",
      "Epoch 6654/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 6655/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1289 - val_loss: 14571678.4522\n",
      "Epoch 6656/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 6657/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 6658/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1677 - val_loss: 14571678.4522\n",
      "Epoch 6659/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 6660/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1317 - val_loss: 14571678.4522\n",
      "Epoch 6661/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1115 - val_loss: 14571678.4522\n",
      "Epoch 6662/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1090 - val_loss: 14571678.4522\n",
      "Epoch 6663/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0837 - val_loss: 14571678.4522\n",
      "Epoch 6664/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9772 - val_loss: 14571678.4522\n",
      "Epoch 6665/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1373 - val_loss: 14571678.4522\n",
      "Epoch 6666/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 6667/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 6668/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1533 - val_loss: 14571678.4522\n",
      "Epoch 6669/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1707 - val_loss: 14571678.4522\n",
      "Epoch 6670/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 6671/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1160 - val_loss: 14571678.4522\n",
      "Epoch 6672/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0812 - val_loss: 14571678.4522\n",
      "Epoch 6673/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1113 - val_loss: 14571678.4522\n",
      "Epoch 6674/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1202 - val_loss: 14571678.4522\n",
      "Epoch 6675/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1145 - val_loss: 14571678.4522\n",
      "Epoch 6676/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 6677/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9482 - val_loss: 14571678.4522\n",
      "Epoch 6678/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 6679/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0920 - val_loss: 14571678.4522\n",
      "Epoch 6680/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 6681/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0533 - val_loss: 14571678.4522\n",
      "Epoch 6682/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0774 - val_loss: 14571678.4522\n",
      "Epoch 6683/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0742 - val_loss: 14571678.4522\n",
      "Epoch 6684/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1188 - val_loss: 14571678.4522\n",
      "Epoch 6685/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1190 - val_loss: 14571678.4522\n",
      "Epoch 6686/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1058 - val_loss: 14571678.4522\n",
      "Epoch 6687/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 6688/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1213 - val_loss: 14571678.4522\n",
      "Epoch 6689/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0188 - val_loss: 14571678.4522\n",
      "Epoch 6690/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 6691/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 6692/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0878 - val_loss: 14571678.4522\n",
      "Epoch 6693/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0712 - val_loss: 14571678.4522\n",
      "Epoch 6694/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 6695/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1357 - val_loss: 14571678.4522\n",
      "Epoch 6696/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 6697/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 6698/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0428 - val_loss: 14571678.4522\n",
      "Epoch 6699/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1438 - val_loss: 14571678.4522\n",
      "Epoch 6700/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0427 - val_loss: 14571678.4522\n",
      "Epoch 6701/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1097 - val_loss: 14571678.4522\n",
      "Epoch 6702/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 6703/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1277 - val_loss: 14571678.4522\n",
      "Epoch 6704/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 6705/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 6706/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1432 - val_loss: 14571678.4522\n",
      "Epoch 6707/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0740 - val_loss: 14571678.4522\n",
      "Epoch 6708/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0697 - val_loss: 14571678.4522\n",
      "Epoch 6709/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0993 - val_loss: 14571678.4522\n",
      "Epoch 6710/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1903 - val_loss: 14571678.4522\n",
      "Epoch 6711/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 6712/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 6713/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 6714/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 6715/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1313 - val_loss: 14571678.4522\n",
      "Epoch 6716/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1430 - val_loss: 14571678.4522\n",
      "Epoch 6717/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0920 - val_loss: 14571678.4522\n",
      "Epoch 6718/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1110 - val_loss: 14571678.4522\n",
      "Epoch 6719/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1717 - val_loss: 14571678.4522\n",
      "Epoch 6720/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1875 - val_loss: 14571678.4522\n",
      "Epoch 6721/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0033 - val_loss: 14571678.4522\n",
      "Epoch 6722/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1420 - val_loss: 14571678.4522\n",
      "Epoch 6723/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1408 - val_loss: 14571678.4522\n",
      "Epoch 6724/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0425 - val_loss: 14571678.4522\n",
      "Epoch 6725/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0705 - val_loss: 14571678.4522\n",
      "Epoch 6726/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 6727/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0554 - val_loss: 14571678.4522\n",
      "Epoch 6728/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 6729/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1125 - val_loss: 14571678.4522\n",
      "Epoch 6730/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1547 - val_loss: 14571678.4522\n",
      "Epoch 6731/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1477 - val_loss: 14571678.4522\n",
      "Epoch 6732/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0993 - val_loss: 14571678.4522\n",
      "Epoch 6733/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 6734/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 6735/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0627 - val_loss: 14571678.4522\n",
      "Epoch 6736/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0665 - val_loss: 14571678.4522\n",
      "Epoch 6737/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9430 - val_loss: 14571678.4522\n",
      "Epoch 6738/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 6739/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 6740/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1195 - val_loss: 14571678.4522\n",
      "Epoch 6741/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1403 - val_loss: 14571678.4522\n",
      "Epoch 6742/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0812 - val_loss: 14571678.4522\n",
      "Epoch 6743/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0413 - val_loss: 14571678.4522\n",
      "Epoch 6744/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1260 - val_loss: 14571678.4522\n",
      "Epoch 6745/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0257 - val_loss: 14571678.4522\n",
      "Epoch 6746/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 6747/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 6748/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9803 - val_loss: 14571678.4522\n",
      "Epoch 6749/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 6750/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 6751/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1110 - val_loss: 14571678.4522\n",
      "Epoch 6752/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1580 - val_loss: 14571678.4522\n",
      "Epoch 6753/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.0613 - val_loss: 14571678.4522\n",
      "Epoch 6754/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1272 - val_loss: 14571678.4522\n",
      "Epoch 6755/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0492 - val_loss: 14571678.4522\n",
      "Epoch 6756/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1510 - val_loss: 14571678.4522\n",
      "Epoch 6757/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1437 - val_loss: 14571678.4522\n",
      "Epoch 6758/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0902 - val_loss: 14571678.4522\n",
      "Epoch 6759/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0978 - val_loss: 14571678.4522\n",
      "Epoch 6760/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1405 - val_loss: 14571678.4522\n",
      "Epoch 6761/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1347 - val_loss: 14571678.4522\n",
      "Epoch 6762/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1116 - val_loss: 14571678.4522\n",
      "Epoch 6763/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0757 - val_loss: 14571678.4522\n",
      "Epoch 6764/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1308 - val_loss: 14571678.4522\n",
      "Epoch 6765/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 6766/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0088 - val_loss: 14571678.4522\n",
      "Epoch 6767/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 6768/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 6769/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1072 - val_loss: 14571678.4522\n",
      "Epoch 6770/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0908 - val_loss: 14571678.4522\n",
      "Epoch 6771/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1313 - val_loss: 14571678.4522\n",
      "Epoch 6772/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 6773/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0618 - val_loss: 14571678.4522\n",
      "Epoch 6774/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0985 - val_loss: 14571678.4522\n",
      "Epoch 6775/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 6776/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0515 - val_loss: 14571678.4522\n",
      "Epoch 6777/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 6778/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 6779/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1128 - val_loss: 14571678.4522\n",
      "Epoch 6780/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1600 - val_loss: 14571678.4522\n",
      "Epoch 6781/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 6782/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9573 - val_loss: 14571678.4522\n",
      "Epoch 6783/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1282 - val_loss: 14571678.4522\n",
      "Epoch 6784/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 6785/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0733 - val_loss: 14571678.4522\n",
      "Epoch 6786/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0577 - val_loss: 14571678.4522\n",
      "Epoch 6787/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0628 - val_loss: 14571678.4522\n",
      "Epoch 6788/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 6789/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0468 - val_loss: 14571678.4522\n",
      "Epoch 6790/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 6791/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1693 - val_loss: 14571678.4522\n",
      "Epoch 6792/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 6793/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 6794/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1627 - val_loss: 14571678.4522\n",
      "Epoch 6795/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0397 - val_loss: 14571678.4522\n",
      "Epoch 6796/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0172 - val_loss: 14571678.4522\n",
      "Epoch 6797/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1370 - val_loss: 14571678.4522\n",
      "Epoch 6798/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1060 - val_loss: 14571678.4522\n",
      "Epoch 6799/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0832 - val_loss: 14571678.4522\n",
      "Epoch 6800/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1290 - val_loss: 14571678.4522\n",
      "Epoch 6801/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1112 - val_loss: 14571678.4522\n",
      "Epoch 6802/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0958 - val_loss: 14571678.4522\n",
      "Epoch 6803/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 6804/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 6805/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0858 - val_loss: 14571678.4522\n",
      "Epoch 6806/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1257 - val_loss: 14571678.4522\n",
      "Epoch 6807/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 6808/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 6809/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0525 - val_loss: 14571678.4522\n",
      "Epoch 6810/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1470 - val_loss: 14571678.4522\n",
      "Epoch 6811/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9887 - val_loss: 14571678.4522\n",
      "Epoch 6812/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 6813/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2005 - val_loss: 14571678.4522\n",
      "Epoch 6814/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 6815/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1435 - val_loss: 14571678.4522\n",
      "Epoch 6816/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1046 - val_loss: 14571678.4522\n",
      "Epoch 6817/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0528 - val_loss: 14571678.4522\n",
      "Epoch 6818/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0865 - val_loss: 14571678.4522\n",
      "Epoch 6819/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0040 - val_loss: 14571678.4522\n",
      "Epoch 6820/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1403 - val_loss: 14571678.4522\n",
      "Epoch 6821/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1437 - val_loss: 14571678.4522\n",
      "Epoch 6822/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1095 - val_loss: 14571678.4522\n",
      "Epoch 6823/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2183 - val_loss: 14571678.4522\n",
      "Epoch 6824/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1138 - val_loss: 14571678.4522\n",
      "Epoch 6825/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1577 - val_loss: 14571678.4522\n",
      "Epoch 6826/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1275 - val_loss: 14571678.4522\n",
      "Epoch 6827/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0188 - val_loss: 14571678.4522\n",
      "Epoch 6828/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0845 - val_loss: 14571678.4522\n",
      "Epoch 6829/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 6830/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1308 - val_loss: 14571678.4522\n",
      "Epoch 6831/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0463 - val_loss: 14571678.4522\n",
      "Epoch 6832/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0527 - val_loss: 14571678.4522\n",
      "Epoch 6833/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1312 - val_loss: 14571678.4522\n",
      "Epoch 6834/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 6835/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0832 - val_loss: 14571678.4522\n",
      "Epoch 6836/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0855 - val_loss: 14571678.4522\n",
      "Epoch 6837/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0657 - val_loss: 14571678.4522\n",
      "Epoch 6838/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1573 - val_loss: 14571678.4522\n",
      "Epoch 6839/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 6840/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1447 - val_loss: 14571678.4522\n",
      "Epoch 6841/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0620 - val_loss: 14571678.4522\n",
      "Epoch 6842/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0275 - val_loss: 14571678.4522\n",
      "Epoch 6843/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1305 - val_loss: 14571678.4522\n",
      "Epoch 6844/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 6845/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0630 - val_loss: 14571678.4522\n",
      "Epoch 6846/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0470 - val_loss: 14571678.4522\n",
      "Epoch 6847/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0402 - val_loss: 14571678.4522\n",
      "Epoch 6848/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 6849/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0717 - val_loss: 14571678.4522\n",
      "Epoch 6850/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 6851/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1268 - val_loss: 14571678.4522\n",
      "Epoch 6852/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1624 - val_loss: 14571678.4522\n",
      "Epoch 6853/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0293 - val_loss: 14571678.4522\n",
      "Epoch 6854/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 6855/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 6856/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 6857/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 6858/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0450 - val_loss: 14571678.4522\n",
      "Epoch 6859/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1408 - val_loss: 14571678.4522\n",
      "Epoch 6860/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 6861/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0380 - val_loss: 14571678.4522\n",
      "Epoch 6862/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 6863/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1443 - val_loss: 14571678.4522\n",
      "Epoch 6864/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1108 - val_loss: 14571678.4522\n",
      "Epoch 6865/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0344 - val_loss: 14571678.4522\n",
      "Epoch 6866/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1455 - val_loss: 14571678.4522\n",
      "Epoch 6867/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 6868/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0512 - val_loss: 14571678.4522\n",
      "Epoch 6869/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 6870/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1930 - val_loss: 14571678.4522\n",
      "Epoch 6871/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0275 - val_loss: 14571678.4522\n",
      "Epoch 6872/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 6873/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1200 - val_loss: 14571678.4522\n",
      "Epoch 6874/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0212 - val_loss: 14571678.4522\n",
      "Epoch 6875/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0798 - val_loss: 14571678.4522\n",
      "Epoch 6876/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1663 - val_loss: 14571678.4522\n",
      "Epoch 6877/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0429 - val_loss: 14571678.4522\n",
      "Epoch 6878/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 6879/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1855 - val_loss: 14571678.4522\n",
      "Epoch 6880/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0467 - val_loss: 14571678.4522\n",
      "Epoch 6881/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1190 - val_loss: 14571678.4522\n",
      "Epoch 6882/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1585 - val_loss: 14571678.4522\n",
      "Epoch 6883/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0528 - val_loss: 14571678.4522\n",
      "Epoch 6884/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 6885/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1560 - val_loss: 14571678.4522\n",
      "Epoch 6886/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.0337 - val_loss: 14571678.4522\n",
      "Epoch 6887/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 6888/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0735 - val_loss: 14571678.4522\n",
      "Epoch 6889/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1113 - val_loss: 14571678.4522\n",
      "Epoch 6890/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0420 - val_loss: 14571678.4522\n",
      "Epoch 6891/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1980 - val_loss: 14571678.4522\n",
      "Epoch 6892/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 6893/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1333 - val_loss: 14571678.4522\n",
      "Epoch 6894/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 6895/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1467 - val_loss: 14571678.4522\n",
      "Epoch 6896/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0837 - val_loss: 14571678.4522\n",
      "Epoch 6897/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0603 - val_loss: 14571678.4522\n",
      "Epoch 6898/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1148 - val_loss: 14571678.4522\n",
      "Epoch 6899/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0718 - val_loss: 14571678.4522\n",
      "Epoch 6900/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1055 - val_loss: 14571678.4522\n",
      "Epoch 6901/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 6902/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9823 - val_loss: 14571678.4522\n",
      "Epoch 6903/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 6904/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0095 - val_loss: 14571678.4522\n",
      "Epoch 6905/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0230 - val_loss: 14571678.4522\n",
      "Epoch 6906/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1765 - val_loss: 14571678.4522\n",
      "Epoch 6907/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0982 - val_loss: 14571678.4522\n",
      "Epoch 6908/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1253 - val_loss: 14571678.4522\n",
      "Epoch 6909/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1188 - val_loss: 14571678.4522\n",
      "Epoch 6910/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 6911/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1393 - val_loss: 14571678.4522\n",
      "Epoch 6912/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 6913/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1363 - val_loss: 14571678.4522\n",
      "Epoch 6914/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0598 - val_loss: 14571678.4522\n",
      "Epoch 6915/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 6916/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1348 - val_loss: 14571678.4522\n",
      "Epoch 6917/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0308 - val_loss: 14571678.4522\n",
      "Epoch 6918/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1025 - val_loss: 14571678.4522\n",
      "Epoch 6919/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0443 - val_loss: 14571678.4522\n",
      "Epoch 6920/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0670 - val_loss: 14571678.4522\n",
      "Epoch 6921/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1060 - val_loss: 14571678.4522\n",
      "Epoch 6922/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0777 - val_loss: 14571678.4522\n",
      "Epoch 6923/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 6924/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1792 - val_loss: 14571678.4522\n",
      "Epoch 6925/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9610 - val_loss: 14571678.4522\n",
      "Epoch 6926/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 6927/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0342 - val_loss: 14571678.4522\n",
      "Epoch 6928/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0871 - val_loss: 14571678.4522\n",
      "Epoch 6929/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1417 - val_loss: 14571678.4522\n",
      "Epoch 6930/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 6931/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0433 - val_loss: 14571678.4522\n",
      "Epoch 6932/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 6933/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0994 - val_loss: 14571678.4522\n",
      "Epoch 6934/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1205 - val_loss: 14571678.4522\n",
      "Epoch 6935/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0233 - val_loss: 14571678.4522\n",
      "Epoch 6936/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1373 - val_loss: 14571678.4522\n",
      "Epoch 6937/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1775 - val_loss: 14571678.4522\n",
      "Epoch 6938/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 6939/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 6940/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 6941/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1658 - val_loss: 14571678.4522\n",
      "Epoch 6942/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1193 - val_loss: 14571678.4522\n",
      "Epoch 6943/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0330 - val_loss: 14571678.4522\n",
      "Epoch 6944/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0874 - val_loss: 14571678.4522\n",
      "Epoch 6945/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1498 - val_loss: 14571678.4522\n",
      "Epoch 6946/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0673 - val_loss: 14571678.4522\n",
      "Epoch 6947/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0093 - val_loss: 14571678.4522\n",
      "Epoch 6948/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0205 - val_loss: 14571678.4522\n",
      "Epoch 6949/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1187 - val_loss: 14571678.4522\n",
      "Epoch 6950/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1685 - val_loss: 14571678.4522\n",
      "Epoch 6951/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0873 - val_loss: 14571678.4522\n",
      "Epoch 6952/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1572 - val_loss: 14571678.4522\n",
      "Epoch 6953/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0220 - val_loss: 14571678.4522\n",
      "Epoch 6954/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0273 - val_loss: 14571678.4522\n",
      "Epoch 6955/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1119 - val_loss: 14571678.4522\n",
      "Epoch 6956/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1887 - val_loss: 14571678.4522\n",
      "Epoch 6957/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1260 - val_loss: 14571678.4522\n",
      "Epoch 6958/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0831 - val_loss: 14571678.4522\n",
      "Epoch 6959/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1090 - val_loss: 14571678.4522\n",
      "Epoch 6960/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0413 - val_loss: 14571678.4522\n",
      "Epoch 6961/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1805 - val_loss: 14571678.4522\n",
      "Epoch 6962/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 6963/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 6964/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 6965/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0443 - val_loss: 14571678.4522\n",
      "Epoch 6966/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0548 - val_loss: 14571678.4522\n",
      "Epoch 6967/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1247 - val_loss: 14571678.4522\n",
      "Epoch 6968/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 6969/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 6970/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1192 - val_loss: 14571678.4522\n",
      "Epoch 6971/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0865 - val_loss: 14571678.4522\n",
      "Epoch 6972/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 6973/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1113 - val_loss: 14571678.4522\n",
      "Epoch 6974/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1422 - val_loss: 14571678.4522\n",
      "Epoch 6975/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1030 - val_loss: 14571678.4522\n",
      "Epoch 6976/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0658 - val_loss: 14571678.4522\n",
      "Epoch 6977/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 6978/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0470 - val_loss: 14571678.4522\n",
      "Epoch 6979/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 6980/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0031 - val_loss: 14571678.4522\n",
      "Epoch 6981/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0533 - val_loss: 14571678.4522\n",
      "Epoch 6982/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0651 - val_loss: 14571678.4522\n",
      "Epoch 6983/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.2038 - val_loss: 14571678.4522\n",
      "Epoch 6984/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0944 - val_loss: 14571678.4522\n",
      "Epoch 6985/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 6986/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 6987/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0774 - val_loss: 14571678.4522\n",
      "Epoch 6988/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0745 - val_loss: 14571678.4522\n",
      "Epoch 6989/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 6990/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 6991/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 6992/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0728 - val_loss: 14571678.4522\n",
      "Epoch 6993/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 6994/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 6995/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0503 - val_loss: 14571678.4522\n",
      "Epoch 6996/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 6997/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1102 - val_loss: 14571678.4522\n",
      "Epoch 6998/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1318 - val_loss: 14571678.4522\n",
      "Epoch 6999/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0198 - val_loss: 14571678.4522\n",
      "Epoch 7000/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1487 - val_loss: 14571678.4522\n",
      "Epoch 7001/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 7002/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1811 - val_loss: 14571678.4522\n",
      "Epoch 7003/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1300 - val_loss: 14571678.4522\n",
      "Epoch 7004/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0603 - val_loss: 14571678.4522\n",
      "Epoch 7005/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1397 - val_loss: 14571678.4522\n",
      "Epoch 7006/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 7007/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1118 - val_loss: 14571678.4522\n",
      "Epoch 7008/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1827 - val_loss: 14571678.4522\n",
      "Epoch 7009/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1483 - val_loss: 14571678.4522\n",
      "Epoch 7010/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0754 - val_loss: 14571678.4522\n",
      "Epoch 7011/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0255 - val_loss: 14571678.4522\n",
      "Epoch 7012/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 7013/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0098 - val_loss: 14571678.4522\n",
      "Epoch 7014/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1115 - val_loss: 14571678.4522\n",
      "Epoch 7015/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0650 - val_loss: 14571678.4522\n",
      "Epoch 7016/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0257 - val_loss: 14571678.4522\n",
      "Epoch 7017/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1440 - val_loss: 14571678.4522\n",
      "Epoch 7018/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 7019/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 7020/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 7021/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1750 - val_loss: 14571678.4522\n",
      "Epoch 7022/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 7023/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0993 - val_loss: 14571678.4522\n",
      "Epoch 7024/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 7025/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 7026/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1713 - val_loss: 14571678.4522\n",
      "Epoch 7027/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 7028/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0347 - val_loss: 14571678.4522\n",
      "Epoch 7029/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 7030/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1450 - val_loss: 14571678.4522\n",
      "Epoch 7031/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1592 - val_loss: 14571678.4522\n",
      "Epoch 7032/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 7033/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1173 - val_loss: 14571678.4522\n",
      "Epoch 7034/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1187 - val_loss: 14571678.4522\n",
      "Epoch 7035/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7036/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0180 - val_loss: 14571678.4522\n",
      "Epoch 7037/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0173 - val_loss: 14571678.4522\n",
      "Epoch 7038/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 7039/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1527 - val_loss: 14571678.4522\n",
      "Epoch 7040/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2010 - val_loss: 14571678.4522\n",
      "Epoch 7041/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1151 - val_loss: 14571678.4522\n",
      "Epoch 7042/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0479 - val_loss: 14571678.4522\n",
      "Epoch 7043/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1622 - val_loss: 14571678.4522\n",
      "Epoch 7044/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0970 - val_loss: 14571678.4522\n",
      "Epoch 7045/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0680 - val_loss: 14571678.4522\n",
      "Epoch 7046/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1513 - val_loss: 14571678.4522\n",
      "Epoch 7047/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 7048/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0692 - val_loss: 14571678.4522\n",
      "Epoch 7049/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 7050/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1294 - val_loss: 14571678.4522\n",
      "Epoch 7051/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 7052/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 7053/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1580 - val_loss: 14571678.4522\n",
      "Epoch 7054/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1092 - val_loss: 14571678.4522\n",
      "Epoch 7055/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0877 - val_loss: 14571678.4522\n",
      "Epoch 7056/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0467 - val_loss: 14571678.4522\n",
      "Epoch 7057/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 7058/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0318 - val_loss: 14571678.4522\n",
      "Epoch 7059/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1602 - val_loss: 14571678.4522\n",
      "Epoch 7060/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0877 - val_loss: 14571678.4522\n",
      "Epoch 7061/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1422 - val_loss: 14571678.4522\n",
      "Epoch 7062/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0702 - val_loss: 14571678.4522\n",
      "Epoch 7063/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 7064/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0465 - val_loss: 14571678.4522\n",
      "Epoch 7065/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1753 - val_loss: 14571678.4522\n",
      "Epoch 7066/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0645 - val_loss: 14571678.4522\n",
      "Epoch 7067/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 7068/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1247 - val_loss: 14571678.4522\n",
      "Epoch 7069/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1412 - val_loss: 14571678.4522\n",
      "Epoch 7070/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0122 - val_loss: 14571678.4522\n",
      "Epoch 7071/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0545 - val_loss: 14571678.4522\n",
      "Epoch 7072/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0879 - val_loss: 14571678.4522\n",
      "Epoch 7073/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 7074/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0237 - val_loss: 14571678.4522\n",
      "Epoch 7075/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0315 - val_loss: 14571678.4522\n",
      "Epoch 7076/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0127 - val_loss: 14571678.4522\n",
      "Epoch 7077/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 7078/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 7079/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1062 - val_loss: 14571678.4522\n",
      "Epoch 7080/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1890 - val_loss: 14571678.4522\n",
      "Epoch 7081/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0137 - val_loss: 14571678.4522\n",
      "Epoch 7082/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 7083/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1255 - val_loss: 14571678.4522\n",
      "Epoch 7084/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 7085/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0695 - val_loss: 14571678.4522\n",
      "Epoch 7086/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1793 - val_loss: 14571678.4522\n",
      "Epoch 7087/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 7088/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1032 - val_loss: 14571678.4522\n",
      "Epoch 7089/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0408 - val_loss: 14571678.4522\n",
      "Epoch 7090/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0832 - val_loss: 14571678.4522\n",
      "Epoch 7091/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0400 - val_loss: 14571678.4522\n",
      "Epoch 7092/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0692 - val_loss: 14571678.4522\n",
      "Epoch 7093/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1543 - val_loss: 14571678.4522\n",
      "Epoch 7094/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0553 - val_loss: 14571678.4522\n",
      "Epoch 7095/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 7096/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1323 - val_loss: 14571678.4522\n",
      "Epoch 7097/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0672 - val_loss: 14571678.4522\n",
      "Epoch 7098/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1050 - val_loss: 14571678.4522\n",
      "Epoch 7099/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0577 - val_loss: 14571678.4522\n",
      "Epoch 7100/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1753 - val_loss: 14571678.4522\n",
      "Epoch 7101/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0615 - val_loss: 14571678.4522\n",
      "Epoch 7102/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 7103/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0233 - val_loss: 14571678.4522\n",
      "Epoch 7104/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 7105/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 7106/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1470 - val_loss: 14571678.4522\n",
      "Epoch 7107/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0838 - val_loss: 14571678.4522\n",
      "Epoch 7108/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0787 - val_loss: 14571678.4522\n",
      "Epoch 7109/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0948 - val_loss: 14571678.4522\n",
      "Epoch 7110/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1443 - val_loss: 14571678.4522\n",
      "Epoch 7111/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 7112/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 7113/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1173 - val_loss: 14571678.4522\n",
      "Epoch 7114/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0627 - val_loss: 14571678.4522\n",
      "Epoch 7115/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0357 - val_loss: 14571678.4522\n",
      "Epoch 7116/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1205 - val_loss: 14571678.4522\n",
      "Epoch 7117/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0406 - val_loss: 14571678.4522\n",
      "Epoch 7118/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0742 - val_loss: 14571678.4522\n",
      "Epoch 7119/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1829 - val_loss: 14571678.4522\n",
      "Epoch 7120/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 7121/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 7122/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 7123/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0280 - val_loss: 14571678.4522\n",
      "Epoch 7124/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0873 - val_loss: 14571678.4522\n",
      "Epoch 7125/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 7126/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 7127/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1531 - val_loss: 14571678.4522\n",
      "Epoch 7128/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9522 - val_loss: 14571678.4522\n",
      "Epoch 7129/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0595 - val_loss: 14571678.4522\n",
      "Epoch 7130/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 7131/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1200 - val_loss: 14571678.4522\n",
      "Epoch 7132/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0560 - val_loss: 14571678.4522\n",
      "Epoch 7133/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1300 - val_loss: 14571678.4522\n",
      "Epoch 7134/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1403 - val_loss: 14571678.4522\n",
      "Epoch 7135/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1287 - val_loss: 14571678.4522\n",
      "Epoch 7136/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0898 - val_loss: 14571678.4522\n",
      "Epoch 7137/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0635 - val_loss: 14571678.4522\n",
      "Epoch 7138/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 7139/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 7140/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 7141/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0341 - val_loss: 14571678.4522\n",
      "Epoch 7142/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1508 - val_loss: 14571678.4522\n",
      "Epoch 7143/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 7144/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0874 - val_loss: 14571678.4522\n",
      "Epoch 7145/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1112 - val_loss: 14571678.4522\n",
      "Epoch 7146/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1387 - val_loss: 14571678.4522\n",
      "Epoch 7147/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9987 - val_loss: 14571678.4522\n",
      "Epoch 7148/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1100 - val_loss: 14571678.4522\n",
      "Epoch 7149/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0002 - val_loss: 14571678.4522\n",
      "Epoch 7150/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1982 - val_loss: 14571678.4522\n",
      "Epoch 7151/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 7152/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1563 - val_loss: 14571678.4522\n",
      "Epoch 7153/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1143 - val_loss: 14571678.4522\n",
      "Epoch 7154/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0307 - val_loss: 14571678.4522\n",
      "Epoch 7155/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0193 - val_loss: 14571678.4522\n",
      "Epoch 7156/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 7157/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 7158/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1348 - val_loss: 14571678.4522\n",
      "Epoch 7159/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 7160/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1687 - val_loss: 14571678.4522\n",
      "Epoch 7161/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 7162/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 7163/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0483 - val_loss: 14571678.4522\n",
      "Epoch 7164/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 7165/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0909 - val_loss: 14571678.4522\n",
      "Epoch 7166/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0060 - val_loss: 14571678.4522\n",
      "Epoch 7167/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1119 - val_loss: 14571678.4522\n",
      "Epoch 7168/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0970 - val_loss: 14571678.4522\n",
      "Epoch 7169/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1458 - val_loss: 14571678.4522\n",
      "Epoch 7170/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1327 - val_loss: 14571678.4522\n",
      "Epoch 7171/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0848 - val_loss: 14571678.4522\n",
      "Epoch 7172/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0753 - val_loss: 14571678.4522\n",
      "Epoch 7173/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0412 - val_loss: 14571678.4522\n",
      "Epoch 7174/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1218 - val_loss: 14571678.4522\n",
      "Epoch 7175/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0777 - val_loss: 14571678.4522\n",
      "Epoch 7176/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1487 - val_loss: 14571678.4522\n",
      "Epoch 7177/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7178/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 7179/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1373 - val_loss: 14571678.4522\n",
      "Epoch 7180/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 7181/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 7182/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 7183/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1523 - val_loss: 14571678.4522\n",
      "Epoch 7184/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1310 - val_loss: 14571678.4522\n",
      "Epoch 7185/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 7186/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0458 - val_loss: 14571678.4522\n",
      "Epoch 7187/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0342 - val_loss: 14571678.4522\n",
      "Epoch 7188/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 7189/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0862 - val_loss: 14571678.4522\n",
      "Epoch 7190/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0948 - val_loss: 14571678.4522\n",
      "Epoch 7191/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0627 - val_loss: 14571678.4522\n",
      "Epoch 7192/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1300 - val_loss: 14571678.4522\n",
      "Epoch 7193/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0672 - val_loss: 14571678.4522\n",
      "Epoch 7194/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0673 - val_loss: 14571678.4522\n",
      "Epoch 7195/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0405 - val_loss: 14571678.4522\n",
      "Epoch 7196/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1085 - val_loss: 14571678.4522\n",
      "Epoch 7197/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1587 - val_loss: 14571678.4522\n",
      "Epoch 7198/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0005 - val_loss: 14571678.4522\n",
      "Epoch 7199/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0307 - val_loss: 14571678.4522\n",
      "Epoch 7200/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1283 - val_loss: 14571678.4522\n",
      "Epoch 7201/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1102 - val_loss: 14571678.4522\n",
      "Epoch 7202/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0570 - val_loss: 14571678.4522\n",
      "Epoch 7203/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0132 - val_loss: 14571678.4522\n",
      "Epoch 7204/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 7205/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 7206/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0413 - val_loss: 14571678.4522\n",
      "Epoch 7207/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 7208/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0825 - val_loss: 14571678.4522\n",
      "Epoch 7209/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0533 - val_loss: 14571678.4522\n",
      "Epoch 7210/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 7211/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0654 - val_loss: 14571678.4522\n",
      "Epoch 7212/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 7213/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 7214/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0771 - val_loss: 14571678.4522\n",
      "Epoch 7215/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0117 - val_loss: 14571678.4522\n",
      "Epoch 7216/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 7217/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 7218/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0297 - val_loss: 14571678.4522\n",
      "Epoch 7219/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 7220/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 7221/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 7222/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 7223/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0975 - val_loss: 14571678.4522\n",
      "Epoch 7224/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0932 - val_loss: 14571678.4522\n",
      "Epoch 7225/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 7226/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 7227/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1032 - val_loss: 14571678.4522\n",
      "Epoch 7228/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0408 - val_loss: 14571678.4522\n",
      "Epoch 7229/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1595 - val_loss: 14571678.4522\n",
      "Epoch 7230/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1338 - val_loss: 14571678.4522\n",
      "Epoch 7231/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0500 - val_loss: 14571678.4522\n",
      "Epoch 7232/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 7233/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 7234/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0040 - val_loss: 14571678.4522\n",
      "Epoch 7235/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7236/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1397 - val_loss: 14571678.4522\n",
      "Epoch 7237/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0585 - val_loss: 14571678.4522\n",
      "Epoch 7238/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0595 - val_loss: 14571678.4522\n",
      "Epoch 7239/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 7240/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0327 - val_loss: 14571678.4522\n",
      "Epoch 7241/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1503 - val_loss: 14571678.4522\n",
      "Epoch 7242/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1052 - val_loss: 14571678.4522\n",
      "Epoch 7243/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1280 - val_loss: 14571678.4522\n",
      "Epoch 7244/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0563 - val_loss: 14571678.4522\n",
      "Epoch 7245/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1802 - val_loss: 14571678.4522\n",
      "Epoch 7246/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1123 - val_loss: 14571678.4522\n",
      "Epoch 7247/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1183 - val_loss: 14571678.4522\n",
      "Epoch 7248/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 7249/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1758 - val_loss: 14571678.4522\n",
      "Epoch 7250/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 7251/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0368 - val_loss: 14571678.4522\n",
      "Epoch 7252/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1303 - val_loss: 14571678.4522\n",
      "Epoch 7253/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 7254/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0611 - val_loss: 14571678.4522\n",
      "Epoch 7255/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0682 - val_loss: 14571678.4522\n",
      "Epoch 7256/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0380 - val_loss: 14571678.4522\n",
      "Epoch 7257/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1517 - val_loss: 14571678.4522\n",
      "Epoch 7258/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 7259/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1617 - val_loss: 14571678.4522\n",
      "Epoch 7260/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0020 - val_loss: 14571678.4522\n",
      "Epoch 7261/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0783 - val_loss: 14571678.4522\n",
      "Epoch 7262/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 7263/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0904 - val_loss: 14571678.4522\n",
      "Epoch 7264/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 7265/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1168 - val_loss: 14571678.4522\n",
      "Epoch 7266/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1025 - val_loss: 14571678.4522\n",
      "Epoch 7267/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0268 - val_loss: 14571678.4522\n",
      "Epoch 7268/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 7269/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1071 - val_loss: 14571678.4522\n",
      "Epoch 7270/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0875 - val_loss: 14571678.4522\n",
      "Epoch 7271/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1253 - val_loss: 14571678.4522\n",
      "Epoch 7272/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0336 - val_loss: 14571678.4522\n",
      "Epoch 7273/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0903 - val_loss: 14571678.4522\n",
      "Epoch 7274/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530844.9877 - val_loss: 14571678.4522\n",
      "Epoch 7275/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 7276/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0380 - val_loss: 14571678.4522\n",
      "Epoch 7277/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1113 - val_loss: 14571678.4522\n",
      "Epoch 7278/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0987 - val_loss: 14571678.4522\n",
      "Epoch 7279/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 7280/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 7281/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 7282/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1108 - val_loss: 14571678.4522\n",
      "Epoch 7283/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0903 - val_loss: 14571678.4522\n",
      "Epoch 7284/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1960 - val_loss: 14571678.4522\n",
      "Epoch 7285/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1595 - val_loss: 14571678.4522\n",
      "Epoch 7286/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0485 - val_loss: 14571678.4522\n",
      "Epoch 7287/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1193 - val_loss: 14571678.4522\n",
      "Epoch 7288/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0608 - val_loss: 14571678.4522\n",
      "Epoch 7289/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0470 - val_loss: 14571678.4522\n",
      "Epoch 7290/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9933 - val_loss: 14571678.4522\n",
      "Epoch 7291/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7292/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1118 - val_loss: 14571678.4522\n",
      "Epoch 7293/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1164 - val_loss: 14571678.4522\n",
      "Epoch 7294/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0795 - val_loss: 14571678.4522\n",
      "Epoch 7295/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 7296/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 7297/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0968 - val_loss: 14571678.4522\n",
      "Epoch 7298/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 7299/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 7300/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0500 - val_loss: 14571678.4522\n",
      "Epoch 7301/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1193 - val_loss: 14571678.4522\n",
      "Epoch 7302/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7303/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 7304/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 7305/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7306/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 7307/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 7308/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 7309/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0798 - val_loss: 14571678.4522\n",
      "Epoch 7310/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 7311/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 7312/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1418 - val_loss: 14571678.4522\n",
      "Epoch 7313/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0718 - val_loss: 14571678.4522\n",
      "Epoch 7314/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 7315/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 7316/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0438 - val_loss: 14571678.4522\n",
      "Epoch 7317/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0895 - val_loss: 14571678.4522\n",
      "Epoch 7318/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1418 - val_loss: 14571678.4522\n",
      "Epoch 7319/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 7320/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0978 - val_loss: 14571678.4522\n",
      "Epoch 7321/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1508 - val_loss: 14571678.4522\n",
      "Epoch 7322/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1030 - val_loss: 14571678.4522\n",
      "Epoch 7323/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1593 - val_loss: 14571678.4522\n",
      "Epoch 7324/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 7325/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 7326/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 7327/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1050 - val_loss: 14571678.4522\n",
      "Epoch 7328/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0670 - val_loss: 14571678.4522\n",
      "Epoch 7329/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1174 - val_loss: 14571678.4522\n",
      "Epoch 7330/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1823 - val_loss: 14571678.4522\n",
      "Epoch 7331/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2085 - val_loss: 14571678.4522\n",
      "Epoch 7332/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0690 - val_loss: 14571678.4522\n",
      "Epoch 7333/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 7334/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0360 - val_loss: 14571678.4522\n",
      "Epoch 7335/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1287 - val_loss: 14571678.4522\n",
      "Epoch 7336/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0708 - val_loss: 14571678.4522\n",
      "Epoch 7337/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0623 - val_loss: 14571678.4522\n",
      "Epoch 7338/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0697 - val_loss: 14571678.4522\n",
      "Epoch 7339/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0413 - val_loss: 14571678.4522\n",
      "Epoch 7340/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 7341/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0262 - val_loss: 14571678.4522\n",
      "Epoch 7342/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0518 - val_loss: 14571678.4522\n",
      "Epoch 7343/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1046 - val_loss: 14571678.4522\n",
      "Epoch 7344/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0118 - val_loss: 14571678.4522\n",
      "Epoch 7345/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0958 - val_loss: 14571678.4522\n",
      "Epoch 7346/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1990 - val_loss: 14571678.4522\n",
      "Epoch 7347/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0840 - val_loss: 14571678.4522\n",
      "Epoch 7348/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1203 - val_loss: 14571678.4522\n",
      "Epoch 7349/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0508 - val_loss: 14571678.4522\n",
      "Epoch 7350/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 7351/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0623 - val_loss: 14571678.4522\n",
      "Epoch 7352/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0762 - val_loss: 14571678.4522\n",
      "Epoch 7353/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 7354/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 7355/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 7356/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0968 - val_loss: 14571678.4522\n",
      "Epoch 7357/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0565 - val_loss: 14571678.4522\n",
      "Epoch 7358/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 7359/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0979 - val_loss: 14571678.4522\n",
      "Epoch 7360/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0500 - val_loss: 14571678.4522\n",
      "Epoch 7361/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0580 - val_loss: 14571678.4522\n",
      "Epoch 7362/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0167 - val_loss: 14571678.4522\n",
      "Epoch 7363/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0403 - val_loss: 14571678.4522\n",
      "Epoch 7364/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 7365/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 7366/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 7367/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0835 - val_loss: 14571678.4522\n",
      "Epoch 7368/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 7369/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 7370/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 7371/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0306 - val_loss: 14571678.4522\n",
      "Epoch 7372/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 7373/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0928 - val_loss: 14571678.4522\n",
      "Epoch 7374/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0007 - val_loss: 14571678.4522\n",
      "Epoch 7375/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0180 - val_loss: 14571678.4522\n",
      "Epoch 7376/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0490 - val_loss: 14571678.4522\n",
      "Epoch 7377/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0732 - val_loss: 14571678.4522\n",
      "Epoch 7378/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1247 - val_loss: 14571678.4522\n",
      "Epoch 7379/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1072 - val_loss: 14571678.4522\n",
      "Epoch 7380/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 7381/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1166 - val_loss: 14571678.4522\n",
      "Epoch 7382/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 7383/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1497 - val_loss: 14571678.4522\n",
      "Epoch 7384/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1182 - val_loss: 14571678.4522\n",
      "Epoch 7385/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0608 - val_loss: 14571678.4522\n",
      "Epoch 7386/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1039 - val_loss: 14571678.4522\n",
      "Epoch 7387/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0328 - val_loss: 14571678.4522\n",
      "Epoch 7388/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 7389/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 7390/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1503 - val_loss: 14571678.4522\n",
      "Epoch 7391/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0838 - val_loss: 14571678.4522\n",
      "Epoch 7392/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9863 - val_loss: 14571678.4522\n",
      "Epoch 7393/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 7394/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1490 - val_loss: 14571678.4522\n",
      "Epoch 7395/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0573 - val_loss: 14571678.4522\n",
      "Epoch 7396/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1983 - val_loss: 14571678.4522\n",
      "Epoch 7397/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 7398/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1553 - val_loss: 14571678.4522\n",
      "Epoch 7399/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0998 - val_loss: 14571678.4522\n",
      "Epoch 7400/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0442 - val_loss: 14571678.4522\n",
      "Epoch 7401/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0260 - val_loss: 14571678.4522\n",
      "Epoch 7402/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0632 - val_loss: 14571678.4522\n",
      "Epoch 7403/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1435 - val_loss: 14571678.4522\n",
      "Epoch 7404/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 7405/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 7406/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0733 - val_loss: 14571678.4522\n",
      "Epoch 7407/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 7408/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1052 - val_loss: 14571678.4522\n",
      "Epoch 7409/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1687 - val_loss: 14571678.4522\n",
      "Epoch 7410/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0940 - val_loss: 14571678.4522\n",
      "Epoch 7411/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0395 - val_loss: 14571678.4522\n",
      "Epoch 7412/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0548 - val_loss: 14571678.4522\n",
      "Epoch 7413/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0553 - val_loss: 14571678.4522\n",
      "Epoch 7414/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0630 - val_loss: 14571678.4522\n",
      "Epoch 7415/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 7416/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0177 - val_loss: 14571678.4522\n",
      "Epoch 7417/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0945 - val_loss: 14571678.4522\n",
      "Epoch 7418/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1493 - val_loss: 14571678.4522\n",
      "Epoch 7419/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0340 - val_loss: 14571678.4522\n",
      "Epoch 7420/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 7421/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1068 - val_loss: 14571678.4522\n",
      "Epoch 7422/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1595 - val_loss: 14571678.4522\n",
      "Epoch 7423/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 7424/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0563 - val_loss: 14571678.4522\n",
      "Epoch 7425/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 7426/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0685 - val_loss: 14571678.4522\n",
      "Epoch 7427/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0936 - val_loss: 14571678.4522\n",
      "Epoch 7428/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 7429/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1173 - val_loss: 14571678.4522\n",
      "Epoch 7430/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 7431/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0997 - val_loss: 14571678.4522\n",
      "Epoch 7432/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0637 - val_loss: 14571678.4522\n",
      "Epoch 7433/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0352 - val_loss: 14571678.4522\n",
      "Epoch 7434/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0315 - val_loss: 14571678.4522\n",
      "Epoch 7435/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0808 - val_loss: 14571678.4522\n",
      "Epoch 7436/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0605 - val_loss: 14571678.4522\n",
      "Epoch 7437/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1577 - val_loss: 14571678.4522\n",
      "Epoch 7438/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 7439/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0940 - val_loss: 14571678.4522\n",
      "Epoch 7440/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0788 - val_loss: 14571678.4522\n",
      "Epoch 7441/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 7442/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 7443/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0700 - val_loss: 14571678.4522\n",
      "Epoch 7444/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 7445/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0942 - val_loss: 14571678.4522\n",
      "Epoch 7446/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9993 - val_loss: 14571678.4522\n",
      "Epoch 7447/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0762 - val_loss: 14571678.4522\n",
      "Epoch 7448/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0802 - val_loss: 14571678.4522\n",
      "Epoch 7449/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1413 - val_loss: 14571678.4522\n",
      "Epoch 7450/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 7451/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0099 - val_loss: 14571678.4522\n",
      "Epoch 7452/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 7453/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1285 - val_loss: 14571678.4522\n",
      "Epoch 7454/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0265 - val_loss: 14571678.4522\n",
      "Epoch 7455/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 7456/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1272 - val_loss: 14571678.4522\n",
      "Epoch 7457/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 7458/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0362 - val_loss: 14571678.4522\n",
      "Epoch 7459/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 7460/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1253 - val_loss: 14571678.4522\n",
      "Epoch 7461/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 7462/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 7463/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0862 - val_loss: 14571678.4522\n",
      "Epoch 7464/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1270 - val_loss: 14571678.4522\n",
      "Epoch 7465/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0768 - val_loss: 14571678.4522\n",
      "Epoch 7466/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0250 - val_loss: 14571678.4522\n",
      "Epoch 7467/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0147 - val_loss: 14571678.4522\n",
      "Epoch 7468/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0517 - val_loss: 14571678.4522\n",
      "Epoch 7469/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 7470/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0573 - val_loss: 14571678.4522\n",
      "Epoch 7471/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0768 - val_loss: 14571678.4522\n",
      "Epoch 7472/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0895 - val_loss: 14571678.4522\n",
      "Epoch 7473/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 7474/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1552 - val_loss: 14571678.4522\n",
      "Epoch 7475/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9695 - val_loss: 14571678.4522\n",
      "Epoch 7476/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0832 - val_loss: 14571678.4522\n",
      "Epoch 7477/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1638 - val_loss: 14571678.4522\n",
      "Epoch 7478/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 7479/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0598 - val_loss: 14571678.4522\n",
      "Epoch 7480/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1958 - val_loss: 14571678.4522\n",
      "Epoch 7481/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 7482/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 7483/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0203 - val_loss: 14571678.4522\n",
      "Epoch 7484/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 7485/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0929 - val_loss: 14571678.4522\n",
      "Epoch 7486/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1783 - val_loss: 14571678.4522\n",
      "Epoch 7487/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1417 - val_loss: 14571678.4522\n",
      "Epoch 7488/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1498 - val_loss: 14571678.4522\n",
      "Epoch 7489/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0493 - val_loss: 14571678.4522\n",
      "Epoch 7490/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1235 - val_loss: 14571678.4522\n",
      "Epoch 7491/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0278 - val_loss: 14571678.4522\n",
      "Epoch 7492/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0708 - val_loss: 14571678.4522\n",
      "Epoch 7493/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1895 - val_loss: 14571678.4522\n",
      "Epoch 7494/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1561 - val_loss: 14571678.4522\n",
      "Epoch 7495/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0608 - val_loss: 14571678.4522\n",
      "Epoch 7496/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0878 - val_loss: 14571678.4522\n",
      "Epoch 7497/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 7498/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 7499/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 7500/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 7501/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0848 - val_loss: 14571678.4522\n",
      "Epoch 7502/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 7503/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 7504/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 7505/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 7506/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 7507/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0828 - val_loss: 14571678.4522\n",
      "Epoch 7508/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9650 - val_loss: 14571678.4522\n",
      "Epoch 7509/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 7510/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1343 - val_loss: 14571678.4522\n",
      "Epoch 7511/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 7512/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1757 - val_loss: 14571678.4522\n",
      "Epoch 7513/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1697 - val_loss: 14571678.4522\n",
      "Epoch 7514/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 7515/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 7516/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 7517/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1184 - val_loss: 14571678.4522\n",
      "Epoch 7518/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 7519/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1503 - val_loss: 14571678.4522\n",
      "Epoch 7520/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1212 - val_loss: 14571678.4522\n",
      "Epoch 7521/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9965 - val_loss: 14571678.4522\n",
      "Epoch 7522/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0385 - val_loss: 14571678.4522\n",
      "Epoch 7523/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 7524/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0393 - val_loss: 14571678.4522\n",
      "Epoch 7525/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0877 - val_loss: 14571678.4522\n",
      "Epoch 7526/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1118 - val_loss: 14571678.4522\n",
      "Epoch 7527/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 7528/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1820 - val_loss: 14571678.4522\n",
      "Epoch 7529/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0502 - val_loss: 14571678.4522\n",
      "Epoch 7530/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1292 - val_loss: 14571678.4522\n",
      "Epoch 7531/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 7532/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 7533/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0194 - val_loss: 14571678.4522\n",
      "Epoch 7534/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 7535/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 7536/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 7537/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0912 - val_loss: 14571678.4522\n",
      "Epoch 7538/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 7539/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1450 - val_loss: 14571678.4522\n",
      "Epoch 7540/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0997 - val_loss: 14571678.4522\n",
      "Epoch 7541/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 7542/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1025 - val_loss: 14571678.4522\n",
      "Epoch 7543/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 7544/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1078 - val_loss: 14571678.4522\n",
      "Epoch 7545/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0962 - val_loss: 14571678.4522\n",
      "Epoch 7546/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0390 - val_loss: 14571678.4522\n",
      "Epoch 7547/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0255 - val_loss: 14571678.4522\n",
      "Epoch 7548/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1562 - val_loss: 14571678.4522\n",
      "Epoch 7549/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0448 - val_loss: 14571678.4522\n",
      "Epoch 7550/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1125 - val_loss: 14571678.4522\n",
      "Epoch 7551/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1138 - val_loss: 14571678.4522\n",
      "Epoch 7552/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 7553/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1280 - val_loss: 14571678.4522\n",
      "Epoch 7554/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 7555/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 7556/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 7557/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1302 - val_loss: 14571678.4522\n",
      "Epoch 7558/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1312 - val_loss: 14571678.4522\n",
      "Epoch 7559/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 7560/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0289 - val_loss: 14571678.4522\n",
      "Epoch 7561/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 7562/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0487 - val_loss: 14571678.4522\n",
      "Epoch 7563/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0985 - val_loss: 14571678.4522\n",
      "Epoch 7564/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 7565/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1627 - val_loss: 14571678.4522\n",
      "Epoch 7566/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1519 - val_loss: 14571678.4522\n",
      "Epoch 7567/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 7568/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1717 - val_loss: 14571678.4522\n",
      "Epoch 7569/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1260 - val_loss: 14571678.4522\n",
      "Epoch 7570/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1814 - val_loss: 14571678.4522\n",
      "Epoch 7571/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0732 - val_loss: 14571678.4522\n",
      "Epoch 7572/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9720 - val_loss: 14571678.4522\n",
      "Epoch 7573/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 7574/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1075 - val_loss: 14571678.4522\n",
      "Epoch 7575/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0513 - val_loss: 14571678.4522\n",
      "Epoch 7576/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0865 - val_loss: 14571678.4522\n",
      "Epoch 7577/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1475 - val_loss: 14571678.4522\n",
      "Epoch 7578/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1312 - val_loss: 14571678.4522\n",
      "Epoch 7579/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 7580/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1015 - val_loss: 14571678.4522\n",
      "Epoch 7581/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0658 - val_loss: 14571678.4522\n",
      "Epoch 7582/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0825 - val_loss: 14571678.4522\n",
      "Epoch 7583/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0575 - val_loss: 14571678.4522\n",
      "Epoch 7584/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0018 - val_loss: 14571678.4522\n",
      "Epoch 7585/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1583 - val_loss: 14571678.4522\n",
      "Epoch 7586/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 7587/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0220 - val_loss: 14571678.4522\n",
      "Epoch 7588/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1253 - val_loss: 14571678.4522\n",
      "Epoch 7589/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0901 - val_loss: 14571678.4522\n",
      "Epoch 7590/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1928 - val_loss: 14571678.4522\n",
      "Epoch 7591/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0310 - val_loss: 14571678.4522\n",
      "Epoch 7592/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 7593/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1218 - val_loss: 14571678.4522\n",
      "Epoch 7594/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0217 - val_loss: 14571678.4522\n",
      "Epoch 7595/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 7596/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0322 - val_loss: 14571678.4522\n",
      "Epoch 7597/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0356 - val_loss: 14571678.4522\n",
      "Epoch 7598/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 7599/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 7600/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7601/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0560 - val_loss: 14571678.4522\n",
      "Epoch 7602/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0670 - val_loss: 14571678.4522\n",
      "Epoch 7603/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 7604/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1015 - val_loss: 14571678.4522\n",
      "Epoch 7605/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 7606/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2183 - val_loss: 14571678.4522\n",
      "Epoch 7607/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0573 - val_loss: 14571678.4522\n",
      "Epoch 7608/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9770 - val_loss: 14571678.4522\n",
      "Epoch 7609/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0795 - val_loss: 14571678.4522\n",
      "Epoch 7610/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 7611/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1198 - val_loss: 14571678.4522\n",
      "Epoch 7612/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 7613/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0365 - val_loss: 14571678.4522\n",
      "Epoch 7614/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1427 - val_loss: 14571678.4522\n",
      "Epoch 7615/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1328 - val_loss: 14571678.4522\n",
      "Epoch 7616/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1395 - val_loss: 14571678.4522\n",
      "Epoch 7617/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 7618/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 7619/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 7620/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7621/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 7622/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 7623/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 7624/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0673 - val_loss: 14571678.4522\n",
      "Epoch 7625/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0992 - val_loss: 14571678.4522\n",
      "Epoch 7626/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 7627/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 7628/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0512 - val_loss: 14571678.4522\n",
      "Epoch 7629/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0812 - val_loss: 14571678.4522\n",
      "Epoch 7630/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1198 - val_loss: 14571678.4522\n",
      "Epoch 7631/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1060 - val_loss: 14571678.4522\n",
      "Epoch 7632/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0512 - val_loss: 14571678.4522\n",
      "Epoch 7633/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0608 - val_loss: 14571678.4522\n",
      "Epoch 7634/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0690 - val_loss: 14571678.4522\n",
      "Epoch 7635/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0877 - val_loss: 14571678.4522\n",
      "Epoch 7636/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 7637/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 7638/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0817 - val_loss: 14571678.4522\n",
      "Epoch 7639/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0728 - val_loss: 14571678.4522\n",
      "Epoch 7640/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1383 - val_loss: 14571678.4522\n",
      "Epoch 7641/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 7642/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1752 - val_loss: 14571678.4522\n",
      "Epoch 7643/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 7644/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0363 - val_loss: 14571678.4522\n",
      "Epoch 7645/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0903 - val_loss: 14571678.4522\n",
      "Epoch 7646/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 7647/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 7648/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0882 - val_loss: 14571678.4522\n",
      "Epoch 7649/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 7650/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1002 - val_loss: 14571678.4522\n",
      "Epoch 7651/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 7652/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 7653/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1597 - val_loss: 14571678.4522\n",
      "Epoch 7654/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 7655/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 7656/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 7657/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1257 - val_loss: 14571678.4522\n",
      "Epoch 7658/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7659/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1402 - val_loss: 14571678.4522\n",
      "Epoch 7660/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 7661/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0433 - val_loss: 14571678.4522\n",
      "Epoch 7662/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 7663/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 7664/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1333 - val_loss: 14571678.4522\n",
      "Epoch 7665/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1468 - val_loss: 14571678.4522\n",
      "Epoch 7666/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1264 - val_loss: 14571678.4522\n",
      "Epoch 7667/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1138 - val_loss: 14571678.4522\n",
      "Epoch 7668/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0495 - val_loss: 14571678.4522\n",
      "Epoch 7669/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0396 - val_loss: 14571678.4522\n",
      "Epoch 7670/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0613 - val_loss: 14571678.4522\n",
      "Epoch 7671/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0525 - val_loss: 14571678.4522\n",
      "Epoch 7672/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 7673/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0760 - val_loss: 14571678.4522\n",
      "Epoch 7674/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 7675/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 7676/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 7677/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 7678/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 7679/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 7680/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0389 - val_loss: 14571678.4522\n",
      "Epoch 7681/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0708 - val_loss: 14571678.4522\n",
      "Epoch 7682/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0617 - val_loss: 14571678.4522\n",
      "Epoch 7683/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 7684/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 7685/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1672 - val_loss: 14571678.4522\n",
      "Epoch 7686/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7687/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1313 - val_loss: 14571678.4522\n",
      "Epoch 7688/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9863 - val_loss: 14571678.4522\n",
      "Epoch 7689/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1663 - val_loss: 14571678.4522\n",
      "Epoch 7690/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0498 - val_loss: 14571678.4522\n",
      "Epoch 7691/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1283 - val_loss: 14571678.4522\n",
      "Epoch 7692/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1357 - val_loss: 14571678.4522\n",
      "Epoch 7693/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 7694/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0982 - val_loss: 14571678.4522\n",
      "Epoch 7695/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7696/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1657 - val_loss: 14571678.4522\n",
      "Epoch 7697/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 7698/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 7699/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1110 - val_loss: 14571678.4522\n",
      "Epoch 7700/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0360 - val_loss: 14571678.4522\n",
      "Epoch 7701/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 7702/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 7703/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 7704/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1090 - val_loss: 14571678.4522\n",
      "Epoch 7705/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 7706/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0516 - val_loss: 14571678.4522\n",
      "Epoch 7707/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 7708/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1590 - val_loss: 14571678.4522\n",
      "Epoch 7709/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1460 - val_loss: 14571678.4522\n",
      "Epoch 7710/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 7711/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1627 - val_loss: 14571678.4522\n",
      "Epoch 7712/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0573 - val_loss: 14571678.4522\n",
      "Epoch 7713/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 7714/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1742 - val_loss: 14571678.4522\n",
      "Epoch 7715/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0417 - val_loss: 14571678.4522\n",
      "Epoch 7716/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1435 - val_loss: 14571678.4522\n",
      "Epoch 7717/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 7718/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1277 - val_loss: 14571678.4522\n",
      "Epoch 7719/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 7720/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 7721/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 7722/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 7723/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0458 - val_loss: 14571678.4522\n",
      "Epoch 7724/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 7725/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1547 - val_loss: 14571678.4522\n",
      "Epoch 7726/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1493 - val_loss: 14571678.4522\n",
      "Epoch 7727/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1105 - val_loss: 14571678.4522\n",
      "Epoch 7728/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0550 - val_loss: 14571678.4522\n",
      "Epoch 7729/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 7730/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1487 - val_loss: 14571678.4522\n",
      "Epoch 7731/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 7732/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7733/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 7734/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0300 - val_loss: 14571678.4522\n",
      "Epoch 7735/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1397 - val_loss: 14571678.4522\n",
      "Epoch 7736/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0328 - val_loss: 14571678.4522\n",
      "Epoch 7737/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 7738/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7739/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0765 - val_loss: 14571678.4522\n",
      "Epoch 7740/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 7741/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0150 - val_loss: 14571678.4522\n",
      "Epoch 7742/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 7743/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 7744/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 7745/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0976 - val_loss: 14571678.4522\n",
      "Epoch 7746/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1247 - val_loss: 14571678.4522\n",
      "Epoch 7747/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0263 - val_loss: 14571678.4522\n",
      "Epoch 7748/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 7749/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 7750/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0147 - val_loss: 14571678.4522\n",
      "Epoch 7751/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1160 - val_loss: 14571678.4522\n",
      "Epoch 7752/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 7753/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0020 - val_loss: 14571678.4522\n",
      "Epoch 7754/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 7755/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 7756/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 7757/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0567 - val_loss: 14571678.4522\n",
      "Epoch 7758/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7759/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 7760/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0682 - val_loss: 14571678.4522\n",
      "Epoch 7761/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9793 - val_loss: 14571678.4522\n",
      "Epoch 7762/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0920 - val_loss: 14571678.4522\n",
      "Epoch 7763/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7764/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0343 - val_loss: 14571678.4522\n",
      "Epoch 7765/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0950 - val_loss: 14571678.4522\n",
      "Epoch 7766/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 7767/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1842 - val_loss: 14571678.4522\n",
      "Epoch 7768/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7769/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 7770/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0663 - val_loss: 14571678.4522\n",
      "Epoch 7771/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 7772/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 7773/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0137 - val_loss: 14571678.4522\n",
      "Epoch 7774/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1272 - val_loss: 14571678.4522\n",
      "Epoch 7775/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0138 - val_loss: 14571678.4522\n",
      "Epoch 7776/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0835 - val_loss: 14571678.4522\n",
      "Epoch 7777/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 7778/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0748 - val_loss: 14571678.4522\n",
      "Epoch 7779/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 7780/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 7781/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 7782/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 7783/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1602 - val_loss: 14571678.4522\n",
      "Epoch 7784/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530844.9425 - val_loss: 14571678.4522\n",
      "Epoch 7785/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 7786/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0676 - val_loss: 14571678.4522\n",
      "Epoch 7787/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 7788/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 7789/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 7790/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 7791/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0975 - val_loss: 14571678.4522\n",
      "Epoch 7792/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0714 - val_loss: 14571678.4522\n",
      "Epoch 7793/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0112 - val_loss: 14571678.4522\n",
      "Epoch 7794/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0863 - val_loss: 14571678.4522\n",
      "Epoch 7795/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0615 - val_loss: 14571678.4522\n",
      "Epoch 7796/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 7797/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 7798/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 7799/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0655 - val_loss: 14571678.4522\n",
      "Epoch 7800/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0958 - val_loss: 14571678.4522\n",
      "Epoch 7801/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0705 - val_loss: 14571678.4522\n",
      "Epoch 7802/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0878 - val_loss: 14571678.4522\n",
      "Epoch 7803/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 7804/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7805/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0838 - val_loss: 14571678.4522\n",
      "Epoch 7806/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0115 - val_loss: 14571678.4522\n",
      "Epoch 7807/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0110 - val_loss: 14571678.4522\n",
      "Epoch 7808/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7809/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 7810/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0942 - val_loss: 14571678.4522\n",
      "Epoch 7811/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1302 - val_loss: 14571678.4522\n",
      "Epoch 7812/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0908 - val_loss: 14571678.4522\n",
      "Epoch 7813/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1187 - val_loss: 14571678.4522\n",
      "Epoch 7814/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0903 - val_loss: 14571678.4522\n",
      "Epoch 7815/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 7816/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 7817/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0740 - val_loss: 14571678.4522\n",
      "Epoch 7818/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0603 - val_loss: 14571678.4522\n",
      "Epoch 7819/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 7820/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 7821/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1367 - val_loss: 14571678.4522\n",
      "Epoch 7822/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 7823/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0472 - val_loss: 14571678.4522\n",
      "Epoch 7824/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1218 - val_loss: 14571678.4522\n",
      "Epoch 7825/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1760 - val_loss: 14571678.4522\n",
      "Epoch 7826/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0697 - val_loss: 14571678.4522\n",
      "Epoch 7827/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0525 - val_loss: 14571678.4522\n",
      "Epoch 7828/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1301 - val_loss: 14571678.4522\n",
      "Epoch 7829/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1140 - val_loss: 14571678.4522\n",
      "Epoch 7830/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 7831/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 7832/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7833/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1767 - val_loss: 14571678.4522\n",
      "Epoch 7834/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 7835/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 7836/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1707 - val_loss: 14571678.4522\n",
      "Epoch 7837/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0008 - val_loss: 14571678.4522\n",
      "Epoch 7838/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1790 - val_loss: 14571678.4522\n",
      "Epoch 7839/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1531 - val_loss: 14571678.4522\n",
      "Epoch 7840/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1828 - val_loss: 14571678.4522\n",
      "Epoch 7841/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 7842/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 7843/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1387 - val_loss: 14571678.4522\n",
      "Epoch 7844/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1560 - val_loss: 14571678.4522\n",
      "Epoch 7845/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 7846/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0966 - val_loss: 14571678.4522\n",
      "Epoch 7847/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1172 - val_loss: 14571678.4522\n",
      "Epoch 7848/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0873 - val_loss: 14571678.4522\n",
      "Epoch 7849/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1553 - val_loss: 14571678.4522\n",
      "Epoch 7850/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1170 - val_loss: 14571678.4522\n",
      "Epoch 7851/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1282 - val_loss: 14571678.4522\n",
      "Epoch 7852/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 7853/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0093 - val_loss: 14571678.4522\n",
      "Epoch 7854/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0320 - val_loss: 14571678.4522\n",
      "Epoch 7855/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 7856/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0522 - val_loss: 14571678.4522\n",
      "Epoch 7857/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2043 - val_loss: 14571678.4522\n",
      "Epoch 7858/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1170 - val_loss: 14571678.4522\n",
      "Epoch 7859/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 7860/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 7861/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 7862/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0500 - val_loss: 14571678.4522\n",
      "Epoch 7863/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0453 - val_loss: 14571678.4522\n",
      "Epoch 7864/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0798 - val_loss: 14571678.4522\n",
      "Epoch 7865/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0167 - val_loss: 14571678.4522\n",
      "Epoch 7866/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 7867/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1023 - val_loss: 14571678.4522\n",
      "Epoch 7868/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 7869/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 7870/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1782 - val_loss: 14571678.4522\n",
      "Epoch 7871/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0313 - val_loss: 14571678.4522\n",
      "Epoch 7872/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0922 - val_loss: 14571678.4522\n",
      "Epoch 7873/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 7874/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1140 - val_loss: 14571678.4522\n",
      "Epoch 7875/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0501 - val_loss: 14571678.4522\n",
      "Epoch 7876/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1367 - val_loss: 14571678.4522\n",
      "Epoch 7877/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 7878/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1408 - val_loss: 14571678.4522\n",
      "Epoch 7879/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1323 - val_loss: 14571678.4522\n",
      "Epoch 7880/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 7881/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 7882/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 7883/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1142 - val_loss: 14571678.4522\n",
      "Epoch 7884/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0856 - val_loss: 14571678.4522\n",
      "Epoch 7885/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 7886/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0362 - val_loss: 14571678.4522\n",
      "Epoch 7887/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0942 - val_loss: 14571678.4522\n",
      "Epoch 7888/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0532 - val_loss: 14571678.4522\n",
      "Epoch 7889/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0906 - val_loss: 14571678.4522\n",
      "Epoch 7890/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 7891/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0618 - val_loss: 14571678.4522\n",
      "Epoch 7892/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 7893/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 7894/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 7895/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 7896/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 7897/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0377 - val_loss: 14571678.4522\n",
      "Epoch 7898/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0745 - val_loss: 14571678.4522\n",
      "Epoch 7899/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 7900/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 7901/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 7902/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0692 - val_loss: 14571678.4522\n",
      "Epoch 7903/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1088 - val_loss: 14571678.4522\n",
      "Epoch 7904/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 7905/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1137 - val_loss: 14571678.4522\n",
      "Epoch 7906/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 7907/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 7908/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1287 - val_loss: 14571678.4522\n",
      "Epoch 7909/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1488 - val_loss: 14571678.4522\n",
      "Epoch 7910/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 7911/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0595 - val_loss: 14571678.4522\n",
      "Epoch 7912/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1790 - val_loss: 14571678.4522\n",
      "Epoch 7913/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0753 - val_loss: 14571678.4522\n",
      "Epoch 7914/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1530 - val_loss: 14571678.4522\n",
      "Epoch 7915/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0605 - val_loss: 14571678.4522\n",
      "Epoch 7916/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0018 - val_loss: 14571678.4522\n",
      "Epoch 7917/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 7918/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0935 - val_loss: 14571678.4522\n",
      "Epoch 7919/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0844 - val_loss: 14571678.4522\n",
      "Epoch 7920/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 7921/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 7922/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 7923/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0865 - val_loss: 14571678.4522\n",
      "Epoch 7924/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0402 - val_loss: 14571678.4522\n",
      "Epoch 7925/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1310 - val_loss: 14571678.4522\n",
      "Epoch 7926/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1843 - val_loss: 14571678.4522\n",
      "Epoch 7927/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 7928/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9890 - val_loss: 14571678.4522\n",
      "Epoch 7929/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 7930/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0342 - val_loss: 14571678.4522\n",
      "Epoch 7931/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 7932/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0831 - val_loss: 14571678.4522\n",
      "Epoch 7933/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1190 - val_loss: 14571678.4522\n",
      "Epoch 7934/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1398 - val_loss: 14571678.4522\n",
      "Epoch 7935/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0483 - val_loss: 14571678.4522\n",
      "Epoch 7936/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1453 - val_loss: 14571678.4522\n",
      "Epoch 7937/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0319 - val_loss: 14571678.4522\n",
      "Epoch 7938/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 7939/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1308 - val_loss: 14571678.4522\n",
      "Epoch 7940/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0548 - val_loss: 14571678.4522\n",
      "Epoch 7941/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0345 - val_loss: 14571678.4522\n",
      "Epoch 7942/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 7943/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 7944/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1471 - val_loss: 14571678.4522\n",
      "Epoch 7945/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 7946/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 7947/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0777 - val_loss: 14571678.4522\n",
      "Epoch 7948/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0400 - val_loss: 14571678.4522\n",
      "Epoch 7949/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2695 - val_loss: 14571678.4522\n",
      "Epoch 7950/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 7951/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 7952/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 7953/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 7954/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1498 - val_loss: 14571678.4522\n",
      "Epoch 7955/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1240 - val_loss: 14571678.4522\n",
      "Epoch 7956/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 7957/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 7958/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 7959/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0610 - val_loss: 14571678.4522\n",
      "Epoch 7960/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1753 - val_loss: 14571678.4522\n",
      "Epoch 7961/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0574 - val_loss: 14571678.4522\n",
      "Epoch 7962/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0455 - val_loss: 14571678.4522\n",
      "Epoch 7963/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1878 - val_loss: 14571678.4522\n",
      "Epoch 7964/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0050 - val_loss: 14571678.4522\n",
      "Epoch 7965/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0776 - val_loss: 14571678.4522\n",
      "Epoch 7966/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0612 - val_loss: 14571678.4522\n",
      "Epoch 7967/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 7968/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7969/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1610 - val_loss: 14571678.4522\n",
      "Epoch 7970/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1185 - val_loss: 14571678.4522\n",
      "Epoch 7971/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1022 - val_loss: 14571678.4522\n",
      "Epoch 7972/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0450 - val_loss: 14571678.4522\n",
      "Epoch 7973/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1203 - val_loss: 14571678.4522\n",
      "Epoch 7974/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7975/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0672 - val_loss: 14571678.4522\n",
      "Epoch 7976/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0580 - val_loss: 14571678.4522\n",
      "Epoch 7977/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0840 - val_loss: 14571678.4522\n",
      "Epoch 7978/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 7979/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 7980/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0934 - val_loss: 14571678.4522\n",
      "Epoch 7981/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 7982/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 7983/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 7984/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1375 - val_loss: 14571678.4522\n",
      "Epoch 7985/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 7986/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 7987/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7988/10000\n",
      "  128/12000 [..............................] - ETA: 0s - loss: 757290.8125"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=10000,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1Jvyjv51f7R"
   },
   "outputs": [],
   "source": [
    "incorrect_training_df = training_df[training_df['label'] == 'incorrect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErwHzzvy3tHH"
   },
   "outputs": [],
   "source": [
    " = incorrect_training_df[training_features_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-n-QS3E4fYv"
   },
   "outputs": [],
   "source": [
    "scaled_data_testing = MinMaxScaler().fit_transform(incorrect_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zx1eZhW_3x1L"
   },
   "outputs": [],
   "source": [
    "predicted = autoencoder.predict(scaled_data_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-0lKd3U4QE2"
   },
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(scaled_data_testing - predicted, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLw1uNz4rcX"
   },
   "outputs": [],
   "source": [
    "incorrect_training_df['anomaly_prediction'] = mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1205,
     "status": "ok",
     "timestamp": 1588582486844,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "xaBOmbtv4-F9",
    "outputId": "613a05d8-64b5-4ed9-aca4-e8407e0d8845"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5bbda3d630>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "incorrect_training_df['anomaly_prediction'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp_Vy12L5UdF"
   },
   "outputs": [],
   "source": [
    "predicted_correct = autoencoder.predict(scaled_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdzZXId75iOg"
   },
   "outputs": [],
   "source": [
    "mse_cor = np.mean(np.power(scaled_seqs - predicted_correct, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1TP5KyF5dx-"
   },
   "outputs": [],
   "source": [
    "correct_training_df['anomaly_prediction'] = mse_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1588582597409,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "oixCzhuD5qdm",
    "outputId": "88bc2d42-2a61-43c6-8561-47d3b2a8b908"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5bbd97d470>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_training_df['anomaly_prediction'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kvs1erDl55F3"
   },
   "outputs": [],
   "source": [
    "training_df = training_df[training_features_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uy2mf_wR6F8t"
   },
   "outputs": [],
   "source": [
    "scaled_full = MinMaxScaler().fit_transform(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4cnbztfo6Pk7"
   },
   "outputs": [],
   "source": [
    "predicted_full = autoencoder.predict(scaled_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1588582789952,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "w2mz5k3p6U8g",
    "outputId": "5f9d5d45-4ff2-498b-c5ee-070fb8dc5076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16968, 13)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSH8lZKv6dB8"
   },
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(scaled_full - predicted_full, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1848,
     "status": "ok",
     "timestamp": 1588582852254,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "gaIPkHvi6mwF",
    "outputId": "29ebb899-6d22-4055-d84e-ceae00a0802a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training_df['pred'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2861,
     "status": "ok",
     "timestamp": 1588582893220,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "RJGAP42_6yKp",
    "outputId": "f7bce735-a264-49ec-a5d2-1a007dc73539"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>cost_per_km</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>distance</th>\n",
       "      <th>time_dif</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>fare</th>\n",
       "      <th>time_driven</th>\n",
       "      <th>charge_per_hour</th>\n",
       "      <th>driving_fare</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189123628</th>\n",
       "      <td>10.5</td>\n",
       "      <td>834.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.019601</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>5.092770</td>\n",
       "      <td>834.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>270.32</td>\n",
       "      <td>778.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>259.8200</td>\n",
       "      <td>0.041286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125358</th>\n",
       "      <td>10.5</td>\n",
       "      <td>791.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>3.168058</td>\n",
       "      <td>791.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>197.85</td>\n",
       "      <td>744.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>187.3500</td>\n",
       "      <td>0.041818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125719</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.021658</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>6.305395</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>301.64</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>291.1400</td>\n",
       "      <td>0.041265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189127273</th>\n",
       "      <td>10.5</td>\n",
       "      <td>598.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.861946</td>\n",
       "      <td>598.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>82.30</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>56.1362</td>\n",
       "      <td>0.035657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189129552</th>\n",
       "      <td>10.5</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.022956</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>24.207039</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1065.02</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1054.5200</td>\n",
       "      <td>0.040784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213803193</th>\n",
       "      <td>10.5</td>\n",
       "      <td>838.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5.4219</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>2.105376</td>\n",
       "      <td>838.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>198.26</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>182.3381</td>\n",
       "      <td>0.035611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213812756</th>\n",
       "      <td>10.5</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>10.868377</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>581.23</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>570.7300</td>\n",
       "      <td>0.040546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213813930</th>\n",
       "      <td>10.5</td>\n",
       "      <td>263.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>1.045518</td>\n",
       "      <td>263.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>76.20</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>65.7000</td>\n",
       "      <td>0.042246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213815405</th>\n",
       "      <td>10.5</td>\n",
       "      <td>858.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>2.879077</td>\n",
       "      <td>858.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>133.31</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>122.8100</td>\n",
       "      <td>0.042632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213817296</th>\n",
       "      <td>10.5</td>\n",
       "      <td>262.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.2243</td>\n",
       "      <td>0.024364</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>2.115875</td>\n",
       "      <td>262.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>98.57</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>86.8457</td>\n",
       "      <td>0.035549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16968 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  ...  driving_fare      pred\n",
       "tripid                                ...                        \n",
       "189123628             10.5     834.0  ...      259.8200  0.041286\n",
       "189125358             10.5     791.0  ...      187.3500  0.041818\n",
       "189125719             10.5    1087.0  ...      291.1400  0.041265\n",
       "189127273             10.5     598.0  ...       56.1362  0.035657\n",
       "189129552             10.5    3407.0  ...     1054.5200  0.040784\n",
       "...                    ...       ...  ...           ...       ...\n",
       "213803193             10.5     838.0  ...      182.3381  0.035611\n",
       "213812756             10.5    2151.0  ...      570.7300  0.040546\n",
       "213813930             10.5     263.0  ...       65.7000  0.042246\n",
       "213815405             10.5     858.0  ...      122.8100  0.042632\n",
       "213817296             10.5     262.0  ...       86.8457  0.035549\n",
       "\n",
       "[16968 rows x 14 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUgtNX9r7AOp"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_df_temp = pd.read_csv(train_path, index_col=\"tripid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bw6JrHPn7GRg"
   },
   "outputs": [],
   "source": [
    "training_df_temp = training_df_temp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGwT9a7k7PuI"
   },
   "outputs": [],
   "source": [
    "training_df_temp['pred'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1588583084329,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "_npe66v77TQI",
    "outputId": "d47bd231-28bc-4a23-ca1c-b81b9160cfaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189123628</th>\n",
       "      <td>10.5</td>\n",
       "      <td>834.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11/1/2019 0:20</td>\n",
       "      <td>11/1/2019 0:34</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>6.90330</td>\n",
       "      <td>79.8783</td>\n",
       "      <td>270.32</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.041286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125358</th>\n",
       "      <td>10.5</td>\n",
       "      <td>791.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11/1/2019 0:56</td>\n",
       "      <td>11/1/2019 1:09</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>6.91373</td>\n",
       "      <td>79.8923</td>\n",
       "      <td>197.85</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.041818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125719</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11/1/2019 1:08</td>\n",
       "      <td>11/1/2019 1:26</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.93669</td>\n",
       "      <td>79.9146</td>\n",
       "      <td>301.64</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.041265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189127273</th>\n",
       "      <td>10.5</td>\n",
       "      <td>598.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11/1/2019 2:27</td>\n",
       "      <td>11/1/2019 2:37</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>6.92748</td>\n",
       "      <td>79.8971</td>\n",
       "      <td>82.30</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.035657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189129552</th>\n",
       "      <td>10.5</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>11/1/2019 5:38</td>\n",
       "      <td>11/1/2019 6:35</td>\n",
       "      <td>7.13402</td>\n",
       "      <td>79.8969</td>\n",
       "      <td>6.91865</td>\n",
       "      <td>79.8649</td>\n",
       "      <td>1065.02</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.040784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213803193</th>\n",
       "      <td>10.5</td>\n",
       "      <td>838.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5.4219</td>\n",
       "      <td>451.0</td>\n",
       "      <td>1/31/2020 22:07</td>\n",
       "      <td>1/31/2020 22:21</td>\n",
       "      <td>7.29073</td>\n",
       "      <td>80.6367</td>\n",
       "      <td>7.28891</td>\n",
       "      <td>80.6557</td>\n",
       "      <td>198.26</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.035611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213812756</th>\n",
       "      <td>10.5</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1/31/2020 23:07</td>\n",
       "      <td>1/31/2020 23:43</td>\n",
       "      <td>6.90569</td>\n",
       "      <td>79.8516</td>\n",
       "      <td>6.95089</td>\n",
       "      <td>79.9389</td>\n",
       "      <td>581.23</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.040546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213813930</th>\n",
       "      <td>10.5</td>\n",
       "      <td>263.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1/31/2020 23:21</td>\n",
       "      <td>1/31/2020 23:25</td>\n",
       "      <td>7.09210</td>\n",
       "      <td>79.9000</td>\n",
       "      <td>7.10135</td>\n",
       "      <td>79.9017</td>\n",
       "      <td>76.20</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.042246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213815405</th>\n",
       "      <td>10.5</td>\n",
       "      <td>858.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>317.0</td>\n",
       "      <td>1/31/2020 23:39</td>\n",
       "      <td>1/31/2020 23:53</td>\n",
       "      <td>6.94540</td>\n",
       "      <td>79.8768</td>\n",
       "      <td>6.93574</td>\n",
       "      <td>79.9010</td>\n",
       "      <td>133.31</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.042632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213817296</th>\n",
       "      <td>10.5</td>\n",
       "      <td>262.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.2243</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1/31/2020 23:49</td>\n",
       "      <td>1/31/2020 23:53</td>\n",
       "      <td>6.90257</td>\n",
       "      <td>79.9557</td>\n",
       "      <td>6.90823</td>\n",
       "      <td>79.9374</td>\n",
       "      <td>98.57</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.035549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15442 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  meter_waiting  ...     fare    label      pred\n",
       "tripid                                               ...                            \n",
       "189123628             10.5     834.0           56.0  ...   270.32  correct  0.041286\n",
       "189125358             10.5     791.0           47.0  ...   197.85  correct  0.041818\n",
       "189125719             10.5    1087.0           80.0  ...   301.64  correct  0.041265\n",
       "189127273             10.5     598.0          271.0  ...    82.30  correct  0.035657\n",
       "189129552             10.5    3407.0          182.0  ...  1065.02  correct  0.040784\n",
       "...                    ...       ...            ...  ...      ...      ...       ...\n",
       "213803193             10.5     838.0           93.0  ...   198.26  correct  0.035611\n",
       "213812756             10.5    2151.0          428.0  ...   581.23  correct  0.040546\n",
       "213813930             10.5     263.0            9.0  ...    76.20  correct  0.042246\n",
       "213815405             10.5     858.0          115.0  ...   133.31  correct  0.042632\n",
       "213817296             10.5     262.0           21.0  ...    98.57  correct  0.035549\n",
       "\n",
       "[15442 rows x 14 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_temp[training_df_temp['label'] == 'correct']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtKe71tVsKjLNIU7ofBYLX",
   "collapsed_sections": [],
   "name": "Copy of autoencorder",
   "provenance": [
    {
     "file_id": "1GuaGsrYxEgpMAryiVdUjWGNBwqz8vVWn",
     "timestamp": 1588584478296
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
