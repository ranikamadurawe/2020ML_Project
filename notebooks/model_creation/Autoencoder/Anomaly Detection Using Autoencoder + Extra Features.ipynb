{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PLEASE NOTE THAT THIS NOTEBOOK WAS RUN IN GOOGLE COLAB AS SUCH CERTAIN IMPORT STATEMENTS MAY DIFFER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4557,
     "status": "ok",
     "timestamp": 1591870165470,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "jUaEoTp3nX62",
    "outputId": "03e252ca-aca7-44e2-c3b1-5a97b84d6f7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMLARlE7odoM"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rK7kM-kBppeM"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_path=os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..', '/content/drive/My Drive/datasets/train.csv'))\n",
    "training_df = pd.read_csv(train_path, index_col=\"tripid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1jv6jOZxtmM"
   },
   "outputs": [],
   "source": [
    "training_df = training_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED75ozkwtQbb"
   },
   "outputs": [],
   "source": [
    "def dist_from_coordinates(lat1, lon1, lat2, lon2):\n",
    "  R = 6371  # Earth radius in km\n",
    "\n",
    "  #conversion to radians\n",
    "  d_lat = np.radians(lat2-lat1)\n",
    "  d_lon = np.radians(lon2-lon1)\n",
    "\n",
    "  r_lat1 = np.radians(lat1)\n",
    "  r_lat2 = np.radians(lat2)\n",
    "\n",
    "  #haversine formula\n",
    "  a = np.sin(d_lat/2.) **2 + np.cos(r_lat1) * np.cos(r_lat2) * np.sin(d_lon/2.)**2\n",
    "\n",
    "  haversine = 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "  return haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0ER9Zu9tSHe"
   },
   "outputs": [],
   "source": [
    "training_df['pickup_time'] = pd.to_datetime(training_df['pickup_time'], format=\"%m/%d/%Y %H:%M\")\n",
    "training_df['drop_time'] = pd.to_datetime(training_df['drop_time'], format=\"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8Ffh2yUuQEL"
   },
   "outputs": [],
   "source": [
    "training_df = training_df.assign(timeOfDay=pd.cut(training_df.pickup_time.dt.hour,[-1, 8, 20, 24],labels=['dawn','day', 'night']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDJHv4gVtZBN"
   },
   "outputs": [],
   "source": [
    "durations = []\n",
    "for index,row in training_df.iterrows():\n",
    "  provided_duration = row['duration'] #first row of location.lat column here\n",
    "  if math.isnan(provided_duration) or provided_duration <= 0 :\n",
    "    time_dif = (row['drop_time'] - row['pickup_time']).seconds\n",
    "    if(time_dif == 0):\n",
    "        time_dif = np.nan\n",
    "    durations.append(time_dif)\n",
    "  else :  \n",
    "    durations.append(provided_duration)\n",
    "\n",
    "training_df.insert(4,\"time_dif\",durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maXCexqwuXAB"
   },
   "outputs": [],
   "source": [
    "new_column = []                    #empty column for distance\n",
    "for index,row in training_df.iterrows():\n",
    "  lat1 = row['pick_lat'] #first row of location.lat column here\n",
    "  lon1 = row['pick_lon'] #first row of location.long column here\n",
    "  lat2 = row['drop_lat'] #second row of location.lat column here\n",
    "  lon2 = row['drop_lon'] #second row of location.long column here\n",
    "  value = dist_from_coordinates(lat1, lon1, lat2, lon2)  #get the distance\n",
    "  new_column.append(value)   #append the empty list with distance values\n",
    "\n",
    "training_df.insert(4,\"distance\",new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUUL7qjuuShC"
   },
   "outputs": [],
   "source": [
    "training_df['time_driven'] = training_df['duration']  - training_df['meter_waiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7DsSWOHuUWL"
   },
   "outputs": [],
   "source": [
    "chargeperhours = []\n",
    "for index,row in training_df.iterrows():\n",
    "    if(row['meter_waiting'] == 0):\n",
    "        chargeperhour = 0\n",
    "    else:\n",
    "        chargeperhour = (row['meter_waiting_fare'] / row['meter_waiting'])\n",
    "    chargeperhours.append(chargeperhour)\n",
    "\n",
    "training_df.insert(4,'charge_per_hour',chargeperhours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szAPuXJ9ur_5"
   },
   "outputs": [],
   "source": [
    "training_df['driving_fare'] = training_df['fare']  - training_df['meter_waiting_fare'] - training_df['additional_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1KGgvV9uu5X"
   },
   "outputs": [],
   "source": [
    "avgspeeds = []\n",
    "for index,row in training_df.iterrows():\n",
    "    if(row['time_driven'] == 0):\n",
    "        avgspeed = 0    \n",
    "    else:\n",
    "        avgspeed = (row['distance'] / row['time_driven'])\n",
    "    avgspeeds.append(avgspeed)\n",
    "\n",
    "training_df.insert(4,\"avg_speed\",avgspeeds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wq6qOBghuxfr"
   },
   "outputs": [],
   "source": [
    "costsperkm = []\n",
    "for index,row in training_df.iterrows():\n",
    "    if row['driving_fare'] == 0:\n",
    "        costperkm = 0\n",
    "            \n",
    "    else:\n",
    "        costperkm = (row['distance'] / row['driving_fare'])\n",
    "    costsperkm.append(costperkm)\n",
    "\n",
    "training_df.insert(4,\"cost_per_km\",costsperkm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KliU6BiLzyFt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1929,
     "status": "ok",
     "timestamp": 1588581456561,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "wnBaVUvju_RB",
    "outputId": "2851fb2d-9338-4672-f8ae-9ab2486e4319"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
       "       'cost_per_km', 'avg_speed', 'charge_per_hour', 'distance', 'time_dif',\n",
       "       'meter_waiting_till_pickup', 'pickup_time', 'drop_time', 'pick_lat',\n",
       "       'pick_lon', 'drop_lat', 'drop_lon', 'fare', 'label', 'timeOfDay',\n",
       "       'time_driven', 'driving_fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evN3ZUMhrt6z"
   },
   "outputs": [],
   "source": [
    "training_features_labels = ['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'cost_per_km', 'avg_speed', 'distance', 'time_dif',\n",
    "       'meter_waiting_till_pickup', 'fare',\n",
    "       'time_driven', 'charge_per_hour', 'driving_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kG1yQPf6ryTh"
   },
   "outputs": [],
   "source": [
    "correct_training_df = training_df[training_df['label'] == 'correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwxbcqkDsmZG"
   },
   "outputs": [],
   "source": [
    "correct_training_df = correct_training_df[training_features_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1588583143259,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "BlZu8olgxSha",
    "outputId": "1fe1d273-0a2e-400f-a61e-5fcbaa716604"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "additional_fare              0\n",
       "duration                     0\n",
       "meter_waiting                0\n",
       "meter_waiting_fare           0\n",
       "cost_per_km                  0\n",
       "avg_speed                    0\n",
       "distance                     0\n",
       "time_dif                     0\n",
       "meter_waiting_till_pickup    0\n",
       "fare                         0\n",
       "time_driven                  0\n",
       "charge_per_hour              0\n",
       "driving_fare                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_training_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsNZwHrlvc7B"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# scaled_seqs = scaler.fit_transform(correct_training_df )\n",
    "scaled_seqs = correct_training_df\n",
    "#Create a test and train sets of our data\n",
    "X_train = scaled_seqs[:12000]\n",
    "X_test = scaled_seqs[12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHjfiP4zwCe2"
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmwiT1fGoXRT"
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1] # the # features\n",
    "encoding_dim = 8 # first layer\n",
    "hidden_dim = int(encoding_dim / 2) #hideen layer\n",
    "\n",
    "nb_epoch = 30\n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(encoding_dim, activation='relu')(encoder)\n",
    "decoder = Dense(input_dim, activation='tanh')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# ----- some data omitted --------- #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnXDbzCXwfpR"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1628194,
     "status": "ok",
     "timestamp": 1588584808439,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "yj6iWgg1we6M",
    "outputId": "4780ffc1-a761-461a-f24d-afc47bd71b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0848 - val_loss: 14571678.4522\n",
      "Epoch 7502/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 7503/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 7504/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 7505/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 7506/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 7507/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0828 - val_loss: 14571678.4522\n",
      "Epoch 7508/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9650 - val_loss: 14571678.4522\n",
      "Epoch 7509/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 7510/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1343 - val_loss: 14571678.4522\n",
      "Epoch 7511/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 7512/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1757 - val_loss: 14571678.4522\n",
      "Epoch 7513/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1697 - val_loss: 14571678.4522\n",
      "Epoch 7514/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 7515/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 7516/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 7517/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1184 - val_loss: 14571678.4522\n",
      "Epoch 7518/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 7519/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1503 - val_loss: 14571678.4522\n",
      "Epoch 7520/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1212 - val_loss: 14571678.4522\n",
      "Epoch 7521/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9965 - val_loss: 14571678.4522\n",
      "Epoch 7522/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0385 - val_loss: 14571678.4522\n",
      "Epoch 7523/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 7524/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0393 - val_loss: 14571678.4522\n",
      "Epoch 7525/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0877 - val_loss: 14571678.4522\n",
      "Epoch 7526/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1118 - val_loss: 14571678.4522\n",
      "Epoch 7527/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 7528/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1820 - val_loss: 14571678.4522\n",
      "Epoch 7529/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0502 - val_loss: 14571678.4522\n",
      "Epoch 7530/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1292 - val_loss: 14571678.4522\n",
      "Epoch 7531/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 7532/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 7533/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0194 - val_loss: 14571678.4522\n",
      "Epoch 7534/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 7535/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 7536/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 7537/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0912 - val_loss: 14571678.4522\n",
      "Epoch 7538/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 7539/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1450 - val_loss: 14571678.4522\n",
      "Epoch 7540/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0997 - val_loss: 14571678.4522\n",
      "Epoch 7541/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 7542/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1025 - val_loss: 14571678.4522\n",
      "Epoch 7543/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 7544/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1078 - val_loss: 14571678.4522\n",
      "Epoch 7545/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0962 - val_loss: 14571678.4522\n",
      "Epoch 7546/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0390 - val_loss: 14571678.4522\n",
      "Epoch 7547/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0255 - val_loss: 14571678.4522\n",
      "Epoch 7548/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1562 - val_loss: 14571678.4522\n",
      "Epoch 7549/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0448 - val_loss: 14571678.4522\n",
      "Epoch 7550/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1125 - val_loss: 14571678.4522\n",
      "Epoch 7551/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1138 - val_loss: 14571678.4522\n",
      "Epoch 7552/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 7553/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1280 - val_loss: 14571678.4522\n",
      "Epoch 7554/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 7555/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 7556/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 7557/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1302 - val_loss: 14571678.4522\n",
      "Epoch 7558/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1312 - val_loss: 14571678.4522\n",
      "Epoch 7559/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 7560/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0289 - val_loss: 14571678.4522\n",
      "Epoch 7561/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 7562/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0487 - val_loss: 14571678.4522\n",
      "Epoch 7563/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0985 - val_loss: 14571678.4522\n",
      "Epoch 7564/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 7565/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1627 - val_loss: 14571678.4522\n",
      "Epoch 7566/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1519 - val_loss: 14571678.4522\n",
      "Epoch 7567/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 7568/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1717 - val_loss: 14571678.4522\n",
      "Epoch 7569/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1260 - val_loss: 14571678.4522\n",
      "Epoch 7570/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1814 - val_loss: 14571678.4522\n",
      "Epoch 7571/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0732 - val_loss: 14571678.4522\n",
      "Epoch 7572/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9720 - val_loss: 14571678.4522\n",
      "Epoch 7573/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 7574/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1075 - val_loss: 14571678.4522\n",
      "Epoch 7575/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0513 - val_loss: 14571678.4522\n",
      "Epoch 7576/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0865 - val_loss: 14571678.4522\n",
      "Epoch 7577/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1475 - val_loss: 14571678.4522\n",
      "Epoch 7578/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1312 - val_loss: 14571678.4522\n",
      "Epoch 7579/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 7580/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1015 - val_loss: 14571678.4522\n",
      "Epoch 7581/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0658 - val_loss: 14571678.4522\n",
      "Epoch 7582/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0825 - val_loss: 14571678.4522\n",
      "Epoch 7583/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0575 - val_loss: 14571678.4522\n",
      "Epoch 7584/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0018 - val_loss: 14571678.4522\n",
      "Epoch 7585/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1583 - val_loss: 14571678.4522\n",
      "Epoch 7586/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 7587/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0220 - val_loss: 14571678.4522\n",
      "Epoch 7588/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1253 - val_loss: 14571678.4522\n",
      "Epoch 7589/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0901 - val_loss: 14571678.4522\n",
      "Epoch 7590/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1928 - val_loss: 14571678.4522\n",
      "Epoch 7591/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0310 - val_loss: 14571678.4522\n",
      "Epoch 7592/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 7593/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1218 - val_loss: 14571678.4522\n",
      "Epoch 7594/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0217 - val_loss: 14571678.4522\n",
      "Epoch 7595/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 7596/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0322 - val_loss: 14571678.4522\n",
      "Epoch 7597/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0356 - val_loss: 14571678.4522\n",
      "Epoch 7598/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 7599/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 7600/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7601/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0560 - val_loss: 14571678.4522\n",
      "Epoch 7602/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0670 - val_loss: 14571678.4522\n",
      "Epoch 7603/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 7604/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1015 - val_loss: 14571678.4522\n",
      "Epoch 7605/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 7606/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2183 - val_loss: 14571678.4522\n",
      "Epoch 7607/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0573 - val_loss: 14571678.4522\n",
      "Epoch 7608/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9770 - val_loss: 14571678.4522\n",
      "Epoch 7609/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0795 - val_loss: 14571678.4522\n",
      "Epoch 7610/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 7611/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1198 - val_loss: 14571678.4522\n",
      "Epoch 7612/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 7613/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0365 - val_loss: 14571678.4522\n",
      "Epoch 7614/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1427 - val_loss: 14571678.4522\n",
      "Epoch 7615/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1328 - val_loss: 14571678.4522\n",
      "Epoch 7616/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1395 - val_loss: 14571678.4522\n",
      "Epoch 7617/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 7618/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 7619/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 7620/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7621/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 7622/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 7623/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 7624/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0673 - val_loss: 14571678.4522\n",
      "Epoch 7625/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0992 - val_loss: 14571678.4522\n",
      "Epoch 7626/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 7627/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 7628/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0512 - val_loss: 14571678.4522\n",
      "Epoch 7629/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0812 - val_loss: 14571678.4522\n",
      "Epoch 7630/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1198 - val_loss: 14571678.4522\n",
      "Epoch 7631/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1060 - val_loss: 14571678.4522\n",
      "Epoch 7632/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0512 - val_loss: 14571678.4522\n",
      "Epoch 7633/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0608 - val_loss: 14571678.4522\n",
      "Epoch 7634/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0690 - val_loss: 14571678.4522\n",
      "Epoch 7635/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0877 - val_loss: 14571678.4522\n",
      "Epoch 7636/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 7637/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 7638/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0817 - val_loss: 14571678.4522\n",
      "Epoch 7639/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0728 - val_loss: 14571678.4522\n",
      "Epoch 7640/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1383 - val_loss: 14571678.4522\n",
      "Epoch 7641/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 7642/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1752 - val_loss: 14571678.4522\n",
      "Epoch 7643/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 7644/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0363 - val_loss: 14571678.4522\n",
      "Epoch 7645/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0903 - val_loss: 14571678.4522\n",
      "Epoch 7646/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 7647/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 7648/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0882 - val_loss: 14571678.4522\n",
      "Epoch 7649/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 7650/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1002 - val_loss: 14571678.4522\n",
      "Epoch 7651/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 7652/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 7653/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1597 - val_loss: 14571678.4522\n",
      "Epoch 7654/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 7655/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 7656/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 7657/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1257 - val_loss: 14571678.4522\n",
      "Epoch 7658/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7659/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1402 - val_loss: 14571678.4522\n",
      "Epoch 7660/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 7661/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0433 - val_loss: 14571678.4522\n",
      "Epoch 7662/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 7663/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 7664/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1333 - val_loss: 14571678.4522\n",
      "Epoch 7665/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1468 - val_loss: 14571678.4522\n",
      "Epoch 7666/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1264 - val_loss: 14571678.4522\n",
      "Epoch 7667/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1138 - val_loss: 14571678.4522\n",
      "Epoch 7668/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0495 - val_loss: 14571678.4522\n",
      "Epoch 7669/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0396 - val_loss: 14571678.4522\n",
      "Epoch 7670/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0613 - val_loss: 14571678.4522\n",
      "Epoch 7671/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0525 - val_loss: 14571678.4522\n",
      "Epoch 7672/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 7673/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0760 - val_loss: 14571678.4522\n",
      "Epoch 7674/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 7675/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 7676/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 7677/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 7678/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 7679/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 7680/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0389 - val_loss: 14571678.4522\n",
      "Epoch 7681/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0708 - val_loss: 14571678.4522\n",
      "Epoch 7682/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0617 - val_loss: 14571678.4522\n",
      "Epoch 7683/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 7684/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 7685/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1672 - val_loss: 14571678.4522\n",
      "Epoch 7686/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7687/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1313 - val_loss: 14571678.4522\n",
      "Epoch 7688/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9863 - val_loss: 14571678.4522\n",
      "Epoch 7689/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1663 - val_loss: 14571678.4522\n",
      "Epoch 7690/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0498 - val_loss: 14571678.4522\n",
      "Epoch 7691/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1283 - val_loss: 14571678.4522\n",
      "Epoch 7692/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1357 - val_loss: 14571678.4522\n",
      "Epoch 7693/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 7694/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0982 - val_loss: 14571678.4522\n",
      "Epoch 7695/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7696/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1657 - val_loss: 14571678.4522\n",
      "Epoch 7697/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 7698/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 7699/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1110 - val_loss: 14571678.4522\n",
      "Epoch 7700/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0360 - val_loss: 14571678.4522\n",
      "Epoch 7701/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 7702/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 7703/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 7704/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1090 - val_loss: 14571678.4522\n",
      "Epoch 7705/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 7706/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0516 - val_loss: 14571678.4522\n",
      "Epoch 7707/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 7708/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1590 - val_loss: 14571678.4522\n",
      "Epoch 7709/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1460 - val_loss: 14571678.4522\n",
      "Epoch 7710/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 7711/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1627 - val_loss: 14571678.4522\n",
      "Epoch 7712/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0573 - val_loss: 14571678.4522\n",
      "Epoch 7713/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 7714/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1742 - val_loss: 14571678.4522\n",
      "Epoch 7715/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0417 - val_loss: 14571678.4522\n",
      "Epoch 7716/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1435 - val_loss: 14571678.4522\n",
      "Epoch 7717/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 7718/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1277 - val_loss: 14571678.4522\n",
      "Epoch 7719/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 7720/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 7721/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 7722/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 7723/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0458 - val_loss: 14571678.4522\n",
      "Epoch 7724/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 7725/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1547 - val_loss: 14571678.4522\n",
      "Epoch 7726/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1493 - val_loss: 14571678.4522\n",
      "Epoch 7727/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1105 - val_loss: 14571678.4522\n",
      "Epoch 7728/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0550 - val_loss: 14571678.4522\n",
      "Epoch 7729/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 7730/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1487 - val_loss: 14571678.4522\n",
      "Epoch 7731/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 7732/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7733/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 7734/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0300 - val_loss: 14571678.4522\n",
      "Epoch 7735/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1397 - val_loss: 14571678.4522\n",
      "Epoch 7736/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0328 - val_loss: 14571678.4522\n",
      "Epoch 7737/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 7738/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7739/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0765 - val_loss: 14571678.4522\n",
      "Epoch 7740/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 7741/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0150 - val_loss: 14571678.4522\n",
      "Epoch 7742/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 7743/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 7744/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 7745/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0976 - val_loss: 14571678.4522\n",
      "Epoch 7746/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1247 - val_loss: 14571678.4522\n",
      "Epoch 7747/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0263 - val_loss: 14571678.4522\n",
      "Epoch 7748/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 7749/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 7750/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0147 - val_loss: 14571678.4522\n",
      "Epoch 7751/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1160 - val_loss: 14571678.4522\n",
      "Epoch 7752/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 7753/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0020 - val_loss: 14571678.4522\n",
      "Epoch 7754/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 7755/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 7756/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 7757/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0567 - val_loss: 14571678.4522\n",
      "Epoch 7758/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7759/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 7760/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0682 - val_loss: 14571678.4522\n",
      "Epoch 7761/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9793 - val_loss: 14571678.4522\n",
      "Epoch 7762/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0920 - val_loss: 14571678.4522\n",
      "Epoch 7763/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7764/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0343 - val_loss: 14571678.4522\n",
      "Epoch 7765/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0950 - val_loss: 14571678.4522\n",
      "Epoch 7766/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 7767/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1842 - val_loss: 14571678.4522\n",
      "Epoch 7768/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7769/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 7770/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0663 - val_loss: 14571678.4522\n",
      "Epoch 7771/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 7772/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 7773/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0137 - val_loss: 14571678.4522\n",
      "Epoch 7774/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1272 - val_loss: 14571678.4522\n",
      "Epoch 7775/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0138 - val_loss: 14571678.4522\n",
      "Epoch 7776/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0835 - val_loss: 14571678.4522\n",
      "Epoch 7777/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 7778/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0748 - val_loss: 14571678.4522\n",
      "Epoch 7779/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 7780/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 7781/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 7782/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 7783/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1602 - val_loss: 14571678.4522\n",
      "Epoch 7784/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530844.9425 - val_loss: 14571678.4522\n",
      "Epoch 7785/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 7786/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0676 - val_loss: 14571678.4522\n",
      "Epoch 7787/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 7788/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 7789/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 7790/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 7791/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0975 - val_loss: 14571678.4522\n",
      "Epoch 7792/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0714 - val_loss: 14571678.4522\n",
      "Epoch 7793/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0112 - val_loss: 14571678.4522\n",
      "Epoch 7794/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0863 - val_loss: 14571678.4522\n",
      "Epoch 7795/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0615 - val_loss: 14571678.4522\n",
      "Epoch 7796/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 7797/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 7798/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 7799/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0655 - val_loss: 14571678.4522\n",
      "Epoch 7800/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0958 - val_loss: 14571678.4522\n",
      "Epoch 7801/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0705 - val_loss: 14571678.4522\n",
      "Epoch 7802/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0878 - val_loss: 14571678.4522\n",
      "Epoch 7803/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 7804/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7805/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0838 - val_loss: 14571678.4522\n",
      "Epoch 7806/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0115 - val_loss: 14571678.4522\n",
      "Epoch 7807/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0110 - val_loss: 14571678.4522\n",
      "Epoch 7808/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0827 - val_loss: 14571678.4522\n",
      "Epoch 7809/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 7810/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0942 - val_loss: 14571678.4522\n",
      "Epoch 7811/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1302 - val_loss: 14571678.4522\n",
      "Epoch 7812/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0908 - val_loss: 14571678.4522\n",
      "Epoch 7813/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1187 - val_loss: 14571678.4522\n",
      "Epoch 7814/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0903 - val_loss: 14571678.4522\n",
      "Epoch 7815/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 7816/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 7817/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0740 - val_loss: 14571678.4522\n",
      "Epoch 7818/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0603 - val_loss: 14571678.4522\n",
      "Epoch 7819/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 7820/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 7821/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1367 - val_loss: 14571678.4522\n",
      "Epoch 7822/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 7823/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0472 - val_loss: 14571678.4522\n",
      "Epoch 7824/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1218 - val_loss: 14571678.4522\n",
      "Epoch 7825/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1760 - val_loss: 14571678.4522\n",
      "Epoch 7826/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0697 - val_loss: 14571678.4522\n",
      "Epoch 7827/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0525 - val_loss: 14571678.4522\n",
      "Epoch 7828/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1301 - val_loss: 14571678.4522\n",
      "Epoch 7829/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1140 - val_loss: 14571678.4522\n",
      "Epoch 7830/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 7831/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 7832/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7833/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1767 - val_loss: 14571678.4522\n",
      "Epoch 7834/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 7835/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 7836/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1707 - val_loss: 14571678.4522\n",
      "Epoch 7837/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0008 - val_loss: 14571678.4522\n",
      "Epoch 7838/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1790 - val_loss: 14571678.4522\n",
      "Epoch 7839/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1531 - val_loss: 14571678.4522\n",
      "Epoch 7840/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1828 - val_loss: 14571678.4522\n",
      "Epoch 7841/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 7842/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 7843/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1387 - val_loss: 14571678.4522\n",
      "Epoch 7844/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1560 - val_loss: 14571678.4522\n",
      "Epoch 7845/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 7846/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0966 - val_loss: 14571678.4522\n",
      "Epoch 7847/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1172 - val_loss: 14571678.4522\n",
      "Epoch 7848/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0873 - val_loss: 14571678.4522\n",
      "Epoch 7849/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1553 - val_loss: 14571678.4522\n",
      "Epoch 7850/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1170 - val_loss: 14571678.4522\n",
      "Epoch 7851/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1282 - val_loss: 14571678.4522\n",
      "Epoch 7852/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 7853/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0093 - val_loss: 14571678.4522\n",
      "Epoch 7854/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0320 - val_loss: 14571678.4522\n",
      "Epoch 7855/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 7856/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0522 - val_loss: 14571678.4522\n",
      "Epoch 7857/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2043 - val_loss: 14571678.4522\n",
      "Epoch 7858/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1170 - val_loss: 14571678.4522\n",
      "Epoch 7859/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 7860/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 7861/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 7862/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0500 - val_loss: 14571678.4522\n",
      "Epoch 7863/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0453 - val_loss: 14571678.4522\n",
      "Epoch 7864/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0798 - val_loss: 14571678.4522\n",
      "Epoch 7865/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0167 - val_loss: 14571678.4522\n",
      "Epoch 7866/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 7867/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1023 - val_loss: 14571678.4522\n",
      "Epoch 7868/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 7869/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 7870/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1782 - val_loss: 14571678.4522\n",
      "Epoch 7871/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0313 - val_loss: 14571678.4522\n",
      "Epoch 7872/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0922 - val_loss: 14571678.4522\n",
      "Epoch 7873/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 7874/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1140 - val_loss: 14571678.4522\n",
      "Epoch 7875/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0501 - val_loss: 14571678.4522\n",
      "Epoch 7876/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1367 - val_loss: 14571678.4522\n",
      "Epoch 7877/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 7878/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1408 - val_loss: 14571678.4522\n",
      "Epoch 7879/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1323 - val_loss: 14571678.4522\n",
      "Epoch 7880/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 7881/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 7882/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 7883/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1142 - val_loss: 14571678.4522\n",
      "Epoch 7884/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0856 - val_loss: 14571678.4522\n",
      "Epoch 7885/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 7886/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0362 - val_loss: 14571678.4522\n",
      "Epoch 7887/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0942 - val_loss: 14571678.4522\n",
      "Epoch 7888/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0532 - val_loss: 14571678.4522\n",
      "Epoch 7889/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0906 - val_loss: 14571678.4522\n",
      "Epoch 7890/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 7891/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0618 - val_loss: 14571678.4522\n",
      "Epoch 7892/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 7893/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 7894/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 7895/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 7896/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 7897/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0377 - val_loss: 14571678.4522\n",
      "Epoch 7898/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0745 - val_loss: 14571678.4522\n",
      "Epoch 7899/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 7900/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 7901/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 7902/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0692 - val_loss: 14571678.4522\n",
      "Epoch 7903/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1088 - val_loss: 14571678.4522\n",
      "Epoch 7904/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 7905/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1137 - val_loss: 14571678.4522\n",
      "Epoch 7906/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 7907/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 7908/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1287 - val_loss: 14571678.4522\n",
      "Epoch 7909/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1488 - val_loss: 14571678.4522\n",
      "Epoch 7910/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 7911/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0595 - val_loss: 14571678.4522\n",
      "Epoch 7912/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1790 - val_loss: 14571678.4522\n",
      "Epoch 7913/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0753 - val_loss: 14571678.4522\n",
      "Epoch 7914/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1530 - val_loss: 14571678.4522\n",
      "Epoch 7915/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0605 - val_loss: 14571678.4522\n",
      "Epoch 7916/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0018 - val_loss: 14571678.4522\n",
      "Epoch 7917/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 7918/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0935 - val_loss: 14571678.4522\n",
      "Epoch 7919/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0844 - val_loss: 14571678.4522\n",
      "Epoch 7920/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 7921/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 7922/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 7923/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0865 - val_loss: 14571678.4522\n",
      "Epoch 7924/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0402 - val_loss: 14571678.4522\n",
      "Epoch 7925/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1310 - val_loss: 14571678.4522\n",
      "Epoch 7926/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1843 - val_loss: 14571678.4522\n",
      "Epoch 7927/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 7928/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9890 - val_loss: 14571678.4522\n",
      "Epoch 7929/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 7930/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0342 - val_loss: 14571678.4522\n",
      "Epoch 7931/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 7932/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0831 - val_loss: 14571678.4522\n",
      "Epoch 7933/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1190 - val_loss: 14571678.4522\n",
      "Epoch 7934/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1398 - val_loss: 14571678.4522\n",
      "Epoch 7935/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0483 - val_loss: 14571678.4522\n",
      "Epoch 7936/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1453 - val_loss: 14571678.4522\n",
      "Epoch 7937/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0319 - val_loss: 14571678.4522\n",
      "Epoch 7938/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 7939/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1308 - val_loss: 14571678.4522\n",
      "Epoch 7940/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0548 - val_loss: 14571678.4522\n",
      "Epoch 7941/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0345 - val_loss: 14571678.4522\n",
      "Epoch 7942/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 7943/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 7944/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1471 - val_loss: 14571678.4522\n",
      "Epoch 7945/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 7946/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 7947/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0777 - val_loss: 14571678.4522\n",
      "Epoch 7948/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0400 - val_loss: 14571678.4522\n",
      "Epoch 7949/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2695 - val_loss: 14571678.4522\n",
      "Epoch 7950/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 7951/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 7952/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 7953/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 7954/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1498 - val_loss: 14571678.4522\n",
      "Epoch 7955/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1240 - val_loss: 14571678.4522\n",
      "Epoch 7956/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 7957/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 7958/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 7959/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0610 - val_loss: 14571678.4522\n",
      "Epoch 7960/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1753 - val_loss: 14571678.4522\n",
      "Epoch 7961/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0574 - val_loss: 14571678.4522\n",
      "Epoch 7962/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0455 - val_loss: 14571678.4522\n",
      "Epoch 7963/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1878 - val_loss: 14571678.4522\n",
      "Epoch 7964/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0050 - val_loss: 14571678.4522\n",
      "Epoch 7965/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0776 - val_loss: 14571678.4522\n",
      "Epoch 7966/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0612 - val_loss: 14571678.4522\n",
      "Epoch 7967/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 7968/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 7969/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1610 - val_loss: 14571678.4522\n",
      "Epoch 7970/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1185 - val_loss: 14571678.4522\n",
      "Epoch 7971/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1022 - val_loss: 14571678.4522\n",
      "Epoch 7972/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0450 - val_loss: 14571678.4522\n",
      "Epoch 7973/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1203 - val_loss: 14571678.4522\n",
      "Epoch 7974/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 7975/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0672 - val_loss: 14571678.4522\n",
      "Epoch 7976/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0580 - val_loss: 14571678.4522\n",
      "Epoch 7977/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0840 - val_loss: 14571678.4522\n",
      "Epoch 7978/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 7979/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 7980/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0934 - val_loss: 14571678.4522\n",
      "Epoch 7981/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 7982/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 7983/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 7984/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1375 - val_loss: 14571678.4522\n",
      "Epoch 7985/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 7986/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 7987/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 7988/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 7989/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0383 - val_loss: 14571678.4522\n",
      "Epoch 7990/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0532 - val_loss: 14571678.4522\n",
      "Epoch 7991/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0283 - val_loss: 14571678.4522\n",
      "Epoch 7992/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0653 - val_loss: 14571678.4522\n",
      "Epoch 7993/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0972 - val_loss: 14571678.4522\n",
      "Epoch 7994/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0582 - val_loss: 14571678.4522\n",
      "Epoch 7995/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 7996/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 7997/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 7998/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 7999/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1097 - val_loss: 14571678.4522\n",
      "Epoch 8000/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0657 - val_loss: 14571678.4522\n",
      "Epoch 8001/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0835 - val_loss: 14571678.4522\n",
      "Epoch 8002/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1238 - val_loss: 14571678.4522\n",
      "Epoch 8003/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0765 - val_loss: 14571678.4522\n",
      "Epoch 8004/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1282 - val_loss: 14571678.4522\n",
      "Epoch 8005/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 8006/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1487 - val_loss: 14571678.4522\n",
      "Epoch 8007/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0160 - val_loss: 14571678.4522\n",
      "Epoch 8008/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 8009/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1793 - val_loss: 14571678.4522\n",
      "Epoch 8010/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0480 - val_loss: 14571678.4522\n",
      "Epoch 8011/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0932 - val_loss: 14571678.4522\n",
      "Epoch 8012/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 8013/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 8014/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 8015/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1720 - val_loss: 14571678.4522\n",
      "Epoch 8016/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 8017/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 8018/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 8019/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1313 - val_loss: 14571678.4522\n",
      "Epoch 8020/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9800 - val_loss: 14571678.4522\n",
      "Epoch 8021/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1700 - val_loss: 14571678.4522\n",
      "Epoch 8022/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0617 - val_loss: 14571678.4522\n",
      "Epoch 8023/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1005 - val_loss: 14571678.4522\n",
      "Epoch 8024/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0300 - val_loss: 14571678.4522\n",
      "Epoch 8025/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 8026/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 8027/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 8028/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 8029/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 8030/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1098 - val_loss: 14571678.4522\n",
      "Epoch 8031/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1183 - val_loss: 14571678.4522\n",
      "Epoch 8032/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 8033/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1410 - val_loss: 14571678.4522\n",
      "Epoch 8034/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0370 - val_loss: 14571678.4522\n",
      "Epoch 8035/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 8036/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1337 - val_loss: 14571678.4522\n",
      "Epoch 8037/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 8038/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0483 - val_loss: 14571678.4522\n",
      "Epoch 8039/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1092 - val_loss: 14571678.4522\n",
      "Epoch 8040/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0996 - val_loss: 14571678.4522\n",
      "Epoch 8041/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0029 - val_loss: 14571678.4522\n",
      "Epoch 8042/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1167 - val_loss: 14571678.4522\n",
      "Epoch 8043/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0747 - val_loss: 14571678.4522\n",
      "Epoch 8044/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1612 - val_loss: 14571678.4522\n",
      "Epoch 8045/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 8046/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0760 - val_loss: 14571678.4522\n",
      "Epoch 8047/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0395 - val_loss: 14571678.4522\n",
      "Epoch 8048/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0688 - val_loss: 14571678.4522\n",
      "Epoch 8049/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1215 - val_loss: 14571678.4522\n",
      "Epoch 8050/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0904 - val_loss: 14571678.4522\n",
      "Epoch 8051/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 8052/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0232 - val_loss: 14571678.4522\n",
      "Epoch 8053/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0137 - val_loss: 14571678.4522\n",
      "Epoch 8054/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1573 - val_loss: 14571678.4522\n",
      "Epoch 8055/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 8056/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1465 - val_loss: 14571678.4522\n",
      "Epoch 8057/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 8058/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0423 - val_loss: 14571678.4522\n",
      "Epoch 8059/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 8060/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 8061/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9750 - val_loss: 14571678.4522\n",
      "Epoch 8062/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0705 - val_loss: 14571678.4522\n",
      "Epoch 8063/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 8064/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 8065/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1757 - val_loss: 14571678.4522\n",
      "Epoch 8066/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1427 - val_loss: 14571678.4522\n",
      "Epoch 8067/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 8068/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1280 - val_loss: 14571678.4522\n",
      "Epoch 8069/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1357 - val_loss: 14571678.4522\n",
      "Epoch 8070/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 8071/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1232 - val_loss: 14571678.4522\n",
      "Epoch 8072/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0157 - val_loss: 14571678.4522\n",
      "Epoch 8073/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0698 - val_loss: 14571678.4522\n",
      "Epoch 8074/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 8075/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0697 - val_loss: 14571678.4522\n",
      "Epoch 8076/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0900 - val_loss: 14571678.4522\n",
      "Epoch 8077/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1503 - val_loss: 14571678.4522\n",
      "Epoch 8078/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0487 - val_loss: 14571678.4522\n",
      "Epoch 8079/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0659 - val_loss: 14571678.4522\n",
      "Epoch 8080/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 8081/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 8082/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1279 - val_loss: 14571678.4522\n",
      "Epoch 8083/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9811 - val_loss: 14571678.4522\n",
      "Epoch 8084/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0500 - val_loss: 14571678.4522\n",
      "Epoch 8085/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 8086/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0463 - val_loss: 14571678.4522\n",
      "Epoch 8087/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 8088/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 8089/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 8090/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 8091/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0327 - val_loss: 14571678.4522\n",
      "Epoch 8092/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0998 - val_loss: 14571678.4522\n",
      "Epoch 8093/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 8094/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 8095/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9895 - val_loss: 14571678.4522\n",
      "Epoch 8096/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1330 - val_loss: 14571678.4522\n",
      "Epoch 8097/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 8098/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1387 - val_loss: 14571678.4522\n",
      "Epoch 8099/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0417 - val_loss: 14571678.4522\n",
      "Epoch 8100/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1205 - val_loss: 14571678.4522\n",
      "Epoch 8101/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 8102/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9733 - val_loss: 14571678.4522\n",
      "Epoch 8103/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1397 - val_loss: 14571678.4522\n",
      "Epoch 8104/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1005 - val_loss: 14571678.4522\n",
      "Epoch 8105/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 8106/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9893 - val_loss: 14571678.4522\n",
      "Epoch 8107/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0297 - val_loss: 14571678.4522\n",
      "Epoch 8108/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 8109/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0663 - val_loss: 14571678.4522\n",
      "Epoch 8110/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 8111/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 8112/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 8113/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 8114/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1603 - val_loss: 14571678.4522\n",
      "Epoch 8115/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0137 - val_loss: 14571678.4522\n",
      "Epoch 8116/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0199 - val_loss: 14571678.4522\n",
      "Epoch 8117/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 8118/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 8119/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0782 - val_loss: 14571678.4522\n",
      "Epoch 8120/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1723 - val_loss: 14571678.4522\n",
      "Epoch 8121/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0620 - val_loss: 14571678.4522\n",
      "Epoch 8122/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 8123/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 8124/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1050 - val_loss: 14571678.4522\n",
      "Epoch 8125/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1265 - val_loss: 14571678.4522\n",
      "Epoch 8126/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0928 - val_loss: 14571678.4522\n",
      "Epoch 8127/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0987 - val_loss: 14571678.4522\n",
      "Epoch 8128/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 8129/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0993 - val_loss: 14571678.4522\n",
      "Epoch 8130/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 8131/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 8132/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 8133/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1755 - val_loss: 14571678.4522\n",
      "Epoch 8134/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 8135/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1030 - val_loss: 14571678.4522\n",
      "Epoch 8136/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 8137/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1088 - val_loss: 14571678.4522\n",
      "Epoch 8138/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 8139/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0895 - val_loss: 14571678.4522\n",
      "Epoch 8140/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0970 - val_loss: 14571678.4522\n",
      "Epoch 8141/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1200 - val_loss: 14571678.4522\n",
      "Epoch 8142/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1173 - val_loss: 14571678.4522\n",
      "Epoch 8143/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1363 - val_loss: 14571678.4522\n",
      "Epoch 8144/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1090 - val_loss: 14571678.4522\n",
      "Epoch 8145/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0733 - val_loss: 14571678.4522\n",
      "Epoch 8146/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 8147/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0598 - val_loss: 14571678.4522\n",
      "Epoch 8148/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1463 - val_loss: 14571678.4522\n",
      "Epoch 8149/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0895 - val_loss: 14571678.4522\n",
      "Epoch 8150/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 8151/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1235 - val_loss: 14571678.4522\n",
      "Epoch 8152/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1730 - val_loss: 14571678.4522\n",
      "Epoch 8153/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0787 - val_loss: 14571678.4522\n",
      "Epoch 8154/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1053 - val_loss: 14571678.4522\n",
      "Epoch 8155/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1517 - val_loss: 14571678.4522\n",
      "Epoch 8156/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0153 - val_loss: 14571678.4522\n",
      "Epoch 8157/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 8158/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 8159/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0515 - val_loss: 14571678.4522\n",
      "Epoch 8160/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 8161/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 8162/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0603 - val_loss: 14571678.4522\n",
      "Epoch 8163/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530844.9800 - val_loss: 14571678.4522\n",
      "Epoch 8164/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 8165/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 8166/10000\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 8167/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0178 - val_loss: 14571678.4522\n",
      "Epoch 8168/10000\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 1530845.0483 - val_loss: 14571678.4522\n",
      "Epoch 8169/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0843 - val_loss: 14571678.4522\n",
      "Epoch 8170/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0611 - val_loss: 14571678.4522\n",
      "Epoch 8171/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0742 - val_loss: 14571678.4522\n",
      "Epoch 8172/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 8173/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 8174/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 8175/10000\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 1530845.0720 - val_loss: 14571678.4522\n",
      "Epoch 8176/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0918 - val_loss: 14571678.4522\n",
      "Epoch 8177/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 8178/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 8179/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1178 - val_loss: 14571678.4522\n",
      "Epoch 8180/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0273 - val_loss: 14571678.4522\n",
      "Epoch 8181/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1440 - val_loss: 14571678.4522\n",
      "Epoch 8182/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.1768 - val_loss: 14571678.4522\n",
      "Epoch 8183/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0655 - val_loss: 14571678.4522\n",
      "Epoch 8184/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0378 - val_loss: 14571678.4522\n",
      "Epoch 8185/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 8186/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 8187/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0073 - val_loss: 14571678.4522\n",
      "Epoch 8188/10000\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 1530845.0418 - val_loss: 14571678.4522\n",
      "Epoch 8189/10000\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 1530845.0787 - val_loss: 14571678.4522\n",
      "Epoch 8190/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0295 - val_loss: 14571678.4522\n",
      "Epoch 8191/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1183 - val_loss: 14571678.4522\n",
      "Epoch 8192/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 8193/10000\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 1530845.0802 - val_loss: 14571678.4522\n",
      "Epoch 8194/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 8195/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530844.9912 - val_loss: 14571678.4522\n",
      "Epoch 8196/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1470 - val_loss: 14571678.4522\n",
      "Epoch 8197/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 8198/10000\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 1530845.0753 - val_loss: 14571678.4522\n",
      "Epoch 8199/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0760 - val_loss: 14571678.4522\n",
      "Epoch 8200/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 8201/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1062 - val_loss: 14571678.4522\n",
      "Epoch 8202/10000\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 8203/10000\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 1530845.0453 - val_loss: 14571678.4522\n",
      "Epoch 8204/10000\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 1530845.0563 - val_loss: 14571678.4522\n",
      "Epoch 8205/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0467 - val_loss: 14571678.4522\n",
      "Epoch 8206/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 8207/10000\n",
      "12000/12000 [==============================] - 0s 23us/step - loss: 1530845.1012 - val_loss: 14571678.4522\n",
      "Epoch 8208/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 8209/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1028 - val_loss: 14571678.4522\n",
      "Epoch 8210/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0987 - val_loss: 14571678.4522\n",
      "Epoch 8211/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1088 - val_loss: 14571678.4522\n",
      "Epoch 8212/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 8213/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1367 - val_loss: 14571678.4522\n",
      "Epoch 8214/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 8215/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0075 - val_loss: 14571678.4522\n",
      "Epoch 8216/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0719 - val_loss: 14571678.4522\n",
      "Epoch 8217/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1277 - val_loss: 14571678.4522\n",
      "Epoch 8218/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1717 - val_loss: 14571678.4522\n",
      "Epoch 8219/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1213 - val_loss: 14571678.4522\n",
      "Epoch 8220/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1312 - val_loss: 14571678.4522\n",
      "Epoch 8221/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0918 - val_loss: 14571678.4522\n",
      "Epoch 8222/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0612 - val_loss: 14571678.4522\n",
      "Epoch 8223/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9957 - val_loss: 14571678.4522\n",
      "Epoch 8224/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 8225/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 8226/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0373 - val_loss: 14571678.4522\n",
      "Epoch 8227/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0923 - val_loss: 14571678.4522\n",
      "Epoch 8228/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 8229/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0825 - val_loss: 14571678.4522\n",
      "Epoch 8230/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.1283 - val_loss: 14571678.4522\n",
      "Epoch 8231/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2442 - val_loss: 14571678.4522\n",
      "Epoch 8232/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1460 - val_loss: 14571678.4522\n",
      "Epoch 8233/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0377 - val_loss: 14571678.4522\n",
      "Epoch 8234/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1477 - val_loss: 14571678.4522\n",
      "Epoch 8235/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 8236/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0393 - val_loss: 14571678.4522\n",
      "Epoch 8237/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0160 - val_loss: 14571678.4522\n",
      "Epoch 8238/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 8239/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0195 - val_loss: 14571678.4522\n",
      "Epoch 8240/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 8241/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 8242/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1088 - val_loss: 14571678.4522\n",
      "Epoch 8243/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0417 - val_loss: 14571678.4522\n",
      "Epoch 8244/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0627 - val_loss: 14571678.4522\n",
      "Epoch 8245/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 8246/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1085 - val_loss: 14571678.4522\n",
      "Epoch 8247/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1360 - val_loss: 14571678.4522\n",
      "Epoch 8248/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2590 - val_loss: 14571678.4522\n",
      "Epoch 8249/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1058 - val_loss: 14571678.4522\n",
      "Epoch 8250/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0760 - val_loss: 14571678.4522\n",
      "Epoch 8251/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1312 - val_loss: 14571678.4522\n",
      "Epoch 8252/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0700 - val_loss: 14571678.4522\n",
      "Epoch 8253/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0657 - val_loss: 14571678.4522\n",
      "Epoch 8254/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1023 - val_loss: 14571678.4522\n",
      "Epoch 8255/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 8256/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1308 - val_loss: 14571678.4522\n",
      "Epoch 8257/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1317 - val_loss: 14571678.4522\n",
      "Epoch 8258/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0260 - val_loss: 14571678.4522\n",
      "Epoch 8259/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0530 - val_loss: 14571678.4522\n",
      "Epoch 8260/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0055 - val_loss: 14571678.4522\n",
      "Epoch 8261/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1128 - val_loss: 14571678.4522\n",
      "Epoch 8262/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1263 - val_loss: 14571678.4522\n",
      "Epoch 8263/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 8264/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0280 - val_loss: 14571678.4522\n",
      "Epoch 8265/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0022 - val_loss: 14571678.4522\n",
      "Epoch 8266/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0635 - val_loss: 14571678.4522\n",
      "Epoch 8267/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 8268/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 8269/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1417 - val_loss: 14571678.4522\n",
      "Epoch 8270/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0495 - val_loss: 14571678.4522\n",
      "Epoch 8271/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0265 - val_loss: 14571678.4522\n",
      "Epoch 8272/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0998 - val_loss: 14571678.4522\n",
      "Epoch 8273/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1633 - val_loss: 14571678.4522\n",
      "Epoch 8274/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 8275/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0673 - val_loss: 14571678.4522\n",
      "Epoch 8276/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 8277/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1780 - val_loss: 14571678.4522\n",
      "Epoch 8278/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 8279/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1383 - val_loss: 14571678.4522\n",
      "Epoch 8280/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 8281/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1510 - val_loss: 14571678.4522\n",
      "Epoch 8282/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 8283/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0288 - val_loss: 14571678.4522\n",
      "Epoch 8284/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0430 - val_loss: 14571678.4522\n",
      "Epoch 8285/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0142 - val_loss: 14571678.4522\n",
      "Epoch 8286/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0610 - val_loss: 14571678.4522\n",
      "Epoch 8287/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 8288/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0453 - val_loss: 14571678.4522\n",
      "Epoch 8289/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1277 - val_loss: 14571678.4522\n",
      "Epoch 8290/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 8291/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 8292/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1092 - val_loss: 14571678.4522\n",
      "Epoch 8293/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0775 - val_loss: 14571678.4522\n",
      "Epoch 8294/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 8295/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1472 - val_loss: 14571678.4522\n",
      "Epoch 8296/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 8297/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 8298/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0918 - val_loss: 14571678.4522\n",
      "Epoch 8299/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0762 - val_loss: 14571678.4522\n",
      "Epoch 8300/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 8301/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0653 - val_loss: 14571678.4522\n",
      "Epoch 8302/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 8303/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 8304/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 8305/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1573 - val_loss: 14571678.4522\n",
      "Epoch 8306/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0173 - val_loss: 14571678.4522\n",
      "Epoch 8307/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1097 - val_loss: 14571678.4522\n",
      "Epoch 8308/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 8309/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0373 - val_loss: 14571678.4522\n",
      "Epoch 8310/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0550 - val_loss: 14571678.4522\n",
      "Epoch 8311/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2253 - val_loss: 14571678.4522\n",
      "Epoch 8312/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0768 - val_loss: 14571678.4522\n",
      "Epoch 8313/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9997 - val_loss: 14571678.4522\n",
      "Epoch 8314/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0377 - val_loss: 14571678.4522\n",
      "Epoch 8315/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0340 - val_loss: 14571678.4522\n",
      "Epoch 8316/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 8317/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0488 - val_loss: 14571678.4522\n",
      "Epoch 8318/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0920 - val_loss: 14571678.4522\n",
      "Epoch 8319/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0718 - val_loss: 14571678.4522\n",
      "Epoch 8320/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1657 - val_loss: 14571678.4522\n",
      "Epoch 8321/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0840 - val_loss: 14571678.4522\n",
      "Epoch 8322/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 8323/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1055 - val_loss: 14571678.4522\n",
      "Epoch 8324/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0508 - val_loss: 14571678.4522\n",
      "Epoch 8325/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 8326/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0597 - val_loss: 14571678.4522\n",
      "Epoch 8327/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 8328/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1447 - val_loss: 14571678.4522\n",
      "Epoch 8329/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1453 - val_loss: 14571678.4522\n",
      "Epoch 8330/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1705 - val_loss: 14571678.4522\n",
      "Epoch 8331/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0766 - val_loss: 14571678.4522\n",
      "Epoch 8332/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0908 - val_loss: 14571678.4522\n",
      "Epoch 8333/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1378 - val_loss: 14571678.4522\n",
      "Epoch 8334/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 8335/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1600 - val_loss: 14571678.4522\n",
      "Epoch 8336/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 8337/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 8338/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0452 - val_loss: 14571678.4522\n",
      "Epoch 8339/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1785 - val_loss: 14571678.4522\n",
      "Epoch 8340/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0565 - val_loss: 14571678.4522\n",
      "Epoch 8341/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2050 - val_loss: 14571678.4522\n",
      "Epoch 8342/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0818 - val_loss: 14571678.4522\n",
      "Epoch 8343/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1673 - val_loss: 14571678.4522\n",
      "Epoch 8344/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 8345/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 8346/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1589 - val_loss: 14571678.4522\n",
      "Epoch 8347/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 8348/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 8349/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 8350/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0362 - val_loss: 14571678.4522\n",
      "Epoch 8351/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0377 - val_loss: 14571678.4522\n",
      "Epoch 8352/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1485 - val_loss: 14571678.4522\n",
      "Epoch 8353/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 8354/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1168 - val_loss: 14571678.4522\n",
      "Epoch 8355/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1265 - val_loss: 14571678.4522\n",
      "Epoch 8356/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 8357/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0327 - val_loss: 14571678.4522\n",
      "Epoch 8358/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0492 - val_loss: 14571678.4522\n",
      "Epoch 8359/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0535 - val_loss: 14571678.4522\n",
      "Epoch 8360/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 8361/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0798 - val_loss: 14571678.4522\n",
      "Epoch 8362/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0823 - val_loss: 14571678.4522\n",
      "Epoch 8363/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1465 - val_loss: 14571678.4522\n",
      "Epoch 8364/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 8365/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0558 - val_loss: 14571678.4522\n",
      "Epoch 8366/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0503 - val_loss: 14571678.4522\n",
      "Epoch 8367/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 8368/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1646 - val_loss: 14571678.4522\n",
      "Epoch 8369/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 8370/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1223 - val_loss: 14571678.4522\n",
      "Epoch 8371/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0672 - val_loss: 14571678.4522\n",
      "Epoch 8372/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 8373/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1161 - val_loss: 14571678.4522\n",
      "Epoch 8374/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9940 - val_loss: 14571678.4522\n",
      "Epoch 8375/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1712 - val_loss: 14571678.4522\n",
      "Epoch 8376/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0988 - val_loss: 14571678.4522\n",
      "Epoch 8377/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1400 - val_loss: 14571678.4522\n",
      "Epoch 8378/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0240 - val_loss: 14571678.4522\n",
      "Epoch 8379/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 8380/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1185 - val_loss: 14571678.4522\n",
      "Epoch 8381/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0515 - val_loss: 14571678.4522\n",
      "Epoch 8382/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 8383/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0478 - val_loss: 14571678.4522\n",
      "Epoch 8384/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 8385/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0978 - val_loss: 14571678.4522\n",
      "Epoch 8386/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 8387/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0285 - val_loss: 14571678.4522\n",
      "Epoch 8388/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0562 - val_loss: 14571678.4522\n",
      "Epoch 8389/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1257 - val_loss: 14571678.4522\n",
      "Epoch 8390/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0688 - val_loss: 14571678.4522\n",
      "Epoch 8391/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0515 - val_loss: 14571678.4522\n",
      "Epoch 8392/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0490 - val_loss: 14571678.4522\n",
      "Epoch 8393/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0387 - val_loss: 14571678.4522\n",
      "Epoch 8394/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0584 - val_loss: 14571678.4522\n",
      "Epoch 8395/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 8396/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 8397/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0817 - val_loss: 14571678.4522\n",
      "Epoch 8398/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1397 - val_loss: 14571678.4522\n",
      "Epoch 8399/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2233 - val_loss: 14571678.4522\n",
      "Epoch 8400/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0180 - val_loss: 14571678.4522\n",
      "Epoch 8401/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 8402/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0668 - val_loss: 14571678.4522\n",
      "Epoch 8403/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 8404/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 8405/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0380 - val_loss: 14571678.4522\n",
      "Epoch 8406/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1097 - val_loss: 14571678.4522\n",
      "Epoch 8407/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1562 - val_loss: 14571678.4522\n",
      "Epoch 8408/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0642 - val_loss: 14571678.4522\n",
      "Epoch 8409/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 8410/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1102 - val_loss: 14571678.4522\n",
      "Epoch 8411/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1213 - val_loss: 14571678.4522\n",
      "Epoch 8412/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0003 - val_loss: 14571678.4522\n",
      "Epoch 8413/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1190 - val_loss: 14571678.4522\n",
      "Epoch 8414/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1062 - val_loss: 14571678.4522\n",
      "Epoch 8415/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0735 - val_loss: 14571678.4522\n",
      "Epoch 8416/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1497 - val_loss: 14571678.4522\n",
      "Epoch 8417/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1228 - val_loss: 14571678.4522\n",
      "Epoch 8418/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0378 - val_loss: 14571678.4522\n",
      "Epoch 8419/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530844.9845 - val_loss: 14571678.4522\n",
      "Epoch 8420/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 8421/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0355 - val_loss: 14571678.4522\n",
      "Epoch 8422/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 8423/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1308 - val_loss: 14571678.4522\n",
      "Epoch 8424/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 8425/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 8426/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 8427/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1607 - val_loss: 14571678.4522\n",
      "Epoch 8428/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1472 - val_loss: 14571678.4522\n",
      "Epoch 8429/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 8430/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1058 - val_loss: 14571678.4522\n",
      "Epoch 8431/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 8432/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1331 - val_loss: 14571678.4522\n",
      "Epoch 8433/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0023 - val_loss: 14571678.4522\n",
      "Epoch 8434/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1452 - val_loss: 14571678.4522\n",
      "Epoch 8435/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 8436/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0320 - val_loss: 14571678.4522\n",
      "Epoch 8437/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1277 - val_loss: 14571678.4522\n",
      "Epoch 8438/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1325 - val_loss: 14571678.4522\n",
      "Epoch 8439/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 8440/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1877 - val_loss: 14571678.4522\n",
      "Epoch 8441/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0382 - val_loss: 14571678.4522\n",
      "Epoch 8442/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1118 - val_loss: 14571678.4522\n",
      "Epoch 8443/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1637 - val_loss: 14571678.4522\n",
      "Epoch 8444/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 8445/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 8446/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1031 - val_loss: 14571678.4522\n",
      "Epoch 8447/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 8448/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0828 - val_loss: 14571678.4522\n",
      "Epoch 8449/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1520 - val_loss: 14571678.4522\n",
      "Epoch 8450/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 8451/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 8452/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0682 - val_loss: 14571678.4522\n",
      "Epoch 8453/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 8454/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 8455/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 8456/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 8457/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0690 - val_loss: 14571678.4522\n",
      "Epoch 8458/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1694 - val_loss: 14571678.4522\n",
      "Epoch 8459/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0753 - val_loss: 14571678.4522\n",
      "Epoch 8460/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 8461/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1810 - val_loss: 14571678.4522\n",
      "Epoch 8462/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0569 - val_loss: 14571678.4522\n",
      "Epoch 8463/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1272 - val_loss: 14571678.4522\n",
      "Epoch 8464/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0835 - val_loss: 14571678.4522\n",
      "Epoch 8465/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0588 - val_loss: 14571678.4522\n",
      "Epoch 8466/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1287 - val_loss: 14571678.4522\n",
      "Epoch 8467/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0553 - val_loss: 14571678.4522\n",
      "Epoch 8468/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 8469/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0050 - val_loss: 14571678.4522\n",
      "Epoch 8470/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 8471/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2017 - val_loss: 14571678.4522\n",
      "Epoch 8472/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 8473/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1005 - val_loss: 14571678.4522\n",
      "Epoch 8474/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1185 - val_loss: 14571678.4522\n",
      "Epoch 8475/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0949 - val_loss: 14571678.4522\n",
      "Epoch 8476/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0799 - val_loss: 14571678.4522\n",
      "Epoch 8477/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 8478/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 8479/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0642 - val_loss: 14571678.4522\n",
      "Epoch 8480/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0916 - val_loss: 14571678.4522\n",
      "Epoch 8481/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1381 - val_loss: 14571678.4522\n",
      "Epoch 8482/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1495 - val_loss: 14571678.4522\n",
      "Epoch 8483/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 8484/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9982 - val_loss: 14571678.4522\n",
      "Epoch 8485/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530844.9791 - val_loss: 14571678.4522\n",
      "Epoch 8486/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0911 - val_loss: 14571678.4522\n",
      "Epoch 8487/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1342 - val_loss: 14571678.4522\n",
      "Epoch 8488/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0093 - val_loss: 14571678.4522\n",
      "Epoch 8489/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0417 - val_loss: 14571678.4522\n",
      "Epoch 8490/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1032 - val_loss: 14571678.4522\n",
      "Epoch 8491/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1403 - val_loss: 14571678.4522\n",
      "Epoch 8492/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0310 - val_loss: 14571678.4522\n",
      "Epoch 8493/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0230 - val_loss: 14571678.4522\n",
      "Epoch 8494/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 8495/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1287 - val_loss: 14571678.4522\n",
      "Epoch 8496/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1813 - val_loss: 14571678.4522\n",
      "Epoch 8497/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 8498/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 8499/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0715 - val_loss: 14571678.4522\n",
      "Epoch 8500/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0567 - val_loss: 14571678.4522\n",
      "Epoch 8501/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0532 - val_loss: 14571678.4522\n",
      "Epoch 8502/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1059 - val_loss: 14571678.4522\n",
      "Epoch 8503/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1257 - val_loss: 14571678.4522\n",
      "Epoch 8504/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0962 - val_loss: 14571678.4522\n",
      "Epoch 8505/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1159 - val_loss: 14571678.4522\n",
      "Epoch 8506/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 8507/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1743 - val_loss: 14571678.4522\n",
      "Epoch 8508/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1287 - val_loss: 14571678.4522\n",
      "Epoch 8509/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1343 - val_loss: 14571678.4522\n",
      "Epoch 8510/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 8511/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1218 - val_loss: 14571678.4522\n",
      "Epoch 8512/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 8513/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1122 - val_loss: 14571678.4522\n",
      "Epoch 8514/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 8515/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0450 - val_loss: 14571678.4522\n",
      "Epoch 8516/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 8517/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0527 - val_loss: 14571678.4522\n",
      "Epoch 8518/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1373 - val_loss: 14571678.4522\n",
      "Epoch 8519/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 8520/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 8521/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1280 - val_loss: 14571678.4522\n",
      "Epoch 8522/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0855 - val_loss: 14571678.4522\n",
      "Epoch 8523/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0213 - val_loss: 14571678.4522\n",
      "Epoch 8524/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 8525/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 8526/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 8527/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0477 - val_loss: 14571678.4522\n",
      "Epoch 8528/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0148 - val_loss: 14571678.4522\n",
      "Epoch 8529/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0680 - val_loss: 14571678.4522\n",
      "Epoch 8530/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 8531/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1823 - val_loss: 14571678.4522\n",
      "Epoch 8532/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 8533/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0580 - val_loss: 14571678.4522\n",
      "Epoch 8534/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0752 - val_loss: 14571678.4522\n",
      "Epoch 8535/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1203 - val_loss: 14571678.4522\n",
      "Epoch 8536/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0153 - val_loss: 14571678.4522\n",
      "Epoch 8537/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 8538/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 8539/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 8540/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 8541/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1560 - val_loss: 14571678.4522\n",
      "Epoch 8542/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9635 - val_loss: 14571678.4522\n",
      "Epoch 8543/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0925 - val_loss: 14571678.4522\n",
      "Epoch 8544/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 8545/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 8546/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1285 - val_loss: 14571678.4522\n",
      "Epoch 8547/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 8548/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0940 - val_loss: 14571678.4522\n",
      "Epoch 8549/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1030 - val_loss: 14571678.4522\n",
      "Epoch 8550/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0728 - val_loss: 14571678.4522\n",
      "Epoch 8551/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 8552/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0433 - val_loss: 14571678.4522\n",
      "Epoch 8553/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0703 - val_loss: 14571678.4522\n",
      "Epoch 8554/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0413 - val_loss: 14571678.4522\n",
      "Epoch 8555/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1012 - val_loss: 14571678.4522\n",
      "Epoch 8556/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2313 - val_loss: 14571678.4522\n",
      "Epoch 8557/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1898 - val_loss: 14571678.4522\n",
      "Epoch 8558/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1405 - val_loss: 14571678.4522\n",
      "Epoch 8559/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 8560/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 8561/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 8562/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 8563/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 8564/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1677 - val_loss: 14571678.4522\n",
      "Epoch 8565/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1447 - val_loss: 14571678.4522\n",
      "Epoch 8566/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1773 - val_loss: 14571678.4522\n",
      "Epoch 8567/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1913 - val_loss: 14571678.4522\n",
      "Epoch 8568/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1206 - val_loss: 14571678.4522\n",
      "Epoch 8569/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 8570/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0222 - val_loss: 14571678.4522\n",
      "Epoch 8571/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0214 - val_loss: 14571678.4522\n",
      "Epoch 8572/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0732 - val_loss: 14571678.4522\n",
      "Epoch 8573/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0085 - val_loss: 14571678.4522\n",
      "Epoch 8574/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0113 - val_loss: 14571678.4522\n",
      "Epoch 8575/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.1202 - val_loss: 14571678.4522\n",
      "Epoch 8576/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0627 - val_loss: 14571678.4522\n",
      "Epoch 8577/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0648 - val_loss: 14571678.4522\n",
      "Epoch 8578/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0273 - val_loss: 14571678.4522\n",
      "Epoch 8579/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0392 - val_loss: 14571678.4522\n",
      "Epoch 8580/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1293 - val_loss: 14571678.4522\n",
      "Epoch 8581/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0088 - val_loss: 14571678.4522\n",
      "Epoch 8582/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0630 - val_loss: 14571678.4522\n",
      "Epoch 8583/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0808 - val_loss: 14571678.4522\n",
      "Epoch 8584/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1450 - val_loss: 14571678.4522\n",
      "Epoch 8585/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 8586/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9503 - val_loss: 14571678.4522\n",
      "Epoch 8587/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0728 - val_loss: 14571678.4522\n",
      "Epoch 8588/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 8589/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.0845 - val_loss: 14571678.4522\n",
      "Epoch 8590/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0993 - val_loss: 14571678.4522\n",
      "Epoch 8591/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1161 - val_loss: 14571678.4522\n",
      "Epoch 8592/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 8593/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.0318 - val_loss: 14571678.4522\n",
      "Epoch 8594/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0623 - val_loss: 14571678.4522\n",
      "Epoch 8595/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 8596/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 8597/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0298 - val_loss: 14571678.4522\n",
      "Epoch 8598/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0834 - val_loss: 14571678.4522\n",
      "Epoch 8599/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1465 - val_loss: 14571678.4522\n",
      "Epoch 8600/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 8601/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0570 - val_loss: 14571678.4522\n",
      "Epoch 8602/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1030 - val_loss: 14571678.4522\n",
      "Epoch 8603/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0468 - val_loss: 14571678.4522\n",
      "Epoch 8604/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0535 - val_loss: 14571678.4522\n",
      "Epoch 8605/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0290 - val_loss: 14571678.4522\n",
      "Epoch 8606/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 8607/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0725 - val_loss: 14571678.4522\n",
      "Epoch 8608/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1487 - val_loss: 14571678.4522\n",
      "Epoch 8609/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0981 - val_loss: 14571678.4522\n",
      "Epoch 8610/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0877 - val_loss: 14571678.4522\n",
      "Epoch 8611/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 8612/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1223 - val_loss: 14571678.4522\n",
      "Epoch 8613/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0035 - val_loss: 14571678.4522\n",
      "Epoch 8614/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0408 - val_loss: 14571678.4522\n",
      "Epoch 8615/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0310 - val_loss: 14571678.4522\n",
      "Epoch 8616/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 8617/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 8618/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1518 - val_loss: 14571678.4522\n",
      "Epoch 8619/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1038 - val_loss: 14571678.4522\n",
      "Epoch 8620/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1810 - val_loss: 14571678.4522\n",
      "Epoch 8621/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 8622/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0628 - val_loss: 14571678.4522\n",
      "Epoch 8623/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 8624/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0942 - val_loss: 14571678.4522\n",
      "Epoch 8625/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1225 - val_loss: 14571678.4522\n",
      "Epoch 8626/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1553 - val_loss: 14571678.4522\n",
      "Epoch 8627/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0948 - val_loss: 14571678.4522\n",
      "Epoch 8628/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0287 - val_loss: 14571678.4522\n",
      "Epoch 8629/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 8630/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1393 - val_loss: 14571678.4522\n",
      "Epoch 8631/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 8632/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1045 - val_loss: 14571678.4522\n",
      "Epoch 8633/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 8634/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0298 - val_loss: 14571678.4522\n",
      "Epoch 8635/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 8636/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 8637/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 8638/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0645 - val_loss: 14571678.4522\n",
      "Epoch 8639/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 8640/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0145 - val_loss: 14571678.4522\n",
      "Epoch 8641/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0120 - val_loss: 14571678.4522\n",
      "Epoch 8642/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 8643/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1580 - val_loss: 14571678.4522\n",
      "Epoch 8644/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 8645/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1503 - val_loss: 14571678.4522\n",
      "Epoch 8646/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0560 - val_loss: 14571678.4522\n",
      "Epoch 8647/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0985 - val_loss: 14571678.4522\n",
      "Epoch 8648/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1733 - val_loss: 14571678.4522\n",
      "Epoch 8649/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1513 - val_loss: 14571678.4522\n",
      "Epoch 8650/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 8651/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 8652/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0040 - val_loss: 14571678.4522\n",
      "Epoch 8653/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1842 - val_loss: 14571678.4522\n",
      "Epoch 8654/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0935 - val_loss: 14571678.4522\n",
      "Epoch 8655/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1213 - val_loss: 14571678.4522\n",
      "Epoch 8656/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 8657/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1050 - val_loss: 14571678.4522\n",
      "Epoch 8658/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0585 - val_loss: 14571678.4522\n",
      "Epoch 8659/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0197 - val_loss: 14571678.4522\n",
      "Epoch 8660/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0765 - val_loss: 14571678.4522\n",
      "Epoch 8661/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0213 - val_loss: 14571678.4522\n",
      "Epoch 8662/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 8663/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0597 - val_loss: 14571678.4522\n",
      "Epoch 8664/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1610 - val_loss: 14571678.4522\n",
      "Epoch 8665/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1547 - val_loss: 14571678.4522\n",
      "Epoch 8666/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1235 - val_loss: 14571678.4522\n",
      "Epoch 8667/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 8668/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1250 - val_loss: 14571678.4522\n",
      "Epoch 8669/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1623 - val_loss: 14571678.4522\n",
      "Epoch 8670/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 8671/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0748 - val_loss: 14571678.4522\n",
      "Epoch 8672/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1059 - val_loss: 14571678.4522\n",
      "Epoch 8673/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0645 - val_loss: 14571678.4522\n",
      "Epoch 8674/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 8675/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0268 - val_loss: 14571678.4522\n",
      "Epoch 8676/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 8677/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1270 - val_loss: 14571678.4522\n",
      "Epoch 8678/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 8679/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0558 - val_loss: 14571678.4522\n",
      "Epoch 8680/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 8681/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0115 - val_loss: 14571678.4522\n",
      "Epoch 8682/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1473 - val_loss: 14571678.4522\n",
      "Epoch 8683/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0787 - val_loss: 14571678.4522\n",
      "Epoch 8684/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 8685/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0558 - val_loss: 14571678.4522\n",
      "Epoch 8686/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 8687/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 8688/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1263 - val_loss: 14571678.4522\n",
      "Epoch 8689/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 8690/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0188 - val_loss: 14571678.4522\n",
      "Epoch 8691/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1248 - val_loss: 14571678.4522\n",
      "Epoch 8692/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 8693/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0103 - val_loss: 14571678.4522\n",
      "Epoch 8694/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0153 - val_loss: 14571678.4522\n",
      "Epoch 8695/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 8696/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 8697/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0137 - val_loss: 14571678.4522\n",
      "Epoch 8698/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1032 - val_loss: 14571678.4522\n",
      "Epoch 8699/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 8700/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0453 - val_loss: 14571678.4522\n",
      "Epoch 8701/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 8702/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1438 - val_loss: 14571678.4522\n",
      "Epoch 8703/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1160 - val_loss: 14571678.4522\n",
      "Epoch 8704/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0482 - val_loss: 14571678.4522\n",
      "Epoch 8705/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0358 - val_loss: 14571678.4522\n",
      "Epoch 8706/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 8707/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0675 - val_loss: 14571678.4522\n",
      "Epoch 8708/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0670 - val_loss: 14571678.4522\n",
      "Epoch 8709/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0317 - val_loss: 14571678.4522\n",
      "Epoch 8710/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0817 - val_loss: 14571678.4522\n",
      "Epoch 8711/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 8712/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9947 - val_loss: 14571678.4522\n",
      "Epoch 8713/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0358 - val_loss: 14571678.4522\n",
      "Epoch 8714/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0925 - val_loss: 14571678.4522\n",
      "Epoch 8715/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9753 - val_loss: 14571678.4522\n",
      "Epoch 8716/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1242 - val_loss: 14571678.4522\n",
      "Epoch 8717/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 8718/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 8719/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0723 - val_loss: 14571678.4522\n",
      "Epoch 8720/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1143 - val_loss: 14571678.4522\n",
      "Epoch 8721/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0658 - val_loss: 14571678.4522\n",
      "Epoch 8722/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0475 - val_loss: 14571678.4522\n",
      "Epoch 8723/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0117 - val_loss: 14571678.4522\n",
      "Epoch 8724/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0863 - val_loss: 14571678.4522\n",
      "Epoch 8725/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0657 - val_loss: 14571678.4522\n",
      "Epoch 8726/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0247 - val_loss: 14571678.4522\n",
      "Epoch 8727/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0945 - val_loss: 14571678.4522\n",
      "Epoch 8728/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0822 - val_loss: 14571678.4522\n",
      "Epoch 8729/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 8730/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 8731/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0477 - val_loss: 14571678.4522\n",
      "Epoch 8732/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0553 - val_loss: 14571678.4522\n",
      "Epoch 8733/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530844.9855 - val_loss: 14571678.4522\n",
      "Epoch 8734/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1263 - val_loss: 14571678.4522\n",
      "Epoch 8735/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 8736/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 8737/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0388 - val_loss: 14571678.4522\n",
      "Epoch 8738/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1142 - val_loss: 14571678.4522\n",
      "Epoch 8739/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 8740/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9843 - val_loss: 14571678.4522\n",
      "Epoch 8741/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1125 - val_loss: 14571678.4522\n",
      "Epoch 8742/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0723 - val_loss: 14571678.4522\n",
      "Epoch 8743/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 8744/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0657 - val_loss: 14571678.4522\n",
      "Epoch 8745/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0783 - val_loss: 14571678.4522\n",
      "Epoch 8746/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1373 - val_loss: 14571678.4522\n",
      "Epoch 8747/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0368 - val_loss: 14571678.4522\n",
      "Epoch 8748/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 8749/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1007 - val_loss: 14571678.4522\n",
      "Epoch 8750/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 8751/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 8752/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1677 - val_loss: 14571678.4522\n",
      "Epoch 8753/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 8754/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1022 - val_loss: 14571678.4522\n",
      "Epoch 8755/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0277 - val_loss: 14571678.4522\n",
      "Epoch 8756/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0753 - val_loss: 14571678.4522\n",
      "Epoch 8757/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0246 - val_loss: 14571678.4522\n",
      "Epoch 8758/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1747 - val_loss: 14571678.4522\n",
      "Epoch 8759/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 8760/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1430 - val_loss: 14571678.4522\n",
      "Epoch 8761/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1304 - val_loss: 14571678.4522\n",
      "Epoch 8762/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 8763/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0650 - val_loss: 14571678.4522\n",
      "Epoch 8764/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 8765/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1477 - val_loss: 14571678.4522\n",
      "Epoch 8766/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0668 - val_loss: 14571678.4522\n",
      "Epoch 8767/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1290 - val_loss: 14571678.4522\n",
      "Epoch 8768/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0008 - val_loss: 14571678.4522\n",
      "Epoch 8769/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0210 - val_loss: 14571678.4522\n",
      "Epoch 8770/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1045 - val_loss: 14571678.4522\n",
      "Epoch 8771/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0788 - val_loss: 14571678.4522\n",
      "Epoch 8772/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1523 - val_loss: 14571678.4522\n",
      "Epoch 8773/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0442 - val_loss: 14571678.4522\n",
      "Epoch 8774/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1065 - val_loss: 14571678.4522\n",
      "Epoch 8775/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0007 - val_loss: 14571678.4522\n",
      "Epoch 8776/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0775 - val_loss: 14571678.4522\n",
      "Epoch 8777/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1570 - val_loss: 14571678.4522\n",
      "Epoch 8778/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0720 - val_loss: 14571678.4522\n",
      "Epoch 8779/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0723 - val_loss: 14571678.4522\n",
      "Epoch 8780/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1613 - val_loss: 14571678.4522\n",
      "Epoch 8781/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 8782/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 8783/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 8784/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1389 - val_loss: 14571678.4522\n",
      "Epoch 8785/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0597 - val_loss: 14571678.4522\n",
      "Epoch 8786/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1590 - val_loss: 14571678.4522\n",
      "Epoch 8787/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1250 - val_loss: 14571678.4522\n",
      "Epoch 8788/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1015 - val_loss: 14571678.4522\n",
      "Epoch 8789/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0377 - val_loss: 14571678.4522\n",
      "Epoch 8790/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1113 - val_loss: 14571678.4522\n",
      "Epoch 8791/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0855 - val_loss: 14571678.4522\n",
      "Epoch 8792/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1483 - val_loss: 14571678.4522\n",
      "Epoch 8793/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 8794/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0637 - val_loss: 14571678.4522\n",
      "Epoch 8795/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 8796/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 8797/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0437 - val_loss: 14571678.4522\n",
      "Epoch 8798/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1383 - val_loss: 14571678.4522\n",
      "Epoch 8799/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 8800/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1125 - val_loss: 14571678.4522\n",
      "Epoch 8801/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 8802/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1235 - val_loss: 14571678.4522\n",
      "Epoch 8803/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 8804/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0528 - val_loss: 14571678.4522\n",
      "Epoch 8805/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1095 - val_loss: 14571678.4522\n",
      "Epoch 8806/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0118 - val_loss: 14571678.4522\n",
      "Epoch 8807/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1100 - val_loss: 14571678.4522\n",
      "Epoch 8808/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 8809/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0755 - val_loss: 14571678.4522\n",
      "Epoch 8810/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0307 - val_loss: 14571678.4522\n",
      "Epoch 8811/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0692 - val_loss: 14571678.4522\n",
      "Epoch 8812/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0912 - val_loss: 14571678.4522\n",
      "Epoch 8813/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0173 - val_loss: 14571678.4522\n",
      "Epoch 8814/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 8815/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1660 - val_loss: 14571678.4522\n",
      "Epoch 8816/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0863 - val_loss: 14571678.4522\n",
      "Epoch 8817/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 8818/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 8819/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0742 - val_loss: 14571678.4522\n",
      "Epoch 8820/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 8821/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0562 - val_loss: 14571678.4522\n",
      "Epoch 8822/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 8823/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0613 - val_loss: 14571678.4522\n",
      "Epoch 8824/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 8825/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 8826/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1550 - val_loss: 14571678.4522\n",
      "Epoch 8827/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0788 - val_loss: 14571678.4522\n",
      "Epoch 8828/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1061 - val_loss: 14571678.4522\n",
      "Epoch 8829/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0723 - val_loss: 14571678.4522\n",
      "Epoch 8830/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 8831/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0373 - val_loss: 14571678.4522\n",
      "Epoch 8832/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0344 - val_loss: 14571678.4522\n",
      "Epoch 8833/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1942 - val_loss: 14571678.4522\n",
      "Epoch 8834/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1580 - val_loss: 14571678.4522\n",
      "Epoch 8835/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 8836/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0338 - val_loss: 14571678.4522\n",
      "Epoch 8837/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1327 - val_loss: 14571678.4522\n",
      "Epoch 8838/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1071 - val_loss: 14571678.4522\n",
      "Epoch 8839/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0792 - val_loss: 14571678.4522\n",
      "Epoch 8840/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1307 - val_loss: 14571678.4522\n",
      "Epoch 8841/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0745 - val_loss: 14571678.4522\n",
      "Epoch 8842/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0135 - val_loss: 14571678.4522\n",
      "Epoch 8843/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0452 - val_loss: 14571678.4522\n",
      "Epoch 8844/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 8845/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 8846/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0600 - val_loss: 14571678.4522\n",
      "Epoch 8847/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0447 - val_loss: 14571678.4522\n",
      "Epoch 8848/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 8849/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1990 - val_loss: 14571678.4522\n",
      "Epoch 8850/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 8851/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1433 - val_loss: 14571678.4522\n",
      "Epoch 8852/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 8853/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 8854/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1185 - val_loss: 14571678.4522\n",
      "Epoch 8855/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0237 - val_loss: 14571678.4522\n",
      "Epoch 8856/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1163 - val_loss: 14571678.4522\n",
      "Epoch 8857/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1467 - val_loss: 14571678.4522\n",
      "Epoch 8858/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 8859/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 8860/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1014 - val_loss: 14571678.4522\n",
      "Epoch 8861/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1495 - val_loss: 14571678.4522\n",
      "Epoch 8862/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1517 - val_loss: 14571678.4522\n",
      "Epoch 8863/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1055 - val_loss: 14571678.4522\n",
      "Epoch 8864/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0653 - val_loss: 14571678.4522\n",
      "Epoch 8865/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9862 - val_loss: 14571678.4522\n",
      "Epoch 8866/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0562 - val_loss: 14571678.4522\n",
      "Epoch 8867/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 8868/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0673 - val_loss: 14571678.4522\n",
      "Epoch 8869/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1658 - val_loss: 14571678.4522\n",
      "Epoch 8870/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 8871/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 8872/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0527 - val_loss: 14571678.4522\n",
      "Epoch 8873/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0150 - val_loss: 14571678.4522\n",
      "Epoch 8874/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 8875/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 8876/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0760 - val_loss: 14571678.4522\n",
      "Epoch 8877/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0708 - val_loss: 14571678.4522\n",
      "Epoch 8878/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1442 - val_loss: 14571678.4522\n",
      "Epoch 8879/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 8880/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1170 - val_loss: 14571678.4522\n",
      "Epoch 8881/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 8882/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 8883/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 8884/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0833 - val_loss: 14571678.4522\n",
      "Epoch 8885/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0665 - val_loss: 14571678.4522\n",
      "Epoch 8886/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 8887/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1360 - val_loss: 14571678.4522\n",
      "Epoch 8888/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1467 - val_loss: 14571678.4522\n",
      "Epoch 8889/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0757 - val_loss: 14571678.4522\n",
      "Epoch 8890/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9977 - val_loss: 14571678.4522\n",
      "Epoch 8891/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0053 - val_loss: 14571678.4522\n",
      "Epoch 8892/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1110 - val_loss: 14571678.4522\n",
      "Epoch 8893/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0951 - val_loss: 14571678.4522\n",
      "Epoch 8894/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0735 - val_loss: 14571678.4522\n",
      "Epoch 8895/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0617 - val_loss: 14571678.4522\n",
      "Epoch 8896/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 8897/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0190 - val_loss: 14571678.4522\n",
      "Epoch 8898/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0772 - val_loss: 14571678.4522\n",
      "Epoch 8899/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 8900/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 8901/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0522 - val_loss: 14571678.4522\n",
      "Epoch 8902/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1803 - val_loss: 14571678.4522\n",
      "Epoch 8903/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0338 - val_loss: 14571678.4522\n",
      "Epoch 8904/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1308 - val_loss: 14571678.4522\n",
      "Epoch 8905/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1913 - val_loss: 14571678.4522\n",
      "Epoch 8906/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1112 - val_loss: 14571678.4522\n",
      "Epoch 8907/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0147 - val_loss: 14571678.4522\n",
      "Epoch 8908/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 8909/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1330 - val_loss: 14571678.4522\n",
      "Epoch 8910/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 8911/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1183 - val_loss: 14571678.4522\n",
      "Epoch 8912/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0123 - val_loss: 14571678.4522\n",
      "Epoch 8913/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 8914/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1695 - val_loss: 14571678.4522\n",
      "Epoch 8915/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1232 - val_loss: 14571678.4522\n",
      "Epoch 8916/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 8917/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0120 - val_loss: 14571678.4522\n",
      "Epoch 8918/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 8919/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9977 - val_loss: 14571678.4522\n",
      "Epoch 8920/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1341 - val_loss: 14571678.4522\n",
      "Epoch 8921/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 8922/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0445 - val_loss: 14571678.4522\n",
      "Epoch 8923/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 8924/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0200 - val_loss: 14571678.4522\n",
      "Epoch 8925/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1073 - val_loss: 14571678.4522\n",
      "Epoch 8926/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 8927/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0817 - val_loss: 14571678.4522\n",
      "Epoch 8928/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1187 - val_loss: 14571678.4522\n",
      "Epoch 8929/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0942 - val_loss: 14571678.4522\n",
      "Epoch 8930/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0437 - val_loss: 14571678.4522\n",
      "Epoch 8931/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0646 - val_loss: 14571678.4522\n",
      "Epoch 8932/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0517 - val_loss: 14571678.4522\n",
      "Epoch 8933/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 8934/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0495 - val_loss: 14571678.4522\n",
      "Epoch 8935/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 8936/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1363 - val_loss: 14571678.4522\n",
      "Epoch 8937/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1777 - val_loss: 14571678.4522\n",
      "Epoch 8938/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0240 - val_loss: 14571678.4522\n",
      "Epoch 8939/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1105 - val_loss: 14571678.4522\n",
      "Epoch 8940/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1673 - val_loss: 14571678.4522\n",
      "Epoch 8941/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0638 - val_loss: 14571678.4522\n",
      "Epoch 8942/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0600 - val_loss: 14571678.4522\n",
      "Epoch 8943/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1242 - val_loss: 14571678.4522\n",
      "Epoch 8944/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 8945/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1563 - val_loss: 14571678.4522\n",
      "Epoch 8946/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 8947/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0427 - val_loss: 14571678.4522\n",
      "Epoch 8948/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0698 - val_loss: 14571678.4522\n",
      "Epoch 8949/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0550 - val_loss: 14571678.4522\n",
      "Epoch 8950/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1507 - val_loss: 14571678.4522\n",
      "Epoch 8951/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0862 - val_loss: 14571678.4522\n",
      "Epoch 8952/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 8953/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 8954/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0208 - val_loss: 14571678.4522\n",
      "Epoch 8955/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0372 - val_loss: 14571678.4522\n",
      "Epoch 8956/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0470 - val_loss: 14571678.4522\n",
      "Epoch 8957/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1375 - val_loss: 14571678.4522\n",
      "Epoch 8958/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0938 - val_loss: 14571678.4522\n",
      "Epoch 8959/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0430 - val_loss: 14571678.4522\n",
      "Epoch 8960/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0097 - val_loss: 14571678.4522\n",
      "Epoch 8961/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 8962/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1009 - val_loss: 14571678.4522\n",
      "Epoch 8963/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0943 - val_loss: 14571678.4522\n",
      "Epoch 8964/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1162 - val_loss: 14571678.4522\n",
      "Epoch 8965/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1360 - val_loss: 14571678.4522\n",
      "Epoch 8966/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530844.9831 - val_loss: 14571678.4522\n",
      "Epoch 8967/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0255 - val_loss: 14571678.4522\n",
      "Epoch 8968/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1167 - val_loss: 14571678.4522\n",
      "Epoch 8969/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1275 - val_loss: 14571678.4522\n",
      "Epoch 8970/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 8971/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0962 - val_loss: 14571678.4522\n",
      "Epoch 8972/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0268 - val_loss: 14571678.4522\n",
      "Epoch 8973/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1053 - val_loss: 14571678.4522\n",
      "Epoch 8974/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0323 - val_loss: 14571678.4522\n",
      "Epoch 8975/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0603 - val_loss: 14571678.4522\n",
      "Epoch 8976/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1113 - val_loss: 14571678.4522\n",
      "Epoch 8977/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 8978/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1740 - val_loss: 14571678.4522\n",
      "Epoch 8979/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0282 - val_loss: 14571678.4522\n",
      "Epoch 8980/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1638 - val_loss: 14571678.4522\n",
      "Epoch 8981/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1491 - val_loss: 14571678.4522\n",
      "Epoch 8982/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 8983/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1540 - val_loss: 14571678.4522\n",
      "Epoch 8984/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0536 - val_loss: 14571678.4522\n",
      "Epoch 8985/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 8986/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1668 - val_loss: 14571678.4522\n",
      "Epoch 8987/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 8988/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0298 - val_loss: 14571678.4522\n",
      "Epoch 8989/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0513 - val_loss: 14571678.4522\n",
      "Epoch 8990/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1230 - val_loss: 14571678.4522\n",
      "Epoch 8991/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0950 - val_loss: 14571678.4522\n",
      "Epoch 8992/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1200 - val_loss: 14571678.4522\n",
      "Epoch 8993/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 8994/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1480 - val_loss: 14571678.4522\n",
      "Epoch 8995/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 8996/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1607 - val_loss: 14571678.4522\n",
      "Epoch 8997/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0160 - val_loss: 14571678.4522\n",
      "Epoch 8998/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 8999/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0413 - val_loss: 14571678.4522\n",
      "Epoch 9000/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0810 - val_loss: 14571678.4522\n",
      "Epoch 9001/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0723 - val_loss: 14571678.4522\n",
      "Epoch 9002/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 9003/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1188 - val_loss: 14571678.4522\n",
      "Epoch 9004/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1660 - val_loss: 14571678.4522\n",
      "Epoch 9005/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0733 - val_loss: 14571678.4522\n",
      "Epoch 9006/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0658 - val_loss: 14571678.4522\n",
      "Epoch 9007/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0343 - val_loss: 14571678.4522\n",
      "Epoch 9008/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0932 - val_loss: 14571678.4522\n",
      "Epoch 9009/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1358 - val_loss: 14571678.4522\n",
      "Epoch 9010/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0253 - val_loss: 14571678.4522\n",
      "Epoch 9011/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 9012/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 9013/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0690 - val_loss: 14571678.4522\n",
      "Epoch 9014/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1195 - val_loss: 14571678.4522\n",
      "Epoch 9015/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 9016/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 9017/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 9018/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1148 - val_loss: 14571678.4522\n",
      "Epoch 9019/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0632 - val_loss: 14571678.4522\n",
      "Epoch 9020/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 9021/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1200 - val_loss: 14571678.4522\n",
      "Epoch 9022/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1068 - val_loss: 14571678.4522\n",
      "Epoch 9023/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0393 - val_loss: 14571678.4522\n",
      "Epoch 9024/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1597 - val_loss: 14571678.4522\n",
      "Epoch 9025/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0747 - val_loss: 14571678.4522\n",
      "Epoch 9026/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0448 - val_loss: 14571678.4522\n",
      "Epoch 9027/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1350 - val_loss: 14571678.4522\n",
      "Epoch 9028/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0503 - val_loss: 14571678.4522\n",
      "Epoch 9029/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1263 - val_loss: 14571678.4522\n",
      "Epoch 9030/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 9031/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 9032/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 9033/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 9034/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2220 - val_loss: 14571678.4522\n",
      "Epoch 9035/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 9036/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0645 - val_loss: 14571678.4522\n",
      "Epoch 9037/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0829 - val_loss: 14571678.4522\n",
      "Epoch 9038/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1306 - val_loss: 14571678.4522\n",
      "Epoch 9039/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0463 - val_loss: 14571678.4522\n",
      "Epoch 9040/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 9041/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1677 - val_loss: 14571678.4522\n",
      "Epoch 9042/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0752 - val_loss: 14571678.4522\n",
      "Epoch 9043/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 9044/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0777 - val_loss: 14571678.4522\n",
      "Epoch 9045/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1766 - val_loss: 14571678.4522\n",
      "Epoch 9046/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0464 - val_loss: 14571678.4522\n",
      "Epoch 9047/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 9048/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 9049/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1097 - val_loss: 14571678.4522\n",
      "Epoch 9050/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 9051/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0638 - val_loss: 14571678.4522\n",
      "Epoch 9052/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 9053/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0587 - val_loss: 14571678.4522\n",
      "Epoch 9054/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0626 - val_loss: 14571678.4522\n",
      "Epoch 9055/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1045 - val_loss: 14571678.4522\n",
      "Epoch 9056/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0712 - val_loss: 14571678.4522\n",
      "Epoch 9057/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0968 - val_loss: 14571678.4522\n",
      "Epoch 9058/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1680 - val_loss: 14571678.4522\n",
      "Epoch 9059/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0000 - val_loss: 14571678.4522\n",
      "Epoch 9060/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 9061/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1480 - val_loss: 14571678.4522\n",
      "Epoch 9062/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1208 - val_loss: 14571678.4522\n",
      "Epoch 9063/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 9064/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 9065/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0395 - val_loss: 14571678.4522\n",
      "Epoch 9066/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1547 - val_loss: 14571678.4522\n",
      "Epoch 9067/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 9068/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0993 - val_loss: 14571678.4522\n",
      "Epoch 9069/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1447 - val_loss: 14571678.4522\n",
      "Epoch 9070/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0849 - val_loss: 14571678.4522\n",
      "Epoch 9071/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1257 - val_loss: 14571678.4522\n",
      "Epoch 9072/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1053 - val_loss: 14571678.4522\n",
      "Epoch 9073/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 9074/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0573 - val_loss: 14571678.4522\n",
      "Epoch 9075/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1300 - val_loss: 14571678.4522\n",
      "Epoch 9076/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0535 - val_loss: 14571678.4522\n",
      "Epoch 9077/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0275 - val_loss: 14571678.4522\n",
      "Epoch 9078/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0348 - val_loss: 14571678.4522\n",
      "Epoch 9079/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1133 - val_loss: 14571678.4522\n",
      "Epoch 9080/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 9081/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0738 - val_loss: 14571678.4522\n",
      "Epoch 9082/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0233 - val_loss: 14571678.4522\n",
      "Epoch 9083/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0522 - val_loss: 14571678.4522\n",
      "Epoch 9084/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0783 - val_loss: 14571678.4522\n",
      "Epoch 9085/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0510 - val_loss: 14571678.4522\n",
      "Epoch 9086/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1305 - val_loss: 14571678.4522\n",
      "Epoch 9087/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1537 - val_loss: 14571678.4522\n",
      "Epoch 9088/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1500 - val_loss: 14571678.4522\n",
      "Epoch 9089/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 9090/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 9091/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 9092/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0952 - val_loss: 14571678.4522\n",
      "Epoch 9093/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1273 - val_loss: 14571678.4522\n",
      "Epoch 9094/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 9095/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 9096/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0862 - val_loss: 14571678.4522\n",
      "Epoch 9097/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1760 - val_loss: 14571678.4522\n",
      "Epoch 9098/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1307 - val_loss: 14571678.4522\n",
      "Epoch 9099/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1128 - val_loss: 14571678.4522\n",
      "Epoch 9100/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0547 - val_loss: 14571678.4522\n",
      "Epoch 9101/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1297 - val_loss: 14571678.4522\n",
      "Epoch 9102/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1420 - val_loss: 14571678.4522\n",
      "Epoch 9103/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0402 - val_loss: 14571678.4522\n",
      "Epoch 9104/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 9105/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0925 - val_loss: 14571678.4522\n",
      "Epoch 9106/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0580 - val_loss: 14571678.4522\n",
      "Epoch 9107/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0902 - val_loss: 14571678.4522\n",
      "Epoch 9108/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1003 - val_loss: 14571678.4522\n",
      "Epoch 9109/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0465 - val_loss: 14571678.4522\n",
      "Epoch 9110/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0550 - val_loss: 14571678.4522\n",
      "Epoch 9111/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1297 - val_loss: 14571678.4522\n",
      "Epoch 9112/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0365 - val_loss: 14571678.4522\n",
      "Epoch 9113/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 9114/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 9115/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1298 - val_loss: 14571678.4522\n",
      "Epoch 9116/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1115 - val_loss: 14571678.4522\n",
      "Epoch 9117/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1380 - val_loss: 14571678.4522\n",
      "Epoch 9118/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0945 - val_loss: 14571678.4522\n",
      "Epoch 9119/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 9120/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0038 - val_loss: 14571678.4522\n",
      "Epoch 9121/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0717 - val_loss: 14571678.4522\n",
      "Epoch 9122/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1194 - val_loss: 14571678.4522\n",
      "Epoch 9123/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0365 - val_loss: 14571678.4522\n",
      "Epoch 9124/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0873 - val_loss: 14571678.4522\n",
      "Epoch 9125/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 9126/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1380 - val_loss: 14571678.4522\n",
      "Epoch 9127/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1362 - val_loss: 14571678.4522\n",
      "Epoch 9128/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0541 - val_loss: 14571678.4522\n",
      "Epoch 9129/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 9130/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0447 - val_loss: 14571678.4522\n",
      "Epoch 9131/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0855 - val_loss: 14571678.4522\n",
      "Epoch 9132/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0220 - val_loss: 14571678.4522\n",
      "Epoch 9133/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 9134/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0647 - val_loss: 14571678.4522\n",
      "Epoch 9135/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0657 - val_loss: 14571678.4522\n",
      "Epoch 9136/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1597 - val_loss: 14571678.4522\n",
      "Epoch 9137/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1097 - val_loss: 14571678.4522\n",
      "Epoch 9138/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1358 - val_loss: 14571678.4522\n",
      "Epoch 9139/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0753 - val_loss: 14571678.4522\n",
      "Epoch 9140/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 9141/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0637 - val_loss: 14571678.4522\n",
      "Epoch 9142/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 9143/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0862 - val_loss: 14571678.4522\n",
      "Epoch 9144/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 9145/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1053 - val_loss: 14571678.4522\n",
      "Epoch 9146/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0240 - val_loss: 14571678.4522\n",
      "Epoch 9147/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1527 - val_loss: 14571678.4522\n",
      "Epoch 9148/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1447 - val_loss: 14571678.4522\n",
      "Epoch 9149/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 9150/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 9151/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1148 - val_loss: 14571678.4522\n",
      "Epoch 9152/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0467 - val_loss: 14571678.4522\n",
      "Epoch 9153/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9800 - val_loss: 14571678.4522\n",
      "Epoch 9154/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2412 - val_loss: 14571678.4522\n",
      "Epoch 9155/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1020 - val_loss: 14571678.4522\n",
      "Epoch 9156/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9958 - val_loss: 14571678.4522\n",
      "Epoch 9157/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 9158/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 9159/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0692 - val_loss: 14571678.4522\n",
      "Epoch 9160/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0142 - val_loss: 14571678.4522\n",
      "Epoch 9161/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0330 - val_loss: 14571678.4522\n",
      "Epoch 9162/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 9163/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0963 - val_loss: 14571678.4522\n",
      "Epoch 9164/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 9165/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1475 - val_loss: 14571678.4522\n",
      "Epoch 9166/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0625 - val_loss: 14571678.4522\n",
      "Epoch 9167/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0417 - val_loss: 14571678.4522\n",
      "Epoch 9168/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1155 - val_loss: 14571678.4522\n",
      "Epoch 9169/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0420 - val_loss: 14571678.4522\n",
      "Epoch 9170/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0815 - val_loss: 14571678.4522\n",
      "Epoch 9171/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0535 - val_loss: 14571678.4522\n",
      "Epoch 9172/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1483 - val_loss: 14571678.4522\n",
      "Epoch 9173/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1088 - val_loss: 14571678.4522\n",
      "Epoch 9174/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2037 - val_loss: 14571678.4522\n",
      "Epoch 9175/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 9176/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0700 - val_loss: 14571678.4522\n",
      "Epoch 9177/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 9178/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 9179/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0410 - val_loss: 14571678.4522\n",
      "Epoch 9180/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0632 - val_loss: 14571678.4522\n",
      "Epoch 9181/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1059 - val_loss: 14571678.4522\n",
      "Epoch 9182/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1285 - val_loss: 14571678.4522\n",
      "Epoch 9183/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 9184/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.0828 - val_loss: 14571678.4522\n",
      "Epoch 9185/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 9186/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1298 - val_loss: 14571678.4522\n",
      "Epoch 9187/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0700 - val_loss: 14571678.4522\n",
      "Epoch 9188/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 9189/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1160 - val_loss: 14571678.4522\n",
      "Epoch 9190/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1865 - val_loss: 14571678.4522\n",
      "Epoch 9191/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 9192/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0257 - val_loss: 14571678.4522\n",
      "Epoch 9193/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1305 - val_loss: 14571678.4522\n",
      "Epoch 9194/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1777 - val_loss: 14571678.4522\n",
      "Epoch 9195/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 9196/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 9197/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0663 - val_loss: 14571678.4522\n",
      "Epoch 9198/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0462 - val_loss: 14571678.4522\n",
      "Epoch 9199/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0397 - val_loss: 14571678.4522\n",
      "Epoch 9200/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 9201/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 9202/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530844.9910 - val_loss: 14571678.4522\n",
      "Epoch 9203/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0420 - val_loss: 14571678.4522\n",
      "Epoch 9204/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0600 - val_loss: 14571678.4522\n",
      "Epoch 9205/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0672 - val_loss: 14571678.4522\n",
      "Epoch 9206/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0122 - val_loss: 14571678.4522\n",
      "Epoch 9207/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 9208/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0712 - val_loss: 14571678.4522\n",
      "Epoch 9209/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 9210/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1587 - val_loss: 14571678.4522\n",
      "Epoch 9211/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0863 - val_loss: 14571678.4522\n",
      "Epoch 9212/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0407 - val_loss: 14571678.4522\n",
      "Epoch 9213/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 9214/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0290 - val_loss: 14571678.4522\n",
      "Epoch 9215/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1247 - val_loss: 14571678.4522\n",
      "Epoch 9216/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1873 - val_loss: 14571678.4522\n",
      "Epoch 9217/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1173 - val_loss: 14571678.4522\n",
      "Epoch 9218/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1583 - val_loss: 14571678.4522\n",
      "Epoch 9219/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1395 - val_loss: 14571678.4522\n",
      "Epoch 9220/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0789 - val_loss: 14571678.4522\n",
      "Epoch 9221/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0580 - val_loss: 14571678.4522\n",
      "Epoch 9222/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 9223/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0503 - val_loss: 14571678.4522\n",
      "Epoch 9224/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0427 - val_loss: 14571678.4522\n",
      "Epoch 9225/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 9226/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0252 - val_loss: 14571678.4522\n",
      "Epoch 9227/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1240 - val_loss: 14571678.4522\n",
      "Epoch 9228/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530844.9900 - val_loss: 14571678.4522\n",
      "Epoch 9229/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0513 - val_loss: 14571678.4522\n",
      "Epoch 9230/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 9231/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0635 - val_loss: 14571678.4522\n",
      "Epoch 9232/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 9233/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1193 - val_loss: 14571678.4522\n",
      "Epoch 9234/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0337 - val_loss: 14571678.4522\n",
      "Epoch 9235/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1987 - val_loss: 14571678.4522\n",
      "Epoch 9236/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0407 - val_loss: 14571678.4522\n",
      "Epoch 9237/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0020 - val_loss: 14571678.4522\n",
      "Epoch 9238/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0407 - val_loss: 14571678.4522\n",
      "Epoch 9239/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1242 - val_loss: 14571678.4522\n",
      "Epoch 9240/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1305 - val_loss: 14571678.4522\n",
      "Epoch 9241/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0650 - val_loss: 14571678.4522\n",
      "Epoch 9242/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 9243/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0093 - val_loss: 14571678.4522\n",
      "Epoch 9244/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0733 - val_loss: 14571678.4522\n",
      "Epoch 9245/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1613 - val_loss: 14571678.4522\n",
      "Epoch 9246/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0417 - val_loss: 14571678.4522\n",
      "Epoch 9247/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0978 - val_loss: 14571678.4522\n",
      "Epoch 9248/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0433 - val_loss: 14571678.4522\n",
      "Epoch 9249/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0878 - val_loss: 14571678.4522\n",
      "Epoch 9250/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1158 - val_loss: 14571678.4522\n",
      "Epoch 9251/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 9252/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0477 - val_loss: 14571678.4522\n",
      "Epoch 9253/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 9254/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0785 - val_loss: 14571678.4522\n",
      "Epoch 9255/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 9256/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 9257/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0585 - val_loss: 14571678.4522\n",
      "Epoch 9258/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0755 - val_loss: 14571678.4522\n",
      "Epoch 9259/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1578 - val_loss: 14571678.4522\n",
      "Epoch 9260/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1298 - val_loss: 14571678.4522\n",
      "Epoch 9261/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1085 - val_loss: 14571678.4522\n",
      "Epoch 9262/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1620 - val_loss: 14571678.4522\n",
      "Epoch 9263/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 9264/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 9265/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0630 - val_loss: 14571678.4522\n",
      "Epoch 9266/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1313 - val_loss: 14571678.4522\n",
      "Epoch 9267/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0209 - val_loss: 14571678.4522\n",
      "Epoch 9268/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1307 - val_loss: 14571678.4522\n",
      "Epoch 9269/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 9270/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 9271/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 9272/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1037 - val_loss: 14571678.4522\n",
      "Epoch 9273/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0742 - val_loss: 14571678.4522\n",
      "Epoch 9274/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0503 - val_loss: 14571678.4522\n",
      "Epoch 9275/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 9276/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1023 - val_loss: 14571678.4522\n",
      "Epoch 9277/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1215 - val_loss: 14571678.4522\n",
      "Epoch 9278/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0585 - val_loss: 14571678.4522\n",
      "Epoch 9279/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 9280/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0655 - val_loss: 14571678.4522\n",
      "Epoch 9281/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1262 - val_loss: 14571678.4522\n",
      "Epoch 9282/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0787 - val_loss: 14571678.4522\n",
      "Epoch 9283/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 9284/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 9285/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0657 - val_loss: 14571678.4522\n",
      "Epoch 9286/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9697 - val_loss: 14571678.4522\n",
      "Epoch 9287/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 9288/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0550 - val_loss: 14571678.4522\n",
      "Epoch 9289/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1523 - val_loss: 14571678.4522\n",
      "Epoch 9290/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0375 - val_loss: 14571678.4522\n",
      "Epoch 9291/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0848 - val_loss: 14571678.4522\n",
      "Epoch 9292/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0782 - val_loss: 14571678.4522\n",
      "Epoch 9293/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0614 - val_loss: 14571678.4522\n",
      "Epoch 9294/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0727 - val_loss: 14571678.4522\n",
      "Epoch 9295/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1058 - val_loss: 14571678.4522\n",
      "Epoch 9296/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1050 - val_loss: 14571678.4522\n",
      "Epoch 9297/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1597 - val_loss: 14571678.4522\n",
      "Epoch 9298/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1268 - val_loss: 14571678.4522\n",
      "Epoch 9299/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0600 - val_loss: 14571678.4522\n",
      "Epoch 9300/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0665 - val_loss: 14571678.4522\n",
      "Epoch 9301/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0503 - val_loss: 14571678.4522\n",
      "Epoch 9302/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1005 - val_loss: 14571678.4522\n",
      "Epoch 9303/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1377 - val_loss: 14571678.4522\n",
      "Epoch 9304/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1557 - val_loss: 14571678.4522\n",
      "Epoch 9305/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 9306/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0577 - val_loss: 14571678.4522\n",
      "Epoch 9307/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0623 - val_loss: 14571678.4522\n",
      "Epoch 9308/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2150 - val_loss: 14571678.4522\n",
      "Epoch 9309/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9960 - val_loss: 14571678.4522\n",
      "Epoch 9310/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 9311/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1297 - val_loss: 14571678.4522\n",
      "Epoch 9312/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0843 - val_loss: 14571678.4522\n",
      "Epoch 9313/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0640 - val_loss: 14571678.4522\n",
      "Epoch 9314/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1112 - val_loss: 14571678.4522\n",
      "Epoch 9315/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1242 - val_loss: 14571678.4522\n",
      "Epoch 9316/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 9317/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1343 - val_loss: 14571678.4522\n",
      "Epoch 9318/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0263 - val_loss: 14571678.4522\n",
      "Epoch 9319/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1338 - val_loss: 14571678.4522\n",
      "Epoch 9320/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0928 - val_loss: 14571678.4522\n",
      "Epoch 9321/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0783 - val_loss: 14571678.4522\n",
      "Epoch 9322/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 9323/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 9324/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1138 - val_loss: 14571678.4522\n",
      "Epoch 9325/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 9326/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0659 - val_loss: 14571678.4522\n",
      "Epoch 9327/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0020 - val_loss: 14571678.4522\n",
      "Epoch 9328/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1248 - val_loss: 14571678.4522\n",
      "Epoch 9329/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1125 - val_loss: 14571678.4522\n",
      "Epoch 9330/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 9331/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0628 - val_loss: 14571678.4522\n",
      "Epoch 9332/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0597 - val_loss: 14571678.4522\n",
      "Epoch 9333/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 9334/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1000 - val_loss: 14571678.4522\n",
      "Epoch 9335/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0578 - val_loss: 14571678.4522\n",
      "Epoch 9336/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 9337/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 9338/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0808 - val_loss: 14571678.4522\n",
      "Epoch 9339/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 9340/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 9341/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1913 - val_loss: 14571678.4522\n",
      "Epoch 9342/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1673 - val_loss: 14571678.4522\n",
      "Epoch 9343/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0801 - val_loss: 14571678.4522\n",
      "Epoch 9344/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1227 - val_loss: 14571678.4522\n",
      "Epoch 9345/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1093 - val_loss: 14571678.4522\n",
      "Epoch 9346/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1997 - val_loss: 14571678.4522\n",
      "Epoch 9347/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0443 - val_loss: 14571678.4522\n",
      "Epoch 9348/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0570 - val_loss: 14571678.4522\n",
      "Epoch 9349/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 9350/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0832 - val_loss: 14571678.4522\n",
      "Epoch 9351/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1790 - val_loss: 14571678.4522\n",
      "Epoch 9352/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0993 - val_loss: 14571678.4522\n",
      "Epoch 9353/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1145 - val_loss: 14571678.4522\n",
      "Epoch 9354/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0578 - val_loss: 14571678.4522\n",
      "Epoch 9355/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0943 - val_loss: 14571678.4522\n",
      "Epoch 9356/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0935 - val_loss: 14571678.4522\n",
      "Epoch 9357/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1135 - val_loss: 14571678.4522\n",
      "Epoch 9358/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0382 - val_loss: 14571678.4522\n",
      "Epoch 9359/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1525 - val_loss: 14571678.4522\n",
      "Epoch 9360/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 9361/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 9362/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 9363/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 9364/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0540 - val_loss: 14571678.4522\n",
      "Epoch 9365/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0473 - val_loss: 14571678.4522\n",
      "Epoch 9366/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 9367/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1327 - val_loss: 14571678.4522\n",
      "Epoch 9368/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1927 - val_loss: 14571678.4522\n",
      "Epoch 9369/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1440 - val_loss: 14571678.4522\n",
      "Epoch 9370/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1367 - val_loss: 14571678.4522\n",
      "Epoch 9371/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1142 - val_loss: 14571678.4522\n",
      "Epoch 9372/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 9373/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0347 - val_loss: 14571678.4522\n",
      "Epoch 9374/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0745 - val_loss: 14571678.4522\n",
      "Epoch 9375/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0525 - val_loss: 14571678.4522\n",
      "Epoch 9376/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 9377/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 9378/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1150 - val_loss: 14571678.4522\n",
      "Epoch 9379/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0710 - val_loss: 14571678.4522\n",
      "Epoch 9380/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0683 - val_loss: 14571678.4522\n",
      "Epoch 9381/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 9382/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1598 - val_loss: 14571678.4522\n",
      "Epoch 9383/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 9384/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0757 - val_loss: 14571678.4522\n",
      "Epoch 9385/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1540 - val_loss: 14571678.4522\n",
      "Epoch 9386/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1322 - val_loss: 14571678.4522\n",
      "Epoch 9387/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1257 - val_loss: 14571678.4522\n",
      "Epoch 9388/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0832 - val_loss: 14571678.4522\n",
      "Epoch 9389/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0870 - val_loss: 14571678.4522\n",
      "Epoch 9390/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1170 - val_loss: 14571678.4522\n",
      "Epoch 9391/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0467 - val_loss: 14571678.4522\n",
      "Epoch 9392/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0952 - val_loss: 14571678.4522\n",
      "Epoch 9393/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 9394/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 9395/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 9396/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1670 - val_loss: 14571678.4522\n",
      "Epoch 9397/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0573 - val_loss: 14571678.4522\n",
      "Epoch 9398/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0097 - val_loss: 14571678.4522\n",
      "Epoch 9399/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0631 - val_loss: 14571678.4522\n",
      "Epoch 9400/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0192 - val_loss: 14571678.4522\n",
      "Epoch 9401/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0370 - val_loss: 14571678.4522\n",
      "Epoch 9402/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1597 - val_loss: 14571678.4522\n",
      "Epoch 9403/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1152 - val_loss: 14571678.4522\n",
      "Epoch 9404/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1168 - val_loss: 14571678.4522\n",
      "Epoch 9405/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0535 - val_loss: 14571678.4522\n",
      "Epoch 9406/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 9407/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0512 - val_loss: 14571678.4522\n",
      "Epoch 9408/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1382 - val_loss: 14571678.4522\n",
      "Epoch 9409/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1500 - val_loss: 14571678.4522\n",
      "Epoch 9410/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0558 - val_loss: 14571678.4522\n",
      "Epoch 9411/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 9412/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1030 - val_loss: 14571678.4522\n",
      "Epoch 9413/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0947 - val_loss: 14571678.4522\n",
      "Epoch 9414/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1250 - val_loss: 14571678.4522\n",
      "Epoch 9415/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 9416/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 9417/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0553 - val_loss: 14571678.4522\n",
      "Epoch 9418/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0717 - val_loss: 14571678.4522\n",
      "Epoch 9419/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 9420/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0722 - val_loss: 14571678.4522\n",
      "Epoch 9421/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 9422/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0518 - val_loss: 14571678.4522\n",
      "Epoch 9423/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0704 - val_loss: 14571678.4522\n",
      "Epoch 9424/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0873 - val_loss: 14571678.4522\n",
      "Epoch 9425/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1695 - val_loss: 14571678.4522\n",
      "Epoch 9426/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1247 - val_loss: 14571678.4522\n",
      "Epoch 9427/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1087 - val_loss: 14571678.4522\n",
      "Epoch 9428/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 9429/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 9430/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2027 - val_loss: 14571678.4522\n",
      "Epoch 9431/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 9432/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0712 - val_loss: 14571678.4522\n",
      "Epoch 9433/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 9434/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0343 - val_loss: 14571678.4522\n",
      "Epoch 9435/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1090 - val_loss: 14571678.4522\n",
      "Epoch 9436/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 9437/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1840 - val_loss: 14571678.4522\n",
      "Epoch 9438/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1338 - val_loss: 14571678.4522\n",
      "Epoch 9439/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0857 - val_loss: 14571678.4522\n",
      "Epoch 9440/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1141 - val_loss: 14571678.4522\n",
      "Epoch 9441/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 9442/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 9443/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0190 - val_loss: 14571678.4522\n",
      "Epoch 9444/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1112 - val_loss: 14571678.4522\n",
      "Epoch 9445/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 9446/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0357 - val_loss: 14571678.4522\n",
      "Epoch 9447/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0583 - val_loss: 14571678.4522\n",
      "Epoch 9448/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1143 - val_loss: 14571678.4522\n",
      "Epoch 9449/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0935 - val_loss: 14571678.4522\n",
      "Epoch 9450/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0762 - val_loss: 14571678.4522\n",
      "Epoch 9451/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 9452/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2002 - val_loss: 14571678.4522\n",
      "Epoch 9453/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1190 - val_loss: 14571678.4522\n",
      "Epoch 9454/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1290 - val_loss: 14571678.4522\n",
      "Epoch 9455/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 9456/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 9457/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 9458/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1010 - val_loss: 14571678.4522\n",
      "Epoch 9459/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 9460/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0472 - val_loss: 14571678.4522\n",
      "Epoch 9461/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 9462/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0038 - val_loss: 14571678.4522\n",
      "Epoch 9463/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 9464/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1075 - val_loss: 14571678.4522\n",
      "Epoch 9465/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0123 - val_loss: 14571678.4522\n",
      "Epoch 9466/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 9467/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 9468/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0251 - val_loss: 14571678.4522\n",
      "Epoch 9469/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0900 - val_loss: 14571678.4522\n",
      "Epoch 9470/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 9471/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1490 - val_loss: 14571678.4522\n",
      "Epoch 9472/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1263 - val_loss: 14571678.4522\n",
      "Epoch 9473/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0407 - val_loss: 14571678.4522\n",
      "Epoch 9474/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0843 - val_loss: 14571678.4522\n",
      "Epoch 9475/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0367 - val_loss: 14571678.4522\n",
      "Epoch 9476/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0828 - val_loss: 14571678.4522\n",
      "Epoch 9477/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0730 - val_loss: 14571678.4522\n",
      "Epoch 9478/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1208 - val_loss: 14571678.4522\n",
      "Epoch 9479/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 9480/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1387 - val_loss: 14571678.4522\n",
      "Epoch 9481/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0912 - val_loss: 14571678.4522\n",
      "Epoch 9482/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0620 - val_loss: 14571678.4522\n",
      "Epoch 9483/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1398 - val_loss: 14571678.4522\n",
      "Epoch 9484/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0433 - val_loss: 14571678.4522\n",
      "Epoch 9485/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 9486/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 9487/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0748 - val_loss: 14571678.4522\n",
      "Epoch 9488/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0942 - val_loss: 14571678.4522\n",
      "Epoch 9489/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1023 - val_loss: 14571678.4522\n",
      "Epoch 9490/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0767 - val_loss: 14571678.4522\n",
      "Epoch 9491/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1450 - val_loss: 14571678.4522\n",
      "Epoch 9492/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0961 - val_loss: 14571678.4522\n",
      "Epoch 9493/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0570 - val_loss: 14571678.4522\n",
      "Epoch 9494/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0956 - val_loss: 14571678.4522\n",
      "Epoch 9495/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0407 - val_loss: 14571678.4522\n",
      "Epoch 9496/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1115 - val_loss: 14571678.4522\n",
      "Epoch 9497/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1138 - val_loss: 14571678.4522\n",
      "Epoch 9498/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 9499/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 9500/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 9501/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0897 - val_loss: 14571678.4522\n",
      "Epoch 9502/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0820 - val_loss: 14571678.4522\n",
      "Epoch 9503/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0932 - val_loss: 14571678.4522\n",
      "Epoch 9504/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1195 - val_loss: 14571678.4522\n",
      "Epoch 9505/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1737 - val_loss: 14571678.4522\n",
      "Epoch 9506/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0610 - val_loss: 14571678.4522\n",
      "Epoch 9507/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0632 - val_loss: 14571678.4522\n",
      "Epoch 9508/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 9509/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0538 - val_loss: 14571678.4522\n",
      "Epoch 9510/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 9511/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 9512/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 9513/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 9514/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0590 - val_loss: 14571678.4522\n",
      "Epoch 9515/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 9516/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0847 - val_loss: 14571678.4522\n",
      "Epoch 9517/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0922 - val_loss: 14571678.4522\n",
      "Epoch 9518/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0803 - val_loss: 14571678.4522\n",
      "Epoch 9519/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0373 - val_loss: 14571678.4522\n",
      "Epoch 9520/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1032 - val_loss: 14571678.4522\n",
      "Epoch 9521/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0510 - val_loss: 14571678.4522\n",
      "Epoch 9522/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0487 - val_loss: 14571678.4522\n",
      "Epoch 9523/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0908 - val_loss: 14571678.4522\n",
      "Epoch 9524/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 9525/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1310 - val_loss: 14571678.4522\n",
      "Epoch 9526/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0560 - val_loss: 14571678.4522\n",
      "Epoch 9527/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1933 - val_loss: 14571678.4522\n",
      "Epoch 9528/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9442 - val_loss: 14571678.4522\n",
      "Epoch 9529/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1097 - val_loss: 14571678.4522\n",
      "Epoch 9530/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1132 - val_loss: 14571678.4522\n",
      "Epoch 9531/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0930 - val_loss: 14571678.4522\n",
      "Epoch 9532/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0257 - val_loss: 14571678.4522\n",
      "Epoch 9533/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0303 - val_loss: 14571678.4522\n",
      "Epoch 9534/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1795 - val_loss: 14571678.4522\n",
      "Epoch 9535/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2050 - val_loss: 14571678.4522\n",
      "Epoch 9536/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0350 - val_loss: 14571678.4522\n",
      "Epoch 9537/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0610 - val_loss: 14571678.4522\n",
      "Epoch 9538/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1413 - val_loss: 14571678.4522\n",
      "Epoch 9539/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0073 - val_loss: 14571678.4522\n",
      "Epoch 9540/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 9541/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0600 - val_loss: 14571678.4522\n",
      "Epoch 9542/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0567 - val_loss: 14571678.4522\n",
      "Epoch 9543/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0065 - val_loss: 14571678.4522\n",
      "Epoch 9544/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1225 - val_loss: 14571678.4522\n",
      "Epoch 9545/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1462 - val_loss: 14571678.4522\n",
      "Epoch 9546/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0805 - val_loss: 14571678.4522\n",
      "Epoch 9547/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0323 - val_loss: 14571678.4522\n",
      "Epoch 9548/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 9549/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0607 - val_loss: 14571678.4522\n",
      "Epoch 9550/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 9551/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0772 - val_loss: 14571678.4522\n",
      "Epoch 9552/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0388 - val_loss: 14571678.4522\n",
      "Epoch 9553/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 9554/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0990 - val_loss: 14571678.4522\n",
      "Epoch 9555/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0807 - val_loss: 14571678.4522\n",
      "Epoch 9556/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0523 - val_loss: 14571678.4522\n",
      "Epoch 9557/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1032 - val_loss: 14571678.4522\n",
      "Epoch 9558/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530844.9945 - val_loss: 14571678.4522\n",
      "Epoch 9559/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 9560/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0510 - val_loss: 14571678.4522\n",
      "Epoch 9561/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0993 - val_loss: 14571678.4522\n",
      "Epoch 9562/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0997 - val_loss: 14571678.4522\n",
      "Epoch 9563/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0503 - val_loss: 14571678.4522\n",
      "Epoch 9564/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 9565/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0681 - val_loss: 14571678.4522\n",
      "Epoch 9566/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1457 - val_loss: 14571678.4522\n",
      "Epoch 9567/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 9568/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0290 - val_loss: 14571678.4522\n",
      "Epoch 9569/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0800 - val_loss: 14571678.4522\n",
      "Epoch 9570/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0457 - val_loss: 14571678.4522\n",
      "Epoch 9571/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0370 - val_loss: 14571678.4522\n",
      "Epoch 9572/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0233 - val_loss: 14571678.4522\n",
      "Epoch 9573/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0447 - val_loss: 14571678.4522\n",
      "Epoch 9574/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0530 - val_loss: 14571678.4522\n",
      "Epoch 9575/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1197 - val_loss: 14571678.4522\n",
      "Epoch 9576/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1267 - val_loss: 14571678.4522\n",
      "Epoch 9577/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 9578/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1220 - val_loss: 14571678.4522\n",
      "Epoch 9579/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0478 - val_loss: 14571678.4522\n",
      "Epoch 9580/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0420 - val_loss: 14571678.4522\n",
      "Epoch 9581/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1532 - val_loss: 14571678.4522\n",
      "Epoch 9582/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 9583/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0450 - val_loss: 14571678.4522\n",
      "Epoch 9584/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0898 - val_loss: 14571678.4522\n",
      "Epoch 9585/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1858 - val_loss: 14571678.4522\n",
      "Epoch 9586/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0338 - val_loss: 14571678.4522\n",
      "Epoch 9587/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 9588/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 9589/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.1055 - val_loss: 14571678.4522\n",
      "Epoch 9590/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1283 - val_loss: 14571678.4522\n",
      "Epoch 9591/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 9592/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1068 - val_loss: 14571678.4522\n",
      "Epoch 9593/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0327 - val_loss: 14571678.4522\n",
      "Epoch 9594/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1593 - val_loss: 14571678.4522\n",
      "Epoch 9595/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1328 - val_loss: 14571678.4522\n",
      "Epoch 9596/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1558 - val_loss: 14571678.4522\n",
      "Epoch 9597/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0740 - val_loss: 14571678.4522\n",
      "Epoch 9598/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0077 - val_loss: 14571678.4522\n",
      "Epoch 9599/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0735 - val_loss: 14571678.4522\n",
      "Epoch 9600/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1172 - val_loss: 14571678.4522\n",
      "Epoch 9601/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1080 - val_loss: 14571678.4522\n",
      "Epoch 9602/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1243 - val_loss: 14571678.4522\n",
      "Epoch 9603/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0215 - val_loss: 14571678.4522\n",
      "Epoch 9604/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1410 - val_loss: 14571678.4522\n",
      "Epoch 9605/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0237 - val_loss: 14571678.4522\n",
      "Epoch 9606/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 9607/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 9608/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0082 - val_loss: 14571678.4522\n",
      "Epoch 9609/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0113 - val_loss: 14571678.4522\n",
      "Epoch 9610/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 9611/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0617 - val_loss: 14571678.4522\n",
      "Epoch 9612/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1035 - val_loss: 14571678.4522\n",
      "Epoch 9613/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0952 - val_loss: 14571678.4522\n",
      "Epoch 9614/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1285 - val_loss: 14571678.4522\n",
      "Epoch 9615/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1445 - val_loss: 14571678.4522\n",
      "Epoch 9616/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0197 - val_loss: 14571678.4522\n",
      "Epoch 9617/10000\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 1530845.1117 - val_loss: 14571678.4522\n",
      "Epoch 9618/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0717 - val_loss: 14571678.4522\n",
      "Epoch 9619/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0907 - val_loss: 14571678.4522\n",
      "Epoch 9620/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2177 - val_loss: 14571678.4522\n",
      "Epoch 9621/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1470 - val_loss: 14571678.4522\n",
      "Epoch 9622/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0633 - val_loss: 14571678.4522\n",
      "Epoch 9623/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 9624/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1477 - val_loss: 14571678.4522\n",
      "Epoch 9625/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0568 - val_loss: 14571678.4522\n",
      "Epoch 9626/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 9627/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1370 - val_loss: 14571678.4522\n",
      "Epoch 9628/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9915 - val_loss: 14571678.4522\n",
      "Epoch 9629/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0888 - val_loss: 14571678.4522\n",
      "Epoch 9630/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 9631/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 9632/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 9633/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 9634/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0307 - val_loss: 14571678.4522\n",
      "Epoch 9635/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 9636/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 9637/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1043 - val_loss: 14571678.4522\n",
      "Epoch 9638/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1572 - val_loss: 14571678.4522\n",
      "Epoch 9639/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1872 - val_loss: 14571678.4522\n",
      "Epoch 9640/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1522 - val_loss: 14571678.4522\n",
      "Epoch 9641/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1123 - val_loss: 14571678.4522\n",
      "Epoch 9642/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0655 - val_loss: 14571678.4522\n",
      "Epoch 9643/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1237 - val_loss: 14571678.4522\n",
      "Epoch 9644/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 9645/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1478 - val_loss: 14571678.4522\n",
      "Epoch 9646/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0412 - val_loss: 14571678.4522\n",
      "Epoch 9647/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1042 - val_loss: 14571678.4522\n",
      "Epoch 9648/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0570 - val_loss: 14571678.4522\n",
      "Epoch 9649/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 9650/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0853 - val_loss: 14571678.4522\n",
      "Epoch 9651/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1155 - val_loss: 14571678.4522\n",
      "Epoch 9652/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0490 - val_loss: 14571678.4522\n",
      "Epoch 9653/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1130 - val_loss: 14571678.4522\n",
      "Epoch 9654/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0387 - val_loss: 14571678.4522\n",
      "Epoch 9655/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0403 - val_loss: 14571678.4522\n",
      "Epoch 9656/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2387 - val_loss: 14571678.4522\n",
      "Epoch 9657/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0677 - val_loss: 14571678.4522\n",
      "Epoch 9658/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0960 - val_loss: 14571678.4522\n",
      "Epoch 9659/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1643 - val_loss: 14571678.4522\n",
      "Epoch 9660/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0927 - val_loss: 14571678.4522\n",
      "Epoch 9661/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1120 - val_loss: 14571678.4522\n",
      "Epoch 9662/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1018 - val_loss: 14571678.4522\n",
      "Epoch 9663/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1127 - val_loss: 14571678.4522\n",
      "Epoch 9664/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 9665/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0700 - val_loss: 14571678.4522\n",
      "Epoch 9666/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0473 - val_loss: 14571678.4522\n",
      "Epoch 9667/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1053 - val_loss: 14571678.4522\n",
      "Epoch 9668/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 9669/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 9670/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1225 - val_loss: 14571678.4522\n",
      "Epoch 9671/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 9672/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0417 - val_loss: 14571678.4522\n",
      "Epoch 9673/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 9674/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1300 - val_loss: 14571678.4522\n",
      "Epoch 9675/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0213 - val_loss: 14571678.4522\n",
      "Epoch 9676/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0928 - val_loss: 14571678.4522\n",
      "Epoch 9677/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 9678/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1460 - val_loss: 14571678.4522\n",
      "Epoch 9679/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1062 - val_loss: 14571678.4522\n",
      "Epoch 9680/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0581 - val_loss: 14571678.4522\n",
      "Epoch 9681/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 9682/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1015 - val_loss: 14571678.4522\n",
      "Epoch 9683/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0778 - val_loss: 14571678.4522\n",
      "Epoch 9684/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0622 - val_loss: 14571678.4522\n",
      "Epoch 9685/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.0745 - val_loss: 14571678.4522\n",
      "Epoch 9686/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0412 - val_loss: 14571678.4522\n",
      "Epoch 9687/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 9688/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0653 - val_loss: 14571678.4522\n",
      "Epoch 9689/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1353 - val_loss: 14571678.4522\n",
      "Epoch 9690/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1143 - val_loss: 14571678.4522\n",
      "Epoch 9691/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1318 - val_loss: 14571678.4522\n",
      "Epoch 9692/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1207 - val_loss: 14571678.4522\n",
      "Epoch 9693/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1650 - val_loss: 14571678.4522\n",
      "Epoch 9694/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0592 - val_loss: 14571678.4522\n",
      "Epoch 9695/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0270 - val_loss: 14571678.4522\n",
      "Epoch 9696/10000\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 1530845.0545 - val_loss: 14571678.4522\n",
      "Epoch 9697/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0900 - val_loss: 14571678.4522\n",
      "Epoch 9698/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1113 - val_loss: 14571678.4522\n",
      "Epoch 9699/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1442 - val_loss: 14571678.4522\n",
      "Epoch 9700/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1040 - val_loss: 14571678.4522\n",
      "Epoch 9701/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0840 - val_loss: 14571678.4522\n",
      "Epoch 9702/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1320 - val_loss: 14571678.4522\n",
      "Epoch 9703/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0955 - val_loss: 14571678.4522\n",
      "Epoch 9704/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1357 - val_loss: 14571678.4522\n",
      "Epoch 9705/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1060 - val_loss: 14571678.4522\n",
      "Epoch 9706/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 9707/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0913 - val_loss: 14571678.4522\n",
      "Epoch 9708/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1395 - val_loss: 14571678.4522\n",
      "Epoch 9709/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0247 - val_loss: 14571678.4522\n",
      "Epoch 9710/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0967 - val_loss: 14571678.4522\n",
      "Epoch 9711/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1119 - val_loss: 14571678.4522\n",
      "Epoch 9712/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0060 - val_loss: 14571678.4522\n",
      "Epoch 9713/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0650 - val_loss: 14571678.4522\n",
      "Epoch 9714/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 9715/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0613 - val_loss: 14571678.4522\n",
      "Epoch 9716/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0693 - val_loss: 14571678.4522\n",
      "Epoch 9717/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1235 - val_loss: 14571678.4522\n",
      "Epoch 9718/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0605 - val_loss: 14571678.4522\n",
      "Epoch 9719/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1290 - val_loss: 14571678.4522\n",
      "Epoch 9720/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0537 - val_loss: 14571678.4522\n",
      "Epoch 9721/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0362 - val_loss: 14571678.4522\n",
      "Epoch 9722/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0991 - val_loss: 14571678.4522\n",
      "Epoch 9723/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 9724/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0805 - val_loss: 14571678.4522\n",
      "Epoch 9725/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2380 - val_loss: 14571678.4522\n",
      "Epoch 9726/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1465 - val_loss: 14571678.4522\n",
      "Epoch 9727/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0322 - val_loss: 14571678.4522\n",
      "Epoch 9728/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1203 - val_loss: 14571678.4522\n",
      "Epoch 9729/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1103 - val_loss: 14571678.4522\n",
      "Epoch 9730/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0858 - val_loss: 14571678.4522\n",
      "Epoch 9731/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 9732/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0931 - val_loss: 14571678.4522\n",
      "Epoch 9733/10000\n",
      "12000/12000 [==============================] - 0s 12us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 9734/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 9735/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 9736/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0462 - val_loss: 14571678.4522\n",
      "Epoch 9737/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 9738/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1165 - val_loss: 14571678.4522\n",
      "Epoch 9739/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1850 - val_loss: 14571678.4522\n",
      "Epoch 9740/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0825 - val_loss: 14571678.4522\n",
      "Epoch 9741/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0770 - val_loss: 14571678.4522\n",
      "Epoch 9742/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0443 - val_loss: 14571678.4522\n",
      "Epoch 9743/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0532 - val_loss: 14571678.4522\n",
      "Epoch 9744/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1088 - val_loss: 14571678.4522\n",
      "Epoch 9745/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1005 - val_loss: 14571678.4522\n",
      "Epoch 9746/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0380 - val_loss: 14571678.4522\n",
      "Epoch 9747/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 9748/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 9749/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 9750/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1013 - val_loss: 14571678.4522\n",
      "Epoch 9751/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 9752/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 9753/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0692 - val_loss: 14571678.4522\n",
      "Epoch 9754/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1083 - val_loss: 14571678.4522\n",
      "Epoch 9755/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1137 - val_loss: 14571678.4522\n",
      "Epoch 9756/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1027 - val_loss: 14571678.4522\n",
      "Epoch 9757/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1382 - val_loss: 14571678.4522\n",
      "Epoch 9758/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1262 - val_loss: 14571678.4522\n",
      "Epoch 9759/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0980 - val_loss: 14571678.4522\n",
      "Epoch 9760/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0763 - val_loss: 14571678.4522\n",
      "Epoch 9761/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0563 - val_loss: 14571678.4522\n",
      "Epoch 9762/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1590 - val_loss: 14571678.4522\n",
      "Epoch 9763/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0175 - val_loss: 14571678.4522\n",
      "Epoch 9764/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1172 - val_loss: 14571678.4522\n",
      "Epoch 9765/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1033 - val_loss: 14571678.4522\n",
      "Epoch 9766/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1217 - val_loss: 14571678.4522\n",
      "Epoch 9767/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0672 - val_loss: 14571678.4522\n",
      "Epoch 9768/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1253 - val_loss: 14571678.4522\n",
      "Epoch 9769/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0970 - val_loss: 14571678.4522\n",
      "Epoch 9770/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1537 - val_loss: 14571678.4522\n",
      "Epoch 9771/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0470 - val_loss: 14571678.4522\n",
      "Epoch 9772/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0673 - val_loss: 14571678.4522\n",
      "Epoch 9773/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0307 - val_loss: 14571678.4522\n",
      "Epoch 9774/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1082 - val_loss: 14571678.4522\n",
      "Epoch 9775/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1240 - val_loss: 14571678.4522\n",
      "Epoch 9776/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0611 - val_loss: 14571678.4522\n",
      "Epoch 9777/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 9778/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1248 - val_loss: 14571678.4522\n",
      "Epoch 9779/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0522 - val_loss: 14571678.4522\n",
      "Epoch 9780/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0582 - val_loss: 14571678.4522\n",
      "Epoch 9781/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0047 - val_loss: 14571678.4522\n",
      "Epoch 9782/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1360 - val_loss: 14571678.4522\n",
      "Epoch 9783/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0733 - val_loss: 14571678.4522\n",
      "Epoch 9784/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0400 - val_loss: 14571678.4522\n",
      "Epoch 9785/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0653 - val_loss: 14571678.4522\n",
      "Epoch 9786/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0987 - val_loss: 14571678.4522\n",
      "Epoch 9787/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0858 - val_loss: 14571678.4522\n",
      "Epoch 9788/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 9789/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 9790/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 9791/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0382 - val_loss: 14571678.4522\n",
      "Epoch 9792/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0877 - val_loss: 14571678.4522\n",
      "Epoch 9793/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 9794/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 9795/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0045 - val_loss: 14571678.4522\n",
      "Epoch 9796/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0490 - val_loss: 14571678.4522\n",
      "Epoch 9797/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0283 - val_loss: 14571678.4522\n",
      "Epoch 9798/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0528 - val_loss: 14571678.4522\n",
      "Epoch 9799/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1187 - val_loss: 14571678.4522\n",
      "Epoch 9800/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1997 - val_loss: 14571678.4522\n",
      "Epoch 9801/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0432 - val_loss: 14571678.4522\n",
      "Epoch 9802/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0115 - val_loss: 14571678.4522\n",
      "Epoch 9803/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1046 - val_loss: 14571678.4522\n",
      "Epoch 9804/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1210 - val_loss: 14571678.4522\n",
      "Epoch 9805/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1008 - val_loss: 14571678.4522\n",
      "Epoch 9806/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1685 - val_loss: 14571678.4522\n",
      "Epoch 9807/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1420 - val_loss: 14571678.4522\n",
      "Epoch 9808/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0643 - val_loss: 14571678.4522\n",
      "Epoch 9809/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0953 - val_loss: 14571678.4522\n",
      "Epoch 9810/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0293 - val_loss: 14571678.4522\n",
      "Epoch 9811/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1252 - val_loss: 14571678.4522\n",
      "Epoch 9812/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0890 - val_loss: 14571678.4522\n",
      "Epoch 9813/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9733 - val_loss: 14571678.4522\n",
      "Epoch 9814/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2072 - val_loss: 14571678.4522\n",
      "Epoch 9815/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 9816/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1063 - val_loss: 14571678.4522\n",
      "Epoch 9817/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1038 - val_loss: 14571678.4522\n",
      "Epoch 9818/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0310 - val_loss: 14571678.4522\n",
      "Epoch 9819/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1862 - val_loss: 14571678.4522\n",
      "Epoch 9820/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0440 - val_loss: 14571678.4522\n",
      "Epoch 9821/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0772 - val_loss: 14571678.4522\n",
      "Epoch 9822/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0757 - val_loss: 14571678.4522\n",
      "Epoch 9823/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1203 - val_loss: 14571678.4522\n",
      "Epoch 9824/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0057 - val_loss: 14571678.4522\n",
      "Epoch 9825/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0878 - val_loss: 14571678.4522\n",
      "Epoch 9826/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1147 - val_loss: 14571678.4522\n",
      "Epoch 9827/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0978 - val_loss: 14571678.4522\n",
      "Epoch 9828/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 9829/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0173 - val_loss: 14571678.4522\n",
      "Epoch 9830/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1273 - val_loss: 14571678.4522\n",
      "Epoch 9831/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.2032 - val_loss: 14571678.4522\n",
      "Epoch 9832/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0030 - val_loss: 14571678.4522\n",
      "Epoch 9833/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0572 - val_loss: 14571678.4522\n",
      "Epoch 9834/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1227 - val_loss: 14571678.4522\n",
      "Epoch 9835/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0548 - val_loss: 14571678.4522\n",
      "Epoch 9836/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1280 - val_loss: 14571678.4522\n",
      "Epoch 9837/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 9838/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1285 - val_loss: 14571678.4522\n",
      "Epoch 9839/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0830 - val_loss: 14571678.4522\n",
      "Epoch 9840/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0593 - val_loss: 14571678.4522\n",
      "Epoch 9841/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0618 - val_loss: 14571678.4522\n",
      "Epoch 9842/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 9843/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1100 - val_loss: 14571678.4522\n",
      "Epoch 9844/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0910 - val_loss: 14571678.4522\n",
      "Epoch 9845/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0675 - val_loss: 14571678.4522\n",
      "Epoch 9846/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0941 - val_loss: 14571678.4522\n",
      "Epoch 9847/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1061 - val_loss: 14571678.4522\n",
      "Epoch 9848/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0797 - val_loss: 14571678.4522\n",
      "Epoch 9849/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1155 - val_loss: 14571678.4522\n",
      "Epoch 9850/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0747 - val_loss: 14571678.4522\n",
      "Epoch 9851/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0817 - val_loss: 14571678.4522\n",
      "Epoch 9852/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0872 - val_loss: 14571678.4522\n",
      "Epoch 9853/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0977 - val_loss: 14571678.4522\n",
      "Epoch 9854/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 9855/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0973 - val_loss: 14571678.4522\n",
      "Epoch 9856/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 9857/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0775 - val_loss: 14571678.4522\n",
      "Epoch 9858/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0485 - val_loss: 14571678.4522\n",
      "Epoch 9859/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1488 - val_loss: 14571678.4522\n",
      "Epoch 9860/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0530 - val_loss: 14571678.4522\n",
      "Epoch 9861/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0270 - val_loss: 14571678.4522\n",
      "Epoch 9862/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1250 - val_loss: 14571678.4522\n",
      "Epoch 9863/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1522 - val_loss: 14571678.4522\n",
      "Epoch 9864/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1057 - val_loss: 14571678.4522\n",
      "Epoch 9865/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0378 - val_loss: 14571678.4522\n",
      "Epoch 9866/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1333 - val_loss: 14571678.4522\n",
      "Epoch 9867/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1233 - val_loss: 14571678.4522\n",
      "Epoch 9868/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1698 - val_loss: 14571678.4522\n",
      "Epoch 9869/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0617 - val_loss: 14571678.4522\n",
      "Epoch 9870/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1047 - val_loss: 14571678.4522\n",
      "Epoch 9871/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0120 - val_loss: 14571678.4522\n",
      "Epoch 9872/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1527 - val_loss: 14571678.4522\n",
      "Epoch 9873/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0297 - val_loss: 14571678.4522\n",
      "Epoch 9874/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0903 - val_loss: 14571678.4522\n",
      "Epoch 9875/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0423 - val_loss: 14571678.4522\n",
      "Epoch 9876/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0212 - val_loss: 14571678.4522\n",
      "Epoch 9877/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 9878/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0873 - val_loss: 14571678.4522\n",
      "Epoch 9879/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 9880/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0880 - val_loss: 14571678.4522\n",
      "Epoch 9881/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0815 - val_loss: 14571678.4522\n",
      "Epoch 9882/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0713 - val_loss: 14571678.4522\n",
      "Epoch 9883/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1173 - val_loss: 14571678.4522\n",
      "Epoch 9884/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 9885/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 9886/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0819 - val_loss: 14571678.4522\n",
      "Epoch 9887/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.2318 - val_loss: 14571678.4522\n",
      "Epoch 9888/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0328 - val_loss: 14571678.4522\n",
      "Epoch 9889/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0655 - val_loss: 14571678.4522\n",
      "Epoch 9890/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0667 - val_loss: 14571678.4522\n",
      "Epoch 9891/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 9892/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0493 - val_loss: 14571678.4522\n",
      "Epoch 9893/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1299 - val_loss: 14571678.4522\n",
      "Epoch 9894/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0842 - val_loss: 14571678.4522\n",
      "Epoch 9895/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0662 - val_loss: 14571678.4522\n",
      "Epoch 9896/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0780 - val_loss: 14571678.4522\n",
      "Epoch 9897/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1123 - val_loss: 14571678.4522\n",
      "Epoch 9898/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1172 - val_loss: 14571678.4522\n",
      "Epoch 9899/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1070 - val_loss: 14571678.4522\n",
      "Epoch 9900/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1153 - val_loss: 14571678.4522\n",
      "Epoch 9901/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 9902/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 9903/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0750 - val_loss: 14571678.4522\n",
      "Epoch 9904/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1307 - val_loss: 14571678.4522\n",
      "Epoch 9905/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0988 - val_loss: 14571678.4522\n",
      "Epoch 9906/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0937 - val_loss: 14571678.4522\n",
      "Epoch 9907/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0565 - val_loss: 14571678.4522\n",
      "Epoch 9908/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1145 - val_loss: 14571678.4522\n",
      "Epoch 9909/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1113 - val_loss: 14571678.4522\n",
      "Epoch 9910/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0558 - val_loss: 14571678.4522\n",
      "Epoch 9911/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0527 - val_loss: 14571678.4522\n",
      "Epoch 9912/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0940 - val_loss: 14571678.4522\n",
      "Epoch 9913/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530844.9883 - val_loss: 14571678.4522\n",
      "Epoch 9914/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0868 - val_loss: 14571678.4522\n",
      "Epoch 9915/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0864 - val_loss: 14571678.4522\n",
      "Epoch 9916/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0497 - val_loss: 14571678.4522\n",
      "Epoch 9917/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0743 - val_loss: 14571678.4522\n",
      "Epoch 9918/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0917 - val_loss: 14571678.4522\n",
      "Epoch 9919/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0127 - val_loss: 14571678.4522\n",
      "Epoch 9920/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0213 - val_loss: 14571678.4522\n",
      "Epoch 9921/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 9922/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1162 - val_loss: 14571678.4522\n",
      "Epoch 9923/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0545 - val_loss: 14571678.4522\n",
      "Epoch 9924/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0860 - val_loss: 14571678.4522\n",
      "Epoch 9925/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0507 - val_loss: 14571678.4522\n",
      "Epoch 9926/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1682 - val_loss: 14571678.4522\n",
      "Epoch 9927/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1268 - val_loss: 14571678.4522\n",
      "Epoch 9928/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0737 - val_loss: 14571678.4522\n",
      "Epoch 9929/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0707 - val_loss: 14571678.4522\n",
      "Epoch 9930/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0883 - val_loss: 14571678.4522\n",
      "Epoch 9931/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0328 - val_loss: 14571678.4522\n",
      "Epoch 9932/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0773 - val_loss: 14571678.4522\n",
      "Epoch 9933/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1112 - val_loss: 14571678.4522\n",
      "Epoch 9934/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1107 - val_loss: 14571678.4522\n",
      "Epoch 9935/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1425 - val_loss: 14571678.4522\n",
      "Epoch 9936/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0393 - val_loss: 14571678.4522\n",
      "Epoch 9937/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0660 - val_loss: 14571678.4522\n",
      "Epoch 9938/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0732 - val_loss: 14571678.4522\n",
      "Epoch 9939/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1180 - val_loss: 14571678.4522\n",
      "Epoch 9940/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0515 - val_loss: 14571678.4522\n",
      "Epoch 9941/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0063 - val_loss: 14571678.4522\n",
      "Epoch 9942/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0905 - val_loss: 14571678.4522\n",
      "Epoch 9943/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0557 - val_loss: 14571678.4522\n",
      "Epoch 9944/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0793 - val_loss: 14571678.4522\n",
      "Epoch 9945/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0933 - val_loss: 14571678.4522\n",
      "Epoch 9946/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0975 - val_loss: 14571678.4522\n",
      "Epoch 9947/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1017 - val_loss: 14571678.4522\n",
      "Epoch 9948/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1482 - val_loss: 14571678.4522\n",
      "Epoch 9949/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1290 - val_loss: 14571678.4522\n",
      "Epoch 9950/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1077 - val_loss: 14571678.4522\n",
      "Epoch 9951/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0463 - val_loss: 14571678.4522\n",
      "Epoch 9952/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0983 - val_loss: 14571678.4522\n",
      "Epoch 9953/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1855 - val_loss: 14571678.4522\n",
      "Epoch 9954/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1198 - val_loss: 14571678.4522\n",
      "Epoch 9955/10000\n",
      "12000/12000 [==============================] - 0s 16us/step - loss: 1530845.0782 - val_loss: 14571678.4522\n",
      "Epoch 9956/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1543 - val_loss: 14571678.4522\n",
      "Epoch 9957/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0998 - val_loss: 14571678.4522\n",
      "Epoch 9958/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1222 - val_loss: 14571678.4522\n",
      "Epoch 9959/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0790 - val_loss: 14571678.4522\n",
      "Epoch 9960/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 9961/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1372 - val_loss: 14571678.4522\n",
      "Epoch 9962/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0520 - val_loss: 14571678.4522\n",
      "Epoch 9963/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0813 - val_loss: 14571678.4522\n",
      "Epoch 9964/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0517 - val_loss: 14571678.4522\n",
      "Epoch 9965/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0935 - val_loss: 14571678.4522\n",
      "Epoch 9966/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1122 - val_loss: 14571678.4522\n",
      "Epoch 9967/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0460 - val_loss: 14571678.4522\n",
      "Epoch 9968/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0373 - val_loss: 14571678.4522\n",
      "Epoch 9969/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1157 - val_loss: 14571678.4522\n",
      "Epoch 9970/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0867 - val_loss: 14571678.4522\n",
      "Epoch 9971/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0850 - val_loss: 14571678.4522\n",
      "Epoch 9972/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.1067 - val_loss: 14571678.4522\n",
      "Epoch 9973/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0670 - val_loss: 14571678.4522\n",
      "Epoch 9974/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0687 - val_loss: 14571678.4522\n",
      "Epoch 9975/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0887 - val_loss: 14571678.4522\n",
      "Epoch 9976/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1295 - val_loss: 14571678.4522\n",
      "Epoch 9977/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1250 - val_loss: 14571678.4522\n",
      "Epoch 9978/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0855 - val_loss: 14571678.4522\n",
      "Epoch 9979/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1347 - val_loss: 14571678.4522\n",
      "Epoch 9980/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0182 - val_loss: 14571678.4522\n",
      "Epoch 9981/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0863 - val_loss: 14571678.4522\n",
      "Epoch 9982/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1347 - val_loss: 14571678.4522\n",
      "Epoch 9983/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0893 - val_loss: 14571678.4522\n",
      "Epoch 9984/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1390 - val_loss: 14571678.4522\n",
      "Epoch 9985/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0612 - val_loss: 14571678.4522\n",
      "Epoch 9986/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1082 - val_loss: 14571678.4522\n",
      "Epoch 9987/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0682 - val_loss: 14571678.4522\n",
      "Epoch 9988/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0188 - val_loss: 14571678.4522\n",
      "Epoch 9989/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1760 - val_loss: 14571678.4522\n",
      "Epoch 9990/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1177 - val_loss: 14571678.4522\n",
      "Epoch 9991/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.0957 - val_loss: 14571678.4522\n",
      "Epoch 9992/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0655 - val_loss: 14571678.4522\n",
      "Epoch 9993/10000\n",
      "12000/12000 [==============================] - 0s 13us/step - loss: 1530845.0863 - val_loss: 14571678.4522\n",
      "Epoch 9994/10000\n",
      "12000/12000 [==============================] - 0s 15us/step - loss: 1530845.1580 - val_loss: 14571678.4522\n",
      "Epoch 9995/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0840 - val_loss: 14571678.4522\n",
      "Epoch 9996/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1797 - val_loss: 14571678.4522\n",
      "Epoch 9997/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0621 - val_loss: 14571678.4522\n",
      "Epoch 9998/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0458 - val_loss: 14571678.4522\n",
      "Epoch 9999/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.1360 - val_loss: 14571678.4522\n",
      "Epoch 10000/10000\n",
      "12000/12000 [==============================] - 0s 14us/step - loss: 1530845.0580 - val_loss: 14571678.4522\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=10000,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1Jvyjv51f7R"
   },
   "outputs": [],
   "source": [
    "incorrect_training_df = training_df[training_df['label'] == 'incorrect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErwHzzvy3tHH"
   },
   "outputs": [],
   "source": [
    " = incorrect_training_df[training_features_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-n-QS3E4fYv"
   },
   "outputs": [],
   "source": [
    "scaled_data_testing = MinMaxScaler().fit_transform(incorrect_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zx1eZhW_3x1L"
   },
   "outputs": [],
   "source": [
    "predicted = autoencoder.predict(scaled_data_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-0lKd3U4QE2"
   },
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(scaled_data_testing - predicted, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLw1uNz4rcX"
   },
   "outputs": [],
   "source": [
    "incorrect_training_df['anomaly_prediction'] = mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1205,
     "status": "ok",
     "timestamp": 1588582486844,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "xaBOmbtv4-F9",
    "outputId": "613a05d8-64b5-4ed9-aca4-e8407e0d8845"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5bbda3d630>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "incorrect_training_df['anomaly_prediction'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp_Vy12L5UdF"
   },
   "outputs": [],
   "source": [
    "predicted_correct = autoencoder.predict(scaled_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdzZXId75iOg"
   },
   "outputs": [],
   "source": [
    "mse_cor = np.mean(np.power(scaled_seqs - predicted_correct, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1TP5KyF5dx-"
   },
   "outputs": [],
   "source": [
    "correct_training_df['anomaly_prediction'] = mse_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1588582597409,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "oixCzhuD5qdm",
    "outputId": "88bc2d42-2a61-43c6-8561-47d3b2a8b908"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5bbd97d470>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_training_df['anomaly_prediction'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kvs1erDl55F3"
   },
   "outputs": [],
   "source": [
    "training_df = training_df[training_features_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uy2mf_wR6F8t"
   },
   "outputs": [],
   "source": [
    "scaled_full = MinMaxScaler().fit_transform(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4cnbztfo6Pk7"
   },
   "outputs": [],
   "source": [
    "predicted_full = autoencoder.predict(scaled_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1588582789952,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "w2mz5k3p6U8g",
    "outputId": "5f9d5d45-4ff2-498b-c5ee-070fb8dc5076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16968, 13)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSH8lZKv6dB8"
   },
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(scaled_full - predicted_full, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1848,
     "status": "ok",
     "timestamp": 1588582852254,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "gaIPkHvi6mwF",
    "outputId": "29ebb899-6d22-4055-d84e-ceae00a0802a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training_df['pred'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2861,
     "status": "ok",
     "timestamp": 1588582893220,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "RJGAP42_6yKp",
    "outputId": "f7bce735-a264-49ec-a5d2-1a007dc73539"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>cost_per_km</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>distance</th>\n",
       "      <th>time_dif</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>fare</th>\n",
       "      <th>time_driven</th>\n",
       "      <th>charge_per_hour</th>\n",
       "      <th>driving_fare</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189123628</th>\n",
       "      <td>10.5</td>\n",
       "      <td>834.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.019601</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>5.092770</td>\n",
       "      <td>834.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>270.32</td>\n",
       "      <td>778.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>259.8200</td>\n",
       "      <td>0.041286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125358</th>\n",
       "      <td>10.5</td>\n",
       "      <td>791.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>3.168058</td>\n",
       "      <td>791.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>197.85</td>\n",
       "      <td>744.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>187.3500</td>\n",
       "      <td>0.041818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125719</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.021658</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>6.305395</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>301.64</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>291.1400</td>\n",
       "      <td>0.041265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189127273</th>\n",
       "      <td>10.5</td>\n",
       "      <td>598.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.861946</td>\n",
       "      <td>598.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>82.30</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>56.1362</td>\n",
       "      <td>0.035657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189129552</th>\n",
       "      <td>10.5</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.022956</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>24.207039</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1065.02</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1054.5200</td>\n",
       "      <td>0.040784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213803193</th>\n",
       "      <td>10.5</td>\n",
       "      <td>838.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5.4219</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>2.105376</td>\n",
       "      <td>838.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>198.26</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>182.3381</td>\n",
       "      <td>0.035611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213812756</th>\n",
       "      <td>10.5</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>10.868377</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>581.23</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>570.7300</td>\n",
       "      <td>0.040546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213813930</th>\n",
       "      <td>10.5</td>\n",
       "      <td>263.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>1.045518</td>\n",
       "      <td>263.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>76.20</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>65.7000</td>\n",
       "      <td>0.042246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213815405</th>\n",
       "      <td>10.5</td>\n",
       "      <td>858.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>2.879077</td>\n",
       "      <td>858.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>133.31</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>122.8100</td>\n",
       "      <td>0.042632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213817296</th>\n",
       "      <td>10.5</td>\n",
       "      <td>262.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.2243</td>\n",
       "      <td>0.024364</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>2.115875</td>\n",
       "      <td>262.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>98.57</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>86.8457</td>\n",
       "      <td>0.035549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16968 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  ...  driving_fare      pred\n",
       "tripid                                ...                        \n",
       "189123628             10.5     834.0  ...      259.8200  0.041286\n",
       "189125358             10.5     791.0  ...      187.3500  0.041818\n",
       "189125719             10.5    1087.0  ...      291.1400  0.041265\n",
       "189127273             10.5     598.0  ...       56.1362  0.035657\n",
       "189129552             10.5    3407.0  ...     1054.5200  0.040784\n",
       "...                    ...       ...  ...           ...       ...\n",
       "213803193             10.5     838.0  ...      182.3381  0.035611\n",
       "213812756             10.5    2151.0  ...      570.7300  0.040546\n",
       "213813930             10.5     263.0  ...       65.7000  0.042246\n",
       "213815405             10.5     858.0  ...      122.8100  0.042632\n",
       "213817296             10.5     262.0  ...       86.8457  0.035549\n",
       "\n",
       "[16968 rows x 14 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUgtNX9r7AOp"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_df_temp = pd.read_csv(train_path, index_col=\"tripid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bw6JrHPn7GRg"
   },
   "outputs": [],
   "source": [
    "training_df_temp = training_df_temp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGwT9a7k7PuI"
   },
   "outputs": [],
   "source": [
    "training_df_temp['pred'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1588583084329,
     "user": {
      "displayName": "Ranika Madurawe",
      "photoUrl": "",
      "userId": "08934122972253344059"
     },
     "user_tz": -330
    },
    "id": "_npe66v77TQI",
    "outputId": "d47bd231-28bc-4a23-ca1c-b81b9160cfaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189123628</th>\n",
       "      <td>10.5</td>\n",
       "      <td>834.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11/1/2019 0:20</td>\n",
       "      <td>11/1/2019 0:34</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>6.90330</td>\n",
       "      <td>79.8783</td>\n",
       "      <td>270.32</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.041286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125358</th>\n",
       "      <td>10.5</td>\n",
       "      <td>791.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11/1/2019 0:56</td>\n",
       "      <td>11/1/2019 1:09</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>6.91373</td>\n",
       "      <td>79.8923</td>\n",
       "      <td>197.85</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.041818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125719</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11/1/2019 1:08</td>\n",
       "      <td>11/1/2019 1:26</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.93669</td>\n",
       "      <td>79.9146</td>\n",
       "      <td>301.64</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.041265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189127273</th>\n",
       "      <td>10.5</td>\n",
       "      <td>598.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11/1/2019 2:27</td>\n",
       "      <td>11/1/2019 2:37</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>6.92748</td>\n",
       "      <td>79.8971</td>\n",
       "      <td>82.30</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.035657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189129552</th>\n",
       "      <td>10.5</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>11/1/2019 5:38</td>\n",
       "      <td>11/1/2019 6:35</td>\n",
       "      <td>7.13402</td>\n",
       "      <td>79.8969</td>\n",
       "      <td>6.91865</td>\n",
       "      <td>79.8649</td>\n",
       "      <td>1065.02</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.040784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213803193</th>\n",
       "      <td>10.5</td>\n",
       "      <td>838.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5.4219</td>\n",
       "      <td>451.0</td>\n",
       "      <td>1/31/2020 22:07</td>\n",
       "      <td>1/31/2020 22:21</td>\n",
       "      <td>7.29073</td>\n",
       "      <td>80.6367</td>\n",
       "      <td>7.28891</td>\n",
       "      <td>80.6557</td>\n",
       "      <td>198.26</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.035611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213812756</th>\n",
       "      <td>10.5</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1/31/2020 23:07</td>\n",
       "      <td>1/31/2020 23:43</td>\n",
       "      <td>6.90569</td>\n",
       "      <td>79.8516</td>\n",
       "      <td>6.95089</td>\n",
       "      <td>79.9389</td>\n",
       "      <td>581.23</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.040546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213813930</th>\n",
       "      <td>10.5</td>\n",
       "      <td>263.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1/31/2020 23:21</td>\n",
       "      <td>1/31/2020 23:25</td>\n",
       "      <td>7.09210</td>\n",
       "      <td>79.9000</td>\n",
       "      <td>7.10135</td>\n",
       "      <td>79.9017</td>\n",
       "      <td>76.20</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.042246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213815405</th>\n",
       "      <td>10.5</td>\n",
       "      <td>858.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>317.0</td>\n",
       "      <td>1/31/2020 23:39</td>\n",
       "      <td>1/31/2020 23:53</td>\n",
       "      <td>6.94540</td>\n",
       "      <td>79.8768</td>\n",
       "      <td>6.93574</td>\n",
       "      <td>79.9010</td>\n",
       "      <td>133.31</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.042632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213817296</th>\n",
       "      <td>10.5</td>\n",
       "      <td>262.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.2243</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1/31/2020 23:49</td>\n",
       "      <td>1/31/2020 23:53</td>\n",
       "      <td>6.90257</td>\n",
       "      <td>79.9557</td>\n",
       "      <td>6.90823</td>\n",
       "      <td>79.9374</td>\n",
       "      <td>98.57</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.035549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15442 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  meter_waiting  ...     fare    label      pred\n",
       "tripid                                               ...                            \n",
       "189123628             10.5     834.0           56.0  ...   270.32  correct  0.041286\n",
       "189125358             10.5     791.0           47.0  ...   197.85  correct  0.041818\n",
       "189125719             10.5    1087.0           80.0  ...   301.64  correct  0.041265\n",
       "189127273             10.5     598.0          271.0  ...    82.30  correct  0.035657\n",
       "189129552             10.5    3407.0          182.0  ...  1065.02  correct  0.040784\n",
       "...                    ...       ...            ...  ...      ...      ...       ...\n",
       "213803193             10.5     838.0           93.0  ...   198.26  correct  0.035611\n",
       "213812756             10.5    2151.0          428.0  ...   581.23  correct  0.040546\n",
       "213813930             10.5     263.0            9.0  ...    76.20  correct  0.042246\n",
       "213815405             10.5     858.0          115.0  ...   133.31  correct  0.042632\n",
       "213817296             10.5     262.0           21.0  ...    98.57  correct  0.035549\n",
       "\n",
       "[15442 rows x 14 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_temp[training_df_temp['label'] == 'correct']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtKe71tVsKjLNIU7ofBYLX",
   "collapsed_sections": [],
   "name": "autoencorder",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
