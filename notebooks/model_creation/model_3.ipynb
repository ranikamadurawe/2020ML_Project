{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset Importing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path.cwd() / \"../../datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189123628</th>\n",
       "      <td>10.5</td>\n",
       "      <td>834.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11/1/2019 0:20</td>\n",
       "      <td>11/1/2019 0:34</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>6.90330</td>\n",
       "      <td>79.8783</td>\n",
       "      <td>270.32</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125358</th>\n",
       "      <td>10.5</td>\n",
       "      <td>791.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11/1/2019 0:56</td>\n",
       "      <td>11/1/2019 1:09</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>6.91373</td>\n",
       "      <td>79.8923</td>\n",
       "      <td>197.85</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125719</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11/1/2019 1:08</td>\n",
       "      <td>11/1/2019 1:26</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.93669</td>\n",
       "      <td>79.9146</td>\n",
       "      <td>301.64</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189127273</th>\n",
       "      <td>10.5</td>\n",
       "      <td>598.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11/1/2019 2:27</td>\n",
       "      <td>11/1/2019 2:37</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>6.92748</td>\n",
       "      <td>79.8971</td>\n",
       "      <td>82.30</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189128020</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/1/2019 3:34</td>\n",
       "      <td>11/1/2019 3:51</td>\n",
       "      <td>6.87441</td>\n",
       "      <td>79.8615</td>\n",
       "      <td>6.84478</td>\n",
       "      <td>79.9290</td>\n",
       "      <td>358.39</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "tripid                                                                    \n",
       "189123628             10.5     834.0           56.0              0.0000   \n",
       "189125358             10.5     791.0           47.0              0.0000   \n",
       "189125719             10.5    1087.0           80.0              0.0000   \n",
       "189127273             10.5     598.0          271.0             15.6638   \n",
       "189128020              NaN       NaN            NaN                 NaN   \n",
       "\n",
       "           meter_waiting_till_pickup     pickup_time       drop_time  \\\n",
       "tripid                                                                 \n",
       "189123628                       64.0  11/1/2019 0:20  11/1/2019 0:34   \n",
       "189125358                      134.0  11/1/2019 0:56  11/1/2019 1:09   \n",
       "189125719                       61.0  11/1/2019 1:08  11/1/2019 1:26   \n",
       "189127273                       68.0  11/1/2019 2:27  11/1/2019 2:37   \n",
       "189128020                        NaN  11/1/2019 3:34  11/1/2019 3:51   \n",
       "\n",
       "           pick_lat  pick_lon  drop_lat  drop_lon    fare    label  \n",
       "tripid                                                              \n",
       "189123628   6.86252   79.8993   6.90330   79.8783  270.32  correct  \n",
       "189125358   6.88589   79.8984   6.91373   79.8923  197.85  correct  \n",
       "189125719   6.90839   79.8651   6.93669   79.9146  301.64  correct  \n",
       "189127273   6.92570   79.8895   6.92748   79.8971   82.30  correct  \n",
       "189128020   6.87441   79.8615   6.84478   79.9290  358.39  correct  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(DATA_PATH / \"train.csv\", index_col=\"tripid\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.drop('pickup_time', 1)\n",
    "training_df = training_df.drop('drop_time', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_df[['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup','fare']]\n",
    "labels = training_df[['label']]\n",
    "mapping = {'correct': 1, 'incorrect': 0}\n",
    "labels = labels.replace({'label':mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = features.columns[features.dtypes != \"object\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.3, shuffle=True, stratify= labels, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Cleaning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Engineering</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## chain numerical preprocessing into a pipeline object\n",
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='median')),\n",
    "    ('minmax_scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "\n",
    "## create preprocessor stage of the final pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_preprocessing_steps, numerical_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_features = preprocessor.fit_transform(X_train)\n",
    "preprocessed_features_data_frame = pd.DataFrame(data=preprocessed_features, columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_features = preprocessor.fit_transform(X_eval)\n",
    "preprocessed_test_features_data_frame = pd.DataFrame(data=preprocessed_features, columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smk = SMOTETomek(random_state=42)\n",
    "os_x_train, os_y_train = smk.fit_sample(preprocessed_features_data_frame,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21372, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = MultiOutputClassifier(\n",
    "    estimator = LogisticRegression(penalty='l2', C=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('estimators',\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(C=1,\n",
       "                                                                    class_weight=None,\n",
       "                                                                    dual=False,\n",
       "                                                                    fit_intercept=True,\n",
       "                                                                    intercept_scaling=1,\n",
       "                                                                    l1_ratio=None,\n",
       "                                                                    max_iter=100,\n",
       "                                                                    multi_class='auto',\n",
       "                                                                    n_jobs=None,\n",
       "                                                                    penalty='l2',\n",
       "                                                                    random_state=None,\n",
       "                                                                    solver='lbfgs',\n",
       "                                                                    tol=0.0001,\n",
       "                                                                    verbose=0,\n",
       "                                                                    warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    ('estimators', estimators)\n",
    "])\n",
    "\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 34.37 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Train the model\n",
    "full_pipeline.fit(os_x_train, os_y_train)\n",
    "\n",
    "# Predict for the evaluation set\n",
    "print(\"Training Accuracy: %.2f\" % (full_pipeline.score(preprocessed_test_features_data_frame, y_eval)*100), \"%\")\n",
    "y_pred = full_pipeline.predict(preprocessed_test_features_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 431,   73],\n",
       "       [3309, 1340]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_eval, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.86      0.20       504\n",
      "           1       0.95      0.29      0.44      4649\n",
      "\n",
      "    accuracy                           0.34      5153\n",
      "   macro avg       0.53      0.57      0.32      5153\n",
      "weighted avg       0.87      0.34      0.42      5153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(features,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(DATA_PATH / \"test.csv\", index_col=\"tripid\")\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = full_pipeline.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set = pd.read_csv(DATA_PATH / \"sample_submission.csv\", index_col=\"tripid\")\n",
    "submission_set.head()\n",
    "\n",
    "submission_set['prediction']= test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set.to_csv('../../submissions/model2/teamCluster_submission_01.csv', index=True)\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set['prediction'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
