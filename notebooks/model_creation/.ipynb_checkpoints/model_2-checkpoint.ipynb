{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset Importing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path.cwd() / \"../../datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(DATA_PATH / \"train.csv\", index_col=\"tripid\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_df[['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
    "       'meter_waiting_till_pickup', 'pickup_time', 'drop_time', 'pick_lat',\n",
    "       'pick_lon', 'drop_lat', 'drop_lon','fare']]\n",
    "labels = training_df[['label']]\n",
    "mapping = {'correct': 1, 'incorrect': 0}\n",
    "labels = labels.replace({'label':mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = features.columns[features.dtypes != \"object\"].values\n",
    "categorical_features = features.columns[features.dtypes == \"object\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Cleaning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Engineering</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## chain numerical preprocessing into a pipeline object\n",
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='median')),\n",
    "    ('minmax_scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "## chain non-numerical preprocessing into a pipeline object\n",
    "non_numeric_preprocessing_steps = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot_encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "#     ('label_encoder', LabelEncoder())\n",
    "])\n",
    "\n",
    "## create preprocessor stage of the final pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('non_numeric', non_numeric_preprocessing_steps, categorical_features),\n",
    "        ('numeric', numeric_preprocessing_steps, numerical_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = MultiOutputClassifier(\n",
    "    estimator = svm.SVC()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('estimators', estimators)\n",
    "])\n",
    "\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.3, shuffle=True, stratify=labels, random_state=RANDOM_SEED)\n",
    "\n",
    "## Train the model\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict for the evaluation set\n",
    "print(\"Training Accuracy: %.2f\" % (full_pipeline.score(X_eval, y_eval)*100), \"%\")\n",
    "preds = full_pipeline.predict(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(DATA_PATH / \"test.csv\", index_col=\"tripid\")\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = full_pipeline.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set = pd.read_csv(DATA_PATH / \"sample_submission.csv\", index_col=\"tripid\")\n",
    "submission_set.head()\n",
    "\n",
    "submission_set['prediction']= test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set.to_csv('../../submissions/model1/teamCluster_submission_02.csv', index=True)\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set['prediction'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set['prediction'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
